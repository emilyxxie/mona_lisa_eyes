{"version":3,"file":"tf-backend-cpu.min.js","sources":["../src/kernels/Max_impl.ts","../src/kernels/Transpose_impl.ts","../src/cpu_util.ts","../src/utils/pool_utils.ts","../src/backend_cpu.ts","../src/utils/kernel_utils.ts","../src/kernels/Div_impl.ts","../src/kernels/Div.ts","../src/kernels/Max.ts","../src/register_all_kernels.ts","../src/kernels/MaxPoolWithArgmax.ts","../src/kernels/MaxPoolWithArgmax_impl.ts","../src/kernels/NonMaxSuppressionV5.ts","../src/kernels/Square.ts","../src/kernels/SquaredDifference.ts","../src/kernels/Transpose.ts","../src/index.ts","../src/version.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, NumericDataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function maxImpl(\n    aVals: TypedArray, reduceSize: number, outShape: number[],\n    dtype: DataType): TypedArray {\n  const vals = util.getTypedArrayFromDType(\n      dtype as NumericDataType, util.sizeFromShape(outShape));\n\n  for (let i = 0; i < vals.length; ++i) {\n    const offset = i * reduceSize;\n    let max = aVals[offset];\n    for (let j = 0; j < reduceSize; ++j) {\n      const value = aVals[offset + j];\n      if (value > max) {\n        max = value;\n      }\n    }\n    vals[i] = max;\n  }\n  return vals;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, NumericDataType, TypedArray} from '@tensorflow/tfjs-core';\nimport {util} from '@tensorflow/tfjs-core';\n\nexport function transposeImpl(\n    xVals: TypedArray, xShape: number[], dtype: DataType, perm: number[],\n    newShape: number[]): TypedArray {\n  const xRank = xShape.length;\n  const xSize = util.sizeFromShape(xShape);\n  const xStrides = util.computeStrides(xShape);\n  const newStrides = util.computeStrides(newShape);\n\n  const result = util.getTypedArrayFromDType(\n      dtype as NumericDataType, util.sizeFromShape(newShape));\n\n  for (let i = 0; i < xSize; ++i) {\n    const loc = util.indexToLoc(i, xRank, xStrides);\n\n    // Permute location.\n    const newLoc: number[] = new Array(loc.length);\n    for (let i = 0; i < newLoc.length; i++) {\n      newLoc[i] = loc[perm[i]];\n    }\n\n    const newIndex = util.locToIndex(newLoc, xRank, newStrides);\n    result[newIndex] = xVals[i];\n  }\n  return result;\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TensorInfo, util} from '@tensorflow/tfjs-core';\n\nexport function assertNotComplex(\n    tensor: TensorInfo|TensorInfo[], opName: string): void {\n  if (!Array.isArray(tensor)) {\n    tensor = [tensor];\n  }\n  tensor.forEach(t => {\n    if (t != null) {\n      util.assert(\n          t.dtype !== 'complex64',\n          () => `${\n              opName} does not support complex64 tensors in the CPU backend.`);\n    }\n  });\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, buffer, DataType, Rank, TensorBuffer, TypedArray} from '@tensorflow/tfjs-core';\n\nexport function pool(\n    xValues: TypedArray, xShape: number[], dtype: DataType, strides: number[],\n    convInfo: backend_util.Conv2DInfo,\n    poolType: 'max'|'avg'): TensorBuffer<Rank, DataType> {\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padTop = convInfo.padInfo.top;\n  const padLeft = convInfo.padInfo.left;\n\n  const initialValue =\n      (poolType === 'max' ? Number.NEGATIVE_INFINITY :\n                            Number.POSITIVE_INFINITY);\n\n  const output = buffer(convInfo.outShape, dtype);\n  const outputVals = output.values;\n\n  const outputBatchStrides =\n      convInfo.outShape[1] * convInfo.outShape[2] * convInfo.outShape[3];\n  const outputRowStrides = convInfo.outShape[2] * convInfo.outShape[3];\n  const outputColStrides = convInfo.outShape[3];\n\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    const outputBatchOffset = b * outputBatchStrides;\n    const inputBatchOffset = b * strides[0];\n    for (let d = 0; d < convInfo.inChannels; ++d) {\n      for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n        const xRCorner = yR * strideHeight - padTop;\n        const xRMin = Math.max(0, xRCorner);\n        const xRMax =\n            Math.min(convInfo.inHeight, effectiveFilterHeight + xRCorner);\n        const outputRowOffset = outputBatchOffset + yR * outputRowStrides;\n        for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n          const xCCorner = yC * strideWidth - padLeft;\n          const xCMin = Math.max(0, xCCorner);\n          const xCMax =\n              Math.min(convInfo.inWidth, effectiveFilterWidth + xCCorner);\n          let minMaxValue = initialValue;\n          let avgValue = 0;\n          let count = 0;\n          for (let xR = xRMin; xR < xRMax; xR += dilationHeight) {\n            const xROffset = inputBatchOffset + xR * strides[1];\n            for (let xC = xCMin; xC < xCMax; xC += dilationWidth) {\n              const xCOffset = xROffset + xC * strides[2];\n              const pixel = xValues[xCOffset + d];\n              if ((poolType === 'max' && pixel > minMaxValue)) {\n                minMaxValue = pixel;\n              } else if (poolType === 'avg') {\n                avgValue += pixel;\n                count++;\n              }\n            }\n            if (isNaN(minMaxValue)) {\n              break;\n            }\n          }\n          const outputOffset = outputRowOffset + yC * outputColStrides + d;\n          outputVals[outputOffset] =\n              poolType === 'avg' ? avgValue / count : minMaxValue;\n        }\n      }\n    }\n  }\n  return output;\n}\n\nexport function maxPoolPositions(\n    xValues: TypedArray, xShape: number[], dtype: DataType,\n    convInfo: backend_util.Conv2DInfo, flattenPositions = false,\n    includeBatchInIndex = false): TensorBuffer<Rank, 'int32'> {\n  const maxPositions = buffer(convInfo.outShape, 'int32');\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padTop = convInfo.padInfo.top;\n  const padLeft = convInfo.padInfo.left;\n\n  const xBuf = buffer(xShape, dtype, xValues);\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    for (let d = 0; d < convInfo.inChannels; ++d) {\n      for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n        const xRCorner = yR * strideHeight - padTop;\n        let xRMin = xRCorner;\n        while (xRMin < 0) {\n          xRMin += dilationHeight;\n        }\n        // const xRMin = Math.max(0, xRCorner);\n        const xRMax =\n            Math.min(convInfo.inHeight, effectiveFilterHeight + xRCorner);\n        for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n          const xCCorner = yC * strideWidth - padLeft;\n          let xCMin = xCCorner;\n          while (xCMin < 0) {\n            xCMin += dilationWidth;\n          }\n          const xCMax =\n              Math.min(convInfo.inWidth, effectiveFilterWidth + xCCorner);\n          let maxValue = Number.NEGATIVE_INFINITY;\n          let maxPosition = -1;\n\n          for (let xR = xRMin; xR < xRMax; xR += dilationHeight) {\n            const wR = xR - xRCorner;\n            for (let xC = xCMin; xC < xCMax; xC += dilationWidth) {\n              const wC = xC - xCCorner;\n              const pixel = xBuf.get(b, xR, xC, d);\n              if (pixel > maxValue) {\n                maxValue = pixel as number;\n                if (flattenPositions) {\n                  maxPosition = includeBatchInIndex ?\n                      ((b * convInfo.inHeight + xR) * convInfo.inWidth + xC) *\n                              convInfo.inChannels +\n                          d :\n                      (xR * convInfo.inWidth + xC) * convInfo.inChannels + d;\n                } else {\n                  maxPosition = wR * effectiveFilterWidth + wC;\n                }\n              }\n            }\n          }\n          maxPositions.set(maxPosition, b, yR, yC, d);\n        }\n      }\n    }\n  }\n  return maxPositions;\n}\n","/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs-core';\nimport {engine, env} from '@tensorflow/tfjs-core';\nimport {backend_util, buffer, slice_util, util} from '@tensorflow/tfjs-core';\nimport {BackendTimingInfo, DataStorage, DataType, DataValues, KernelBackend, max, NumericDataType, Rank, Scalar, ShapeMap, Tensor, Tensor1D, Tensor2D, Tensor3D, Tensor4D, Tensor5D, TensorBuffer, TypedArray, upcastType} from '@tensorflow/tfjs-core';\nimport {kernel_impls} from '@tensorflow/tfjs-core';\n\nconst nonMaxSuppressionV3 = kernel_impls.nonMaxSuppressionV3;\nconst split = kernel_impls.split;\nconst tile = kernel_impls.tile;\nconst topkImpl = kernel_impls.topkImpl;\nconst whereImpl = kernel_impls.whereImpl;\nimport * as seedrandom from 'seedrandom';\nimport {assertNotComplex} from './cpu_util';\nimport {maxPoolPositions, pool} from './utils/pool_utils';\n\ninterface DataId {}\n\nfunction mapActivation(\n    backend: MathBackendCPU, x: Tensor, activation: backend_util.Activation,\n    preluActivationWeights?: Tensor): Tensor {\n  if (activation === 'linear') {\n    return backend.linear(x);\n  } else if (activation === 'relu') {\n    return backend.relu(x);\n  } else if (activation === 'elu') {\n    return backend.elu(x);\n  } else if (activation === 'relu6') {\n    return backend.relu6(x);\n  } else if (activation === 'prelu') {\n    return backend.prelu(x, preluActivationWeights);\n  }\n  throw new Error(\n      `Activation ${activation} has not been implemented for the CPU backend.`);\n}\n\nexport interface TensorData<D extends DataType> {\n  values?: backend_util.BackendValues;\n  dtype: D;\n  // For complex numbers, the real and imaginary parts are stored as their own\n  // individual tensors, with a parent joining the two with the\n  // complexTensors field.\n  // TODO(smilkov): Replace Tensor with TensorInfo when you modularize ops\n  // that work with complex tensors.\n  complexTensors?: {real: Tensor, imag: Tensor};\n}\n\nexport class MathBackendCPU extends KernelBackend {\n  public blockSize = 48;\n\n  data: DataStorage<TensorData<DataType>>;\n  private firstUse = true;\n\n  constructor() {\n    super();\n    this.data = new DataStorage(this, engine());\n  }\n\n  write(values: backend_util.BackendValues, shape: number[], dtype: DataType):\n      DataId {\n    if (this.firstUse) {\n      this.firstUse = false;\n      if (env().get('IS_NODE')) {\n        backend_util.warn(\n            '\\n============================\\n' +\n            'Hi there ðŸ‘‹. Looks like you are running TensorFlow.js in ' +\n            'Node.js. To speed things up dramatically, install our node ' +\n            'backend, which binds to TensorFlow C++, by running ' +\n            'npm i @tensorflow/tfjs-node, ' +\n            'or npm i @tensorflow/tfjs-node-gpu if you have CUDA. ' +\n            'Then call require(\\'@tensorflow/tfjs-node\\'); (-gpu ' +\n            'suffix for CUDA) at the start of your program. ' +\n            'Visit https://github.com/tensorflow/tfjs-node for more details.' +\n            '\\n============================');\n      }\n    }\n    const dataId = {};\n    this.data.set(dataId, {values, dtype});\n    return dataId;\n  }\n\n  move(\n      dataId: DataId, values: backend_util.BackendValues, shape: number[],\n      dtype: DataType): void {\n    this.data.set(dataId, {values, dtype});\n  }\n\n  numDataIds(): number {\n    return this.data.numDataIds();\n  }\n\n  async read(dataId: DataId): Promise<backend_util.BackendValues> {\n    return this.readSync(dataId);\n  }\n  readSync(dataId: DataId): backend_util.BackendValues {\n    const {dtype, complexTensors} = this.data.get(dataId);\n    if (dtype === 'complex64') {\n      const realValues =\n          this.readSync(complexTensors.real.dataId) as Float32Array;\n      const imagValues =\n          this.readSync(complexTensors.imag.dataId) as Float32Array;\n      return backend_util.mergeRealAndImagArrays(realValues, imagValues);\n    }\n    return this.data.get(dataId).values;\n  }\n\n  private bufferSync<R extends Rank>(t: Tensor<R>): TensorBuffer<R> {\n    const data = this.readSync(t.dataId);\n    let decodedData = data as DataValues;\n    if (t.dtype === 'string') {\n      try {\n        // Decode the bytes into string.\n        decodedData = (data as Uint8Array[]).map(d => util.decodeString(d));\n      } catch {\n        throw new Error('Failed to decode encoded string bytes into utf-8');\n      }\n    }\n    return tf.buffer(t.shape, t.dtype, decodedData) as TensorBuffer<R>;\n  }\n\n  private makeOutput<T extends Tensor>(\n      values: backend_util.BackendValues, shape: number[], dtype: DataType): T {\n    const dataId = this.write(values, shape, dtype);\n    return engine().makeTensorFromDataId(dataId, shape, dtype, this) as T;\n  }\n\n  disposeData(dataId: DataId): void {\n    if (this.data.has(dataId)) {\n      const {complexTensors} = this.data.get(dataId);\n      if (complexTensors != null) {\n        complexTensors.real.dispose();\n        complexTensors.imag.dispose();\n      }\n      this.data.delete(dataId);\n    }\n  }\n\n  async time(f: () => void): Promise<BackendTimingInfo> {\n    const start = util.now();\n    f();\n    const kernelMs = util.now() - start;\n    return {kernelMs};\n  }\n\n  memory() {\n    return {\n      // Unreliable due to automatic gc. The numbers above are cumulative.\n      unreliable: true,\n      reasons:\n          ['The reported memory is an upper bound. Due to automatic garbage ' +\n           'collection, the true allocated memory may be less.']\n    };\n  }\n\n  complex<T extends Tensor>(real: T, imag: T): T {\n    const result = this.makeOutput(null, real.shape, 'complex64');\n\n    const resultData = this.data.get(result.dataId);\n    // The backend owns the reference to the underlying real and imaginary\n    // clones. These will explicitly get disposed when the complex tensor is\n    // disposed.\n    resultData.complexTensors = {\n      real: engine().keep(real.clone()),\n      imag: engine().keep(imag.clone())\n    };\n\n    return result as T;\n  }\n  real<T extends Tensor>(input: T): T {\n    const resultData = this.data.get(input.dataId);\n    return resultData.complexTensors.real.clone() as T;\n  }\n  imag<T extends Tensor>(input: T): T {\n    const resultData = this.data.get(input.dataId);\n    return resultData.complexTensors.imag.clone() as T;\n  }\n\n  slice<T extends Tensor>(x: T, begin: number[], size: number[]): T {\n    assertNotComplex(x, 'slice');\n\n    const isContinous = slice_util.isSliceContinous(x.shape, begin, size);\n    if (isContinous) {\n      const flatOffset = slice_util.computeFlatOffset(begin, x.strides);\n      const length = util.sizeFromShape(size);\n      const vals = this.readSync(x.dataId) as TypedArray;\n      return tf.tensor(\n                 vals.subarray(flatOffset, flatOffset + length), size,\n                 x.dtype) as T;\n    }\n\n    const buffer = tf.buffer(size, x.dtype);\n    const xBuf = this.bufferSync(x);\n    for (let i = 0; i < buffer.size; ++i) {\n      const loc = buffer.indexToLoc(i);\n      const xLoc = loc.map((idx, j) => idx + begin[j]);\n      buffer.values[i] = xBuf.get(...xLoc);\n    }\n    return buffer.toTensor() as T;\n  }\n\n  stridedSlice<T extends Tensor>(\n      x: T, begin: number[], end: number[], strides: number[]): T {\n    assertNotComplex(x, 'stridedSlice');\n\n    const outShape = slice_util.computeOutShape(begin, end, strides);\n\n    if (outShape.some(axis => axis === 0)) {\n      return tf.tensor([], outShape) as T;\n    }\n\n    const buffer = tf.buffer(outShape, x.dtype);\n    const xBuf = this.bufferSync(x);\n    for (let i = 0; i < buffer.size; i++) {\n      const loc = buffer.indexToLoc(i);\n\n      const newLoc: number[] = new Array(loc.length);\n      for (let j = 0; j < newLoc.length; j++) {\n        newLoc[j] = loc[j] * strides[j] + begin[j];\n      }\n      buffer.set(xBuf.get(...newLoc), ...loc);\n    }\n\n    return buffer.toTensor() as T;\n  }\n\n  diag(x: Tensor): Tensor {\n    const xVals = this.readSync(x.dataId) as TypedArray;\n    const buffer = tf.buffer([x.size, x.size], x.dtype);\n    const vals = buffer.values;\n    for (let i = 0; i < xVals.length; i++) {\n      vals[i * x.size + i] = xVals[i];\n    }\n    return buffer.toTensor();\n  }\n\n  unstack(x: Tensor, axis: number): Tensor[] {\n    const num = x.shape[axis];\n    const outShape: number[] = new Array(x.rank - 1);\n    let outIndex = 0;\n    for (let i = 0; i < x.rank; i++) {\n      if (i !== axis) {\n        outShape[outIndex++] = x.shape[i];\n      }\n    }\n\n    const begin = new Array(x.rank).fill(0);\n    const size = x.shape.slice();\n    size[axis] = 1;\n    const res = new Array(num);\n    for (let i = 0; i < res.length; i++) {\n      begin[axis] = i;\n      res[i] = this.slice(x, begin, size).reshape(outShape);\n    }\n    return res;\n  }\n\n  reverse<T extends Tensor>(x: T, axis: number[]): T {\n    assertNotComplex(x, 'reverse');\n\n    const buffer = tf.buffer(x.shape, x.dtype);\n    const xBuf = this.bufferSync(x);\n\n    for (let i = 0; i < buffer.size; i++) {\n      const outLoc = buffer.indexToLoc(i);\n      const inLoc = outLoc.slice();\n      axis.forEach(ax => inLoc[ax] = x.shape[ax] - 1 - inLoc[ax]);\n      buffer.set(xBuf.get(...inLoc), ...outLoc);\n    }\n\n    return buffer.toTensor() as T;\n  }\n\n  concat(tensors: Tensor[], axis: number): Tensor {\n    if (tensors[0].dtype === 'complex64') {\n      const reals = tensors.map((t) => tf.real(t));\n      const imags = tensors.map((t) => tf.imag(t));\n      return tf.complex(this.concat(reals, axis), this.concat(imags, axis));\n    }\n    const tensors2D = tensors.map(t => {\n      const innerSize = util.sizeFromShape(t.shape.slice(axis));\n      return t.as2D(-1, innerSize);\n    });\n    const outShape =\n      backend_util.computeOutShape(tensors2D.map(t => t.shape), 1 /* axis\n        */);\n    const values =\n        tf.buffer(outShape as [number, number], tensors[0].dtype as 'float32')\n            .values;\n    if (tensors2D[0].shape[0] === 1) {\n      // Use built-in TypedArray.set() method for speed.\n      let offset = 0;\n      tensors2D.forEach(t => {\n        values.set(this.readSync(t.dataId) as TypedArray, offset);\n        offset += t.size;\n      });\n    } else {\n      let colOffset = 0;\n      tensors2D.forEach(t => {\n        const tVals = this.readSync(t.dataId) as TypedArray;\n        let tIdx = 0;\n        for (let row = 0; row < t.shape[0]; ++row) {\n          const resIdx = row * outShape[1] + colOffset;\n          for (let col = 0; col < t.shape[1]; ++col) {\n            values[resIdx + col] = tVals[tIdx++];\n          }\n        }\n        colOffset += t.shape[1];\n      });\n    }\n    const finalOutShape =\n        backend_util.computeOutShape(tensors.map(t => t.shape), axis);\n    return tf.tensor(values, finalOutShape, tensors[0].dtype);\n  }\n\n  neg<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'neg');\n\n    return this.multiply(tf.scalar(-1), x) as T;\n  }\n\n  add(a: Tensor, b: Tensor): Tensor {\n    if (a.dtype === 'complex64' || b.dtype === 'complex64') {\n      return this.broadcastedBinaryComplexOp(\n          a.cast('complex64'), b.cast('complex64'),\n          (aReal, aImag, bReal, bImag) => {\n            return {real: aReal + bReal, imag: aImag + bImag};\n          });\n    }\n\n    return this.broadcastedBinaryOp(\n        a, b, upcastType(a.dtype, b.dtype),\n        (aValue, bValue) => aValue + bValue);\n  }\n\n  addN<T extends Tensor>(tensors: T[]): T {\n    assertNotComplex(tensors, 'addN');\n\n    const vals = tensors.map(t => this.readSync(t.dataId) as TypedArray);\n    const result = tf.buffer(tensors[0].shape, tensors[0].dtype as 'float32');\n    const resultVals = result.values;\n    for (let i = 0; i < tensors.length; i++) {\n      const currVals = vals[i];\n      for (let j = 0; j < resultVals.length; j++) {\n        resultVals[j] += currVals[j];\n      }\n    }\n    return result.toTensor() as T;\n  }\n\n  softmax<T extends Tensor>(logits: T, dim: number): T {\n    const axes = util.parseAxisParam([dim], logits.shape);\n    // TODO(annxingyuan): Call maxImpl rather than op as part of softmax kernel\n    // modularization.\n    const maxLogit = max(logits, axes);\n    const expandedShape =\n        backend_util.expandShapeToKeepDim(maxLogit.shape, axes);\n    const a = this.subtract(logits, maxLogit.reshape(expandedShape));\n    const b = this.exp(a);\n    const sumExp = this.sum(b, axes).reshape(expandedShape);\n\n    // TODO(annxingyuan): Call divImpl rather than op as part of softmax\n    // kernel modularization.\n    return tf.div(b, sumExp);\n  }\n\n  subtract(a: Tensor, b: Tensor): Tensor {\n    if (a.dtype === 'complex64' || b.dtype === 'complex64') {\n      return this.broadcastedBinaryComplexOp(\n          a.cast('complex64'), b.cast('complex64'),\n          (aReal, aImag, bReal, bImag) => {\n            return {real: aReal - bReal, imag: aImag - bImag};\n          });\n    }\n\n    return this.broadcastedBinaryOp(\n        a, b, upcastType(a.dtype, b.dtype),\n        (aValue, bValue) => aValue - bValue);\n  }\n\n  pow<T extends Tensor>(a: T, b: Tensor): T {\n    assertNotComplex([a, b], 'pow');\n\n    return this.broadcastedBinaryOp(\n               a, b, a.dtype, (aValue, bValue) => Math.pow(aValue, bValue)) as\n        T;\n  }\n\n  batchMatMul(\n      a: Tensor3D, b: Tensor3D, transposeA: boolean,\n      transposeB: boolean): Tensor3D {\n    assertNotComplex([a, b], 'matMul');\n\n    const sharedDim = transposeA ? a.shape[1] : a.shape[2];\n    const leftDim = transposeA ? a.shape[2] : a.shape[1];\n    const rightDim = transposeB ? b.shape[1] : b.shape[2];\n    const batchDim = a.shape[0];\n\n    const aValues = this.readSync(a.dataId) as TypedArray;\n    const bValues = this.readSync(b.dataId) as TypedArray;\n    const [aBatch, aOuterStep, aInnerStep] = transposeA ?\n        [a.strides[0], 1, a.strides[1]] :\n        [a.strides[0], a.strides[1], 1];\n    const [bInnerStep, bOuterStep, bBatch] = transposeB ?\n        [1, b.strides[1], b.strides[0]] :\n        [b.strides[1], 1, b.strides[0]];\n\n    const size = leftDim * rightDim;\n    const result = tf.buffer([batchDim, leftDim, rightDim], a.dtype);\n    const resVals = result.values as TypedArray;\n    const blockSize = this.blockSize;\n\n    for (let b = 0; b < batchDim; b++) {\n      for (let i0 = 0; i0 < leftDim; i0 += blockSize) {\n        for (let j0 = 0; j0 < rightDim; j0 += blockSize) {\n          for (let k0 = 0; k0 < sharedDim; k0 += blockSize) {\n            // for when blockSize doesn't evenly divide the input\n            const iBlock = Math.min(i0 + blockSize, leftDim);\n            const jBlock = Math.min(j0 + blockSize, rightDim);\n            const kBlock = Math.min(k0 + blockSize, sharedDim);\n\n            for (let i = i0; i < iBlock; i++) {\n              for (let j = j0; j < jBlock; j++) {\n                let sum = 0.0;\n\n                for (let k = k0; k < kBlock; k++) {\n                  sum += aValues[b * aBatch + i * aOuterStep + k * aInnerStep] *\n                      bValues[k * bInnerStep + j * bOuterStep + b * bBatch];\n                }\n                resVals[b * size + (i * rightDim + j)] += sum;\n              }\n            }\n          }\n        }\n      }\n    }\n    return result.toTensor() as Tensor3D;\n  }\n\n  fusedBatchMatMul(\n      {a, b, transposeA, transposeB, bias, activation, preluActivationWeights}:\n          backend_util.FusedBatchMatMulConfig): Tensor3D {\n    let result = this.batchMatMul(a, b, transposeA, transposeB);\n    if (bias) {\n      result = this.add(result, bias) as Tensor3D;\n    }\n    if (activation) {\n      result =\n          mapActivation(this, result, activation, preluActivationWeights) as\n          Tensor3D;\n    }\n    return result;\n  }\n\n  multiply(a: Tensor, b: Tensor): Tensor {\n    if (a.dtype === 'complex64' || b.dtype === 'complex64') {\n      return this.broadcastedBinaryComplexOp(\n          a.cast('complex64'), b.cast('complex64'),\n          (aReal, aImag, bReal, bImag) => {\n            return {\n              real: aReal * bReal - aImag * bImag,\n              imag: aReal * bImag + aImag * bReal\n            };\n          });\n    }\n\n    return this.broadcastedBinaryOp(\n        a, b, upcastType(a.dtype, b.dtype),\n        (aValue, bValue) => aValue * bValue);\n  }\n\n  floorDiv(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'floorDiv');\n\n    const op = (a: number, b: number) => Math.floor(a / b);\n    const outputDtype = 'int32';\n    return this.broadcastedBinaryOp(a, b, outputDtype, op);\n  }\n\n  sum(x: Tensor, axes: number[]): Tensor {\n    assertNotComplex(x, 'sum');\n\n    backend_util.assertAxesAreInnerMostDims('sum', axes, x.rank);\n    const [outShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(x.shape, axes);\n    const resultDtype = upcastType(x.dtype, 'int32');\n    const result = tf.zeros(outShape, resultDtype);\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let sum = 0;\n      for (let j = 0; j < reduceSize; ++j) {\n        sum += aVals[offset + j];\n      }\n      vals[i] = sum;\n    }\n    return result;\n  }\n\n  prod(x: Tensor, axes: number[]): Tensor {\n    assertNotComplex(x, 'sum');\n\n    const [outShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(x.shape, axes);\n    const resultDtype = upcastType(x.dtype, 'int32');\n    const result = tf.zeros(outShape, resultDtype);\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let prod = 1;\n      for (let j = 0; j < reduceSize; ++j) {\n        prod *= aVals[offset + j];\n      }\n      vals[i] = prod;\n    }\n    return result;\n  }\n\n  unsortedSegmentSum<T extends Tensor>(\n      x: T, segmentIds: Tensor1D, numSegments: number): Tensor {\n    assertNotComplex(x, 'unsortedSegmentSum');\n\n    const res = [];\n\n    // Reshape the segment id's so that they can be broadcast with\n    // x. The new shape should be [segmentIds.shape, 1, ..., 1]\n    const numIters = x.rank - segmentIds.rank;\n    for (let i = 0; i < numIters; ++i) {\n      segmentIds = segmentIds.expandDims(i + 1);\n    }\n\n    for (let i = 0; i < numSegments; ++i) {\n      const segmentId = tf.scalar(i, 'int32');\n      const mask = tf.equal(segmentId, segmentIds).asType('float32');\n      const sum = mask.mul(x).sum(0);\n      res.push(sum);\n    }\n\n    return tf.stack(res);\n  }\n\n  argMin(x: Tensor, axis: number): Tensor {\n    assertNotComplex(x, 'argMin');\n\n    const axes = [axis];\n    backend_util.assertAxesAreInnerMostDims('argMin', axes, x.rank);\n    const [outShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(x.shape, axes);\n    const result = tf.zeros(outShape, 'int32');\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let min = aVals[offset];\n      let minIndex = 0;\n      for (let j = 0; j < reduceSize; ++j) {\n        const value = aVals[offset + j];\n        if (value < min) {\n          min = value;\n          minIndex = j;\n        }\n      }\n      vals[i] = minIndex;\n    }\n    return result;\n  }\n\n  argMax(x: Tensor, axis: number): Tensor {\n    assertNotComplex(x, 'argMax');\n\n    const axes = [axis];\n    backend_util.assertAxesAreInnerMostDims('argMax', axes, x.rank);\n    const [outShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(x.shape, axes);\n    const result = tf.zeros(outShape, 'int32');\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let max = aVals[offset];\n      let maxIndex = 0;\n      for (let j = 0; j < reduceSize; ++j) {\n        const value = aVals[offset + j];\n        if (value > max) {\n          max = value;\n          maxIndex = j;\n        }\n      }\n      vals[i] = maxIndex;\n    }\n    return result;\n  }\n\n  cumsum(x: Tensor, axis: number, exclusive: boolean, reverse: boolean):\n      Tensor {\n    assertNotComplex(x, 'cumsum');\n\n    if (axis !== x.rank - 1) {\n      throw new Error(\n          `backend.cumsum in CPU expects an inner-most axis=${x.rank - 1} ` +\n          `but got axis=${axis}`);\n    }\n    const resultDtype = upcastType(x.dtype, 'int32');\n    const result = tf.zeros(x.shape, resultDtype);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    const finalDim = x.shape[x.rank - 1];\n    const indexAdjuster = reverse ?\n        (i: number, j: number) => i + finalDim - j - 1 :\n        (i: number, j: number) => i + j;\n    for (let i = 0; i < aVals.length; i += finalDim) {\n      for (let j = 0; j < finalDim; j++) {\n        const idx = indexAdjuster(i, j);\n        if (j === 0) {\n          vals[idx] = exclusive ? 0 : aVals[idx];\n        } else {\n          const prevIdx = indexAdjuster(i, j - 1);\n          vals[idx] = exclusive ? aVals[prevIdx] + vals[prevIdx] :\n                                  aVals[idx] + vals[prevIdx];\n        }\n      }\n    }\n    return result;\n  }\n\n  equal(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'equal');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return (aVal === bVal) ? 1 : 0;\n    });\n  }\n\n  notEqual(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'notEqual');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return (aVal !== bVal) ? 1 : 0;\n    });\n  }\n\n  less(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'less');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return (aVal < bVal) ? 1 : 0;\n    });\n  }\n\n  lessEqual(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'lessEqual');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return (aVal <= bVal) ? 1 : 0;\n    });\n  }\n\n  greater(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'greater');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return (aVal > bVal) ? 1 : 0;\n    });\n  }\n\n  greaterEqual(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'greaterEqual');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return (aVal >= bVal) ? 1 : 0;\n    });\n  }\n\n  logicalNot<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'logicalNot');\n\n    const values = this.readSync(x.dataId) as TypedArray;\n    const newValues = new Uint8Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      newValues[i] = values[i] ? 0 : 1;\n    }\n    return this.makeOutput(newValues, x.shape, 'bool');\n  }\n\n  logicalAnd(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'logicalAnd');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return aVal && bVal;\n    });\n  }\n\n  logicalOr(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'logicalOr');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return aVal || bVal;\n    });\n  }\n\n  select(condition: Tensor, a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([condition, a, b], 'select');\n\n    const values = this.readSync(condition.dataId) as TypedArray;\n    const aValues = this.readSync(a.dataId) as TypedArray;\n    const bValues = this.readSync(b.dataId) as TypedArray;\n    const result = tf.zeros(a.shape, upcastType(a.dtype, b.dtype));\n    const newValues = this.readSync(result.dataId) as TypedArray;\n    let index = 0;\n    const offset = condition.rank === 0 || condition.rank > 1 || a.rank === 1 ?\n        1 :\n        util.sizeFromShape(a.shape.slice(1));\n\n    for (let i = 0; i < values.length; i++) {\n      for (let j = 0; j < offset; j++) {\n        if (values[i] === 1) {\n          newValues[index++] = aValues[i];\n        } else {\n          newValues[index++] = bValues[i];\n        }\n      }\n    }\n\n    return result;\n  }\n\n  where(condition: Tensor): Tensor2D {\n    assertNotComplex([condition], 'where');\n\n    const condVals = this.readSync(condition.dataId) as TypedArray;\n    return whereImpl(condition.shape, condVals);\n  }\n\n  topk<T extends Tensor>(x: T, k: number, sorted: boolean): [T, T] {\n    assertNotComplex(x, 'topk');\n\n    const xVals = this.readSync(x.dataId) as TypedArray;\n    return topkImpl(xVals, x.shape, x.dtype as NumericDataType, k, sorted);\n  }\n\n  min(x: Tensor, axes: number[]): Tensor {\n    assertNotComplex(x, 'min');\n\n    backend_util.assertAxesAreInnerMostDims('min', axes, x.rank);\n    const [outShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(x.shape, axes);\n    const result = tf.zeros(outShape, x.dtype);\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let min = aVals[offset];\n      for (let j = 0; j < reduceSize; ++j) {\n        const value = aVals[offset + j];\n        if (value < min) {\n          min = value;\n        }\n      }\n      vals[i] = min;\n    }\n    return result;\n  }\n\n  minimum(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'minimum');\n\n    return this.broadcastedBinaryOp(\n        a, b, a.dtype, (aVal, bVal) => Math.min(aVal, bVal));\n  }\n\n  mod(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'mod');\n\n    return this.broadcastedBinaryOp(a, b, a.dtype, (aVal, bVal) => {\n      const rem = aVal % bVal;\n      if ((aVal < 0 && bVal < 0) || (aVal >= 0 && bVal >= 0)) {\n        return rem;\n      } else {\n        return (rem + bVal) % bVal;\n      }\n    });\n  }\n\n  maximum(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'maximum');\n\n    return this.broadcastedBinaryOp(\n        a, b, a.dtype, (aVal, bVal) => Math.max(aVal, bVal));\n  }\n\n  all(x: Tensor, axes: number[]): Tensor {\n    assertNotComplex(x, 'all');\n\n    backend_util.assertAxesAreInnerMostDims('all', axes, x.rank);\n    const [outShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(x.shape, axes);\n    const result = tf.zeros(outShape, x.dtype);\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let all = aVals[offset];\n      for (let j = 0; j < reduceSize; ++j) {\n        const value = aVals[offset + j];\n        all = all && value;\n      }\n      vals[i] = all;\n    }\n    return result;\n  }\n\n  any(x: Tensor, axes: number[]): Tensor {\n    assertNotComplex(x, 'any');\n\n    backend_util.assertAxesAreInnerMostDims('any', axes, x.rank);\n    const [outShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(x.shape, axes);\n    const result = tf.zeros(outShape, x.dtype);\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let anyVal = aVals[offset];\n      for (let j = 0; j < reduceSize; ++j) {\n        const value = aVals[offset + j];\n        anyVal = anyVal || value;\n      }\n      vals[i] = anyVal;\n    }\n    return result;\n  }\n\n  squaredDifference(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'squaredDifference');\n\n    return this.broadcastedBinaryOp(a, b, a.dtype, (aVal, bVal) => {\n      const diff = aVal - bVal;\n      return diff * diff;\n    });\n  }\n\n  ceil<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'ceil');\n\n    const values = this.readSync(x.dataId) as TypedArray;\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      newValues[i] = Math.ceil(values[i]);\n    }\n    return this.makeOutput(newValues, x.shape, 'float32');\n  }\n\n  floor<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'floor');\n\n    const values = this.readSync(x.dataId) as TypedArray;\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      newValues[i] = Math.floor(values[i]);\n    }\n    return this.makeOutput(newValues, x.shape, 'float32');\n  }\n\n  sign<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'x');\n\n    const values = this.readSync(x.dataId) as TypedArray;\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      if (values[i] < 0) {\n        newValues[i] = -1;\n      } else if (values[i] > 0) {\n        newValues[i] = 1;\n      } else {\n        newValues[i] = 0;\n      }\n    }\n    return this.makeOutput(newValues, x.shape, 'float32');\n  }\n\n  isNaN<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'x');\n\n    const values = this.readSync(x.dataId) as TypedArray;\n    const newValues = new Uint8Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      if (Number.isNaN(values[i])) {\n        newValues[i] = 1;\n      }\n    }\n    return this.makeOutput(newValues, x.shape, 'bool');\n  }\n\n  isInf<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'x');\n\n    const values = this.readSync(x.dataId) as TypedArray;\n    const newValues = new Uint8Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      if (Math.abs(values[i]) === Infinity) {\n        newValues[i] = 1;\n      }\n    }\n    return this.makeOutput(newValues, x.shape, 'bool');\n  }\n\n  isFinite<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'x');\n\n    const values = this.readSync(x.dataId) as TypedArray;\n    const newValues = new Uint8Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      if (Number.isFinite(values[i])) {\n        newValues[i] = 1;\n      }\n    }\n    return this.makeOutput(newValues, x.shape, 'bool');\n  }\n\n  round<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'round');\n\n    const values = this.readSync(x.dataId) as TypedArray;\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      // The algorithm is based on banker's rounding.\n      const base = Math.floor(values[i]);\n      if (values[i] - base < 0.5) {\n        newValues[i] = Math.floor(values[i]);\n      } else if (values[i] - base > 0.5) {\n        newValues[i] = Math.ceil(values[i]);\n      } else {\n        if (base % 2.0 === 0.0) {\n          newValues[i] = base;\n        } else {\n          newValues[i] = base + 1.0;\n        }\n      }\n    }\n    return this.makeOutput(newValues, x.shape, 'float32');\n  }\n\n  exp<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'exp');\n\n    const values = this.readSync(x.dataId) as TypedArray;\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      newValues[i] = Math.exp(values[i]);\n    }\n    return this.makeOutput(newValues, x.shape, 'float32');\n  }\n\n  expm1<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'expm1');\n\n    const values = this.readSync(x.dataId) as TypedArray;\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      newValues[i] = Math.expm1(values[i]);\n    }\n    return this.makeOutput(newValues, x.shape, 'float32');\n  }\n\n  log<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'log');\n\n    const values = this.readSync(x.dataId) as TypedArray;\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      const value = values[i];\n      newValues[i] = Math.log(value);\n    }\n    return this.makeOutput(newValues, x.shape, 'float32');\n  }\n\n  log1p<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'log1p');\n\n    const values = this.readSync(x.dataId) as TypedArray;\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      const value = values[i];\n      newValues[i] = Math.log1p(value);\n    }\n    return this.makeOutput(newValues, x.shape, 'float32');\n  }\n\n  sqrt<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'sqrt');\n\n    const values = this.readSync(x.dataId) as TypedArray;\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      const value = values[i];\n      newValues[i] = Math.sqrt(value);\n    }\n    return this.makeOutput(newValues, x.shape, 'float32');\n  }\n\n  rsqrt<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'rsqrt');\n\n    const values = this.readSync(x.dataId) as TypedArray;\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      const value = values[i];\n      newValues[i] = 1 / Math.sqrt(value);\n    }\n    return this.makeOutput(newValues, x.shape, 'float32');\n  }\n\n  reciprocal<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'reciprocal');\n\n    const values = this.readSync(x.dataId) as TypedArray;\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      newValues[i] = 1 / values[i];\n    }\n    return this.makeOutput(newValues, x.shape, 'float32');\n  }\n\n  linear<T extends Tensor>(x: T): T {\n    return x;\n  }\n\n  relu<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'relu');\n\n    const res = tf.zeros(x.shape, x.dtype);\n    const resVals = this.readSync(res.dataId) as TypedArray;\n    const inVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < inVals.length; ++i) {\n      resVals[i] = Math.max(0, inVals[i]);\n    }\n    return res as T;\n  }\n\n  relu6<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'relu');\n\n    const res = tf.zeros(x.shape, x.dtype);\n    const resVals = this.readSync(res.dataId) as TypedArray;\n    const inVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < inVals.length; ++i) {\n      resVals[i] = Math.min(Math.max(0, inVals[i]), 6);\n    }\n    return res as T;\n  }\n\n  prelu<T extends Tensor>(x: T, a: T): T {\n    assertNotComplex([x, a], 'prelu');\n\n    return this.broadcastedBinaryOp(\n               x, a, x.dtype,\n               (xValue, aValue) => xValue < 0 ? aValue * xValue : xValue) as T;\n  }\n\n  elu<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'elu');\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      const v = values[i];\n      if (v >= 0) {\n        resultValues[i] = v;\n      } else {\n        resultValues[i] = (Math.exp(v) - 1);\n      }\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  eluDer<T extends Tensor>(dy: T, y: T): T {\n    assertNotComplex([dy, y], 'eluDer');\n\n    const resultValues = new Float32Array(y.size);\n    const values = this.readSync(y.dataId) as TypedArray;\n    const dyValues = this.readSync(dy.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      const v = values[i];\n      if (v >= 1) {\n        resultValues[i] = dyValues[i];\n      } else {\n        resultValues[i] = dyValues[i] * (v + 1);\n      }\n    }\n    return this.makeOutput(resultValues, y.shape, 'float32');\n  }\n\n  selu<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'selu');\n\n    // Stable and Attracting Fixed Point (0, 1) for Normalized Weights.\n    // see: https://arxiv.org/abs/1706.02515\n    const scaleAlpha = backend_util.SELU_SCALEALPHA;\n    const scale = backend_util.SELU_SCALE;\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      const v = values[i];\n      if (v >= 0) {\n        resultValues[i] = scale * v;\n      } else {\n        resultValues[i] = scaleAlpha * (Math.exp(v) - 1);\n      }\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  clip<T extends Tensor>(x: T, min: number, max: number): T {\n    assertNotComplex(x, 'clip');\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      const v = values[i];\n      resultValues[i] = v > max ? max : (v < min ? min : v);\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  abs<T extends Tensor>(x: T): T {\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.abs(values[i]);\n    }\n\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  complexAbs<T extends Tensor>(x: T): T {\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n\n    for (let i = 0; i < x.size; ++i) {\n      const real = values[i * 2];\n      const imag = values[i * 2 + 1];\n      resultValues[i] = Math.hypot(real, imag);\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  int<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'int');\n\n    const resultValues = new Int32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = values[i];\n    }\n    return this.makeOutput(resultValues, x.shape, 'int32');\n  }\n\n  sigmoid<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'sigmoid');\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = 1 / (1 + Math.exp(-values[i]));\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  softplus<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'softplus');\n\n    // mirrors the implementation of tf.nn.softplus: https://goo.gl/vkcvwX\n\n    // epsilon is the difference between 1.0 and the next representable float.\n    // For a single precision 32 bit float this should be 2^-23, see:\n    // https://math.byu.edu/~schow/work/IEEEFloatingPoint.htm\n    const epsilon = 1.1920928955078125e-7;\n    const threshold = Math.log(epsilon) + 2.0;\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n\n    for (let i = 0; i < values.length; ++i) {\n      // Value above which exp(x) may overflow, but softplus(x) == x\n      // is within machine epsilon.\n      const tooLarge = values[i] > -threshold;\n\n      // Value below which exp(x) may underflow, but softplus(x) == exp(x)\n      // is within machine epsilon.\n      const tooSmall = values[i] < threshold;\n\n      const expX = Math.exp(values[i]);\n      let result;\n\n      if (tooSmall) {\n        result = expX;\n      } else if (tooLarge) {\n        result = values[i];\n      } else {\n        result = Math.log(1.0 + expX);\n      }\n      resultValues[i] = result;\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  sin<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'sin');\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.sin(values[i]);\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  cos<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'cos');\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.cos(values[i]);\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  tan<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'tan');\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.tan(values[i]);\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  asin<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'asin');\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.asin(values[i]);\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  acos<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'acos');\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.acos(values[i]);\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  atan<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'atan');\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.atan(values[i]);\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  atan2<T extends Tensor>(a: T, b: T): T {\n    assertNotComplex([a, b], 'atan2');\n\n    return this.broadcastedBinaryOp(\n               a, b, a.dtype, (aValue, bValue) => Math.atan2(aValue, bValue)) as\n        T;\n  }\n\n  sinh<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'sinh');\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.sinh(values[i]);\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  cosh<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'cosh');\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.cosh(values[i]);\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  tanh<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'tanh');\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = util.tanh(values[i]);\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  asinh<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'asinh');\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.asinh(values[i]);\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  acosh<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'acosh');\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.acosh(values[i]);\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  atanh<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'atanh');\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.atanh(values[i]);\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  erf<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'erf');\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    const p = backend_util.ERF_P;\n    const a1 = backend_util.ERF_A1;\n    const a2 = backend_util.ERF_A2;\n    const a3 = backend_util.ERF_A3;\n    const a4 = backend_util.ERF_A4;\n    const a5 = backend_util.ERF_A5;\n    for (let i = 0; i < values.length; ++i) {\n      const sign = Math.sign(values[i]);\n      const v = Math.abs(values[i]);\n      const t = 1.0 / (1.0 + p * v);\n      resultValues[i] = sign *\n          (1.0 -\n           (((((a5 * t + a4) * t) + a3) * t + a2) * t + a1) * t *\n               Math.exp(-v * v));\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  step<T extends Tensor>(x: T, alpha = 0): T {\n    assertNotComplex(x, 'step');\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      const value = values[i];\n      if (isNaN(value)) {\n        resultValues[i] = NaN;\n      } else {\n        resultValues[i] = value > 0 ? 1 : alpha;\n      }\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  fusedConv2d(\n      {input, filter, convInfo, bias, activation, preluActivationWeights}:\n          backend_util.FusedConv2DConfig): Tensor4D {\n    let result = this.conv2d(input, filter, convInfo);\n\n    if (bias) {\n      result = this.add(result, bias) as Tensor4D;\n    }\n    if (activation) {\n      result =\n          mapActivation(this, result, activation, preluActivationWeights) as\n          Tensor4D;\n    }\n    return result;\n  }\n\n  conv2d(x: Tensor4D, filter: Tensor4D, convInfo: backend_util.Conv2DInfo):\n      Tensor4D {\n    assertNotComplex([x, filter], 'conv2d');\n\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const padLeft = convInfo.padInfo.left;\n    const padTop = convInfo.padInfo.top;\n    const isChannelsLast = convInfo.dataFormat === 'channelsLast';\n\n    const y = tf.buffer(convInfo.outShape, x.dtype as 'float32');\n\n    const xBatchStride = x.strides[0];\n    const xRowStride = isChannelsLast ? x.strides[1] : x.strides[2];\n    const xColStride = isChannelsLast ? x.strides[2] : 1;\n    const xChannelStride = isChannelsLast ? 1 : x.strides[1];\n    const yBatchStride = y.strides[0];\n    const yRowStride = isChannelsLast ? y.strides[1] : y.strides[2];\n    const yColStride = isChannelsLast ? y.strides[2] : 1;\n    const yChannelStride = isChannelsLast ? 1 : y.strides[1];\n\n    const xVals = this.readSync(x.dataId) as TypedArray;\n    const wVals = this.readSync(filter.dataId) as TypedArray;\n    const yVals = y.values;\n\n    for (let b = 0; b < convInfo.batchSize; ++b) {\n      const xOffset1 = b * xBatchStride;\n      const yOffset1 = b * yBatchStride;\n      for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n        const yOffset2 = yOffset1 + yR * yRowStride;\n        const xRCorner = yR * convInfo.strideHeight - padTop;\n        for (let wR = 0; wR < filterHeight; wR++) {\n          const xR = xRCorner + wR * dilationHeight;\n          if (xR < 0 || xR >= convInfo.inHeight) {\n            continue;\n          }\n          const wOffset1 = wR * filter.strides[0];\n          const xOffset2 = xOffset1 + xR * xRowStride;\n          for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n            const yOffset3 = yOffset2 + yC * yColStride;\n            const xCCorner = yC * convInfo.strideWidth - padLeft;\n            for (let wC = 0; wC < filterWidth; wC++) {\n              const xC = xCCorner + wC * dilationWidth;\n              if (xC < 0 || xC >= convInfo.inWidth) {\n                continue;\n              }\n              const wOffset2 = wOffset1 + wC * filter.strides[1];\n              const xOffset3 = xOffset2 + xC * xColStride;\n              let wOffset3 = wOffset2;\n              for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                const xVal = xVals[xOffset3 + d1 * xChannelStride];\n                for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                  yVals[yOffset3 + d2 * yChannelStride] +=\n                      xVal * wVals[wOffset3 + d2];\n                }\n                wOffset3 += convInfo.outChannels;\n              }\n            }\n          }\n        }\n      }\n    }\n    return y.toTensor() as Tensor4D;\n  }\n\n  conv3d(x: Tensor5D, filter: Tensor5D, convInfo: backend_util.Conv3DInfo):\n      Tensor5D {\n    const filterDepth = convInfo.filterDepth;\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const dilationDepth = convInfo.dilationDepth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const padFront = convInfo.padInfo.front;\n    const padLeft = convInfo.padInfo.left;\n    const padTop = convInfo.padInfo.top;\n    const y = tf.buffer<Rank.R5>(convInfo.outShape, x.dtype as 'float32');\n\n    const xVals = this.readSync(x.dataId) as TypedArray;\n    const wVals = this.readSync(filter.dataId) as TypedArray;\n    const yVals = y.values;\n\n    for (let b = 0; b < convInfo.batchSize; ++b) {\n      const xOffset1 = b * x.strides[0];\n      const yOffset1 = b * y.strides[0];\n      for (let yF = 0; yF < convInfo.outDepth; ++yF) {\n        const yOffset2 = yOffset1 + yF * y.strides[1];\n        const xFCorner = yF * convInfo.strideDepth - padFront;\n        for (let wF = 0; wF < filterDepth; wF++) {\n          const xF = xFCorner + wF * dilationDepth;\n          if (xF < 0 || xF >= convInfo.inDepth) {\n            continue;\n          }\n          const wOffset1 = wF * filter.strides[0];\n          const xOffset2 = xOffset1 + xF * x.strides[1];\n\n          for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n            const yOffset3 = yOffset2 + yR * y.strides[2];\n            const xRCorner = yR * convInfo.strideHeight - padTop;\n            for (let wR = 0; wR < filterHeight; wR++) {\n              const xR = xRCorner + wR * dilationHeight;\n              if (xR < 0 || xR >= convInfo.inHeight) {\n                continue;\n              }\n              const wOffset2 = wOffset1 + wR * filter.strides[1];\n              const xOffset3 = xOffset2 + xR * x.strides[2];\n              for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n                const yOffset4 = yOffset3 + yC * convInfo.outChannels;\n                const xCCorner = yC * convInfo.strideWidth - padLeft;\n                for (let wC = 0; wC < filterWidth; wC++) {\n                  const xC = xCCorner + wC * dilationWidth;\n                  if (xC < 0 || xC >= convInfo.inWidth) {\n                    continue;\n                  }\n                  const wOffset3 = wOffset2 + wC * filter.strides[2];\n                  const xOffset4 = xOffset3 + xC * convInfo.inChannels;\n                  let wOffset4 = wOffset3;\n                  for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                    const xVal = xVals[xOffset4 + d1];\n                    for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                      yVals[yOffset4 + d2] += xVal * wVals[wOffset4 + d2];\n                    }\n                    wOffset4 += convInfo.outChannels;\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    return y.toTensor();\n  }\n\n  conv2dDerInput(\n      dy: Tensor4D, filter: Tensor4D,\n      convInfo: backend_util.Conv2DInfo): Tensor4D {\n    assertNotComplex([dy, filter], 'conv2dDerInput');\n\n    const dx = tf.buffer<Rank.R4>(convInfo.inShape, 'float32');\n    const dxValues = dx.values;\n    const dyValues = this.readSync(dy.dataId) as TypedArray;\n    const fltValues = this.readSync(filter.dataId) as TypedArray;\n    const [fltS0, fltS1, fltS2] = filter.strides;\n    const {\n      batchSize,\n      filterHeight,\n      filterWidth,\n      inChannels,\n      inHeight,\n      inWidth,\n      outChannels,\n      outHeight,\n      outWidth,\n      strideHeight,\n      strideWidth,\n      dataFormat\n    } = convInfo;\n    const topPad = filterHeight - 1 - convInfo.padInfo.top;\n    const leftPad = filterWidth - 1 - convInfo.padInfo.left;\n\n    const isChannelsLast = dataFormat === 'channelsLast';\n    const xBatchStride = dx.strides[0];\n    const xRowStride = isChannelsLast ? dx.strides[1] : dx.strides[2];\n    const xColStride = isChannelsLast ? dx.strides[2] : 1;\n    const xChannelStride = isChannelsLast ? 1 : dx.strides[1];\n    const yBatchStride = dy.strides[0];\n    const yRowStride = isChannelsLast ? dy.strides[1] : dy.strides[2];\n    const yColStride = isChannelsLast ? dy.strides[2] : 1;\n    const yChannelStride = isChannelsLast ? 1 : dy.strides[1];\n\n    for (let b = 0; b < batchSize; ++b) {\n      for (let d1 = 0; d1 < inChannels; ++d1) {\n        for (let xR = 0; xR < inHeight; ++xR) {\n          const xRCorner = xR - topPad;\n          const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n          const yRMax =\n              Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);\n\n          for (let xC = 0; xC < inWidth; ++xC) {\n            const xCCorner = xC - leftPad;\n            const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n            const yCMax =\n                Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);\n\n            let dotProd = 0;\n            for (let yR = xRMin; yR < yRMax; ++yR) {\n              const wR = yR * strideHeight - xRCorner;\n\n              for (let yC = xCMin; yC < yCMax; ++yC) {\n                const wC = yC * strideWidth - xCCorner;\n                const dyOffset =\n                    yBatchStride * b + yRowStride * yR + yColStride * yC;\n                const fltOffset = fltS0 * (filterHeight - 1 - wR) +\n                    fltS1 * (filterWidth - 1 - wC) + fltS2 * d1;\n\n                for (let d2 = 0; d2 < outChannels; ++d2) {\n                  const pixel = dyValues[dyOffset + yChannelStride * d2];\n                  const weight = fltValues[fltOffset + d2];\n                  dotProd += pixel * weight;\n                }\n              }\n            }\n            const dxOffset = xBatchStride * b + xRowStride * xR +\n                xColStride * xC + xChannelStride * d1;\n            dxValues[dxOffset] = dotProd;\n          }\n        }\n      }\n    }\n    return dx.toTensor();\n  }\n\n  conv3dDerInput(\n      dy: Tensor5D, filter: Tensor5D,\n      convInfo: backend_util.Conv3DInfo): Tensor5D {\n    const dx = tf.buffer<Rank.R5>(convInfo.inShape, 'float32');\n    const dxValues = dx.values;\n    const [dxS0, dxS1, dxS2, dxS3] = dx.strides;\n    const dyValues = this.readSync(dy.dataId) as TypedArray;\n    const [dyS0, dyS1, dyS2, dyS3] = dy.strides;\n    const fltValues = this.readSync(filter.dataId) as TypedArray;\n    const [fltS0, fltS1, fltS2, fltS3] = filter.strides;\n    const {\n      batchSize,\n      filterDepth,\n      filterHeight,\n      filterWidth,\n      inChannels,\n      inDepth,\n      inHeight,\n      inWidth,\n      outChannels,\n      outDepth,\n      outHeight,\n      outWidth,\n      strideDepth,\n      strideHeight,\n      strideWidth\n    } = convInfo;\n    const frontPad = filterDepth - 1 - convInfo.padInfo.front;\n    const topPad = filterHeight - 1 - convInfo.padInfo.top;\n    const leftPad = filterWidth - 1 - convInfo.padInfo.left;\n\n    for (let b = 0; b < batchSize; ++b) {\n      for (let d1 = 0; d1 < inChannels; ++d1) {\n        // Frames of depth\n        for (let xF = 0; xF < inDepth; ++xF) {\n          const xFCorner = xF - frontPad;\n          const xFMin = Math.max(0, Math.ceil(xFCorner / strideDepth));\n          const yFMax =\n              Math.min(outDepth, (filterDepth + xFCorner) / strideDepth);\n\n          // Rows as per standard 2d matrix notation\n          for (let xR = 0; xR < inHeight; ++xR) {\n            const xRCorner = xR - topPad;\n            const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n            const yRMax =\n                Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);\n            // Columns as per standard 2d matrix notation\n            for (let xC = 0; xC < inWidth; ++xC) {\n              const xCCorner = xC - leftPad;\n              const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n              const yCMax =\n                  Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);\n\n              let dotProd = 0;\n              for (let yF = xFMin; yF < yFMax; ++yF) {\n                const wF = yF * strideDepth - xFCorner;\n\n                for (let yR = xRMin; yR < yRMax; ++yR) {\n                  const wR = yR * strideHeight - xRCorner;\n\n                  for (let yC = xCMin; yC < yCMax; ++yC) {\n                    const wC = yC * strideWidth - xCCorner;\n                    const dyOffset =\n                        dyS0 * b + dyS1 * yF + dyS2 * yR + dyS3 * yC;\n                    const fltOffset = fltS0 * (filterDepth - 1 - wF) +\n                        fltS1 * (filterHeight - 1 - wR) +\n                        fltS2 * (filterWidth - 1 - wC) + fltS3 * d1;\n\n                    for (let d2 = 0; d2 < outChannels; ++d2) {\n                      const pixel = dyValues[dyOffset + d2];\n                      const weight = fltValues[fltOffset + d2];\n                      dotProd += pixel * weight;\n                    }\n                  }\n                }\n              }\n              dxValues[dxS0 * b + dxS1 * xF + dxS2 * xR + dxS3 * xC + d1] =\n                  dotProd;\n            }\n          }\n        }\n      }\n    }\n    return dx.toTensor();\n  }\n\n  conv2dDerFilter(x: Tensor4D, dy: Tensor4D, convInfo: backend_util.Conv2DInfo):\n      Tensor4D {\n    assertNotComplex([x, dy], 'conv2dDerFilter');\n\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const isChannelsLast = convInfo.dataFormat === 'channelsLast';\n    const dW = tf.buffer<Rank.R4>(convInfo.filterShape, 'float32');\n\n    const leftPad = convInfo.padInfo.left;\n    const topPad = convInfo.padInfo.top;\n    const xBuf = this.bufferSync(x);\n    const dyBuf = this.bufferSync(dy);\n    for (let wR = 0; wR < filterHeight; ++wR) {\n      const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n      const yRMax = Math.min(\n          convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);\n\n      for (let wC = 0; wC < filterWidth; ++wC) {\n        const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n        const yCMax = Math.min(\n            convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);\n\n        for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n          for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n            // Need to convolve.\n            let dotProd = 0;\n            for (let b = 0; b < convInfo.batchSize; ++b) {\n              for (let yR = yRMin; yR < yRMax; ++yR) {\n                const xR = wR + yR * strideHeight - topPad;\n                for (let yC = yCMin; yC < yCMax; ++yC) {\n                  const xC = wC + yC * strideWidth - leftPad;\n                  if (isChannelsLast) {\n                    dotProd +=\n                        xBuf.get(b, xR, xC, d1) * dyBuf.get(b, yR, yC, d2);\n                  } else {\n                    dotProd +=\n                        xBuf.get(b, d1, xR, xC) * dyBuf.get(b, d2, yR, yC);\n                  }\n                }\n              }\n            }\n            dW.set(dotProd, wR, wC, d1, d2);\n          }\n        }\n      }\n    }\n    return dW.toTensor();\n  }\n\n  conv3dDerFilter(x: Tensor5D, dy: Tensor5D, convInfo: backend_util.Conv3DInfo):\n      Tensor5D {\n    const strideDepth = convInfo.strideDepth;\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const filterDepth = convInfo.filterDepth;\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n\n    const dw = tf.buffer<Rank.R5>(convInfo.filterShape, 'float32');\n    const dwValues = dw.values;\n    const [dwS0, dwS1, dwS2, dwS3] = dw.strides;\n    const dyValues = this.readSync(dy.dataId) as TypedArray;\n    const [dyS0, dyS1, dyS2, dyS3] = dy.strides;\n    const xValues = this.readSync(x.dataId) as TypedArray;\n    const [xS0, xS1, xS2, xS3] = x.strides;\n\n    const frontPad = convInfo.padInfo.front;\n    const leftPad = convInfo.padInfo.left;\n    const topPad = convInfo.padInfo.top;\n\n    for (let wF = 0; wF < filterDepth; ++wF) {\n      const yFMin = Math.max(0, Math.ceil((frontPad - wF) / strideDepth));\n      const yFMax = Math.min(\n          convInfo.outDepth, (convInfo.inDepth + frontPad - wF) / strideDepth);\n      const wOffset1 = wF * dwS0;\n\n      for (let wR = 0; wR < filterHeight; ++wR) {\n        const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n        const yRMax = Math.min(\n            convInfo.outHeight,\n            (convInfo.inHeight + topPad - wR) / strideHeight);\n        const wOffset2 = wR * dwS1 + wOffset1;\n\n        for (let wC = 0; wC < filterWidth; ++wC) {\n          const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n          const yCMax = Math.min(\n              convInfo.outWidth,\n              (convInfo.inWidth + leftPad - wC) / strideWidth);\n          const wOffset3 = wC * dwS2 + wOffset2;\n\n          for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n            const wOffset4 = d1 * dwS3 + wOffset3;\n\n            for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n              let dotProd = 0;\n              for (let b = 0; b < convInfo.batchSize; ++b) {\n                const xOffset1 = b * xS0;\n                const yOffset1 = b * dyS0;\n\n                for (let yF = yFMin; yF < yFMax; ++yF) {\n                  const xF = wF + yF * strideDepth - frontPad;\n                  const xOffset2 = xF * xS1 + xOffset1;\n                  const yOffset2 = yF * dyS1 + yOffset1;\n\n                  for (let yR = yRMin; yR < yRMax; ++yR) {\n                    const xR = wR + yR * strideHeight - topPad;\n                    const xOffset3 = xR * xS2 + xOffset2;\n                    const yOffset3 = yR * dyS2 + yOffset2;\n\n                    for (let yC = yCMin; yC < yCMax; ++yC) {\n                      const xC = wC + yC * strideWidth - leftPad;\n                      const xOffset4 = xC * xS3 + xOffset3;\n                      const yOffset4 = yC * dyS3 + yOffset3;\n\n                      dotProd +=\n                          xValues[xOffset4 + d1] * dyValues[yOffset4 + d2];\n                    }\n                  }\n                }\n              }\n              dwValues[wOffset4 + d2] = dotProd;\n            }\n          }\n        }\n      }\n    }\n    return dw.toTensor();\n  }\n\n  fusedDepthwiseConv2D(\n      {input, filter, convInfo, bias, activation, preluActivationWeights}:\n          backend_util.FusedConv2DConfig): Tensor4D {\n    let result = this.depthwiseConv2D(input, filter, convInfo);\n\n    if (bias) {\n      result = this.add(result, bias) as Tensor4D;\n    }\n    if (activation) {\n      result =\n          mapActivation(this, result, activation, preluActivationWeights) as\n          Tensor4D;\n    }\n    return result;\n  }\n\n  depthwiseConv2D(\n      x: Tensor4D, filter: Tensor4D,\n      convInfo: backend_util.Conv2DInfo): Tensor4D {\n    assertNotComplex([x, filter], 'depthwiseConv2D');\n\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const padLeft = convInfo.padInfo.left;\n    const padTop = convInfo.padInfo.top;\n    const chMul = convInfo.outChannels / convInfo.inChannels;\n    const y = tf.buffer(convInfo.outShape, x.dtype as 'float32');\n    const xVals = this.readSync(x.dataId) as TypedArray;\n    const wVals = this.readSync(filter.dataId) as TypedArray;\n    const yVals = y.values;\n\n    for (let b = 0; b < convInfo.batchSize; ++b) {\n      const xOffset1 = b * x.strides[0];\n      const yOffset1 = b * y.strides[0];\n      for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n        const yOffset2 = yOffset1 + yR * y.strides[1];\n        const xRCorner = yR * convInfo.strideHeight - padLeft;\n        for (let wR = 0; wR < filterHeight; ++wR) {\n          const xR = xRCorner + wR * dilationHeight;\n          if (xR < 0 || xR >= convInfo.inHeight) {\n            continue;\n          }\n          const wOffset1 = wR * filter.strides[0];\n          const xOffset2 = xOffset1 + xR * x.strides[1];\n          for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n            const yOffset3 = yOffset2 + yC * y.strides[2];\n            const xCCorner = yC * convInfo.strideWidth - padTop;\n            for (let wC = 0; wC < filterWidth; ++wC) {\n              const xC = xCCorner + wC * dilationWidth;\n              if (xC < 0 || xC >= convInfo.inWidth) {\n                continue;\n              }\n              const wOffset2 = wOffset1 + wC * filter.strides[1];\n              const xOffset3 = xOffset2 + xC * convInfo.inChannels;\n              let yOffset4 = yOffset3;\n              let wOffset3 = wOffset2;\n              for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                const xVal = xVals[xOffset3 + d1];\n                for (let q = 0; q < chMul; ++q) {\n                  yVals[yOffset4 + q] += xVal * wVals[wOffset3 + q];\n                }\n                yOffset4 += chMul;\n                wOffset3 += chMul;\n              }\n            }\n          }\n        }\n      }\n    }\n\n    return y.toTensor() as Tensor4D;\n  }\n\n  depthwiseConv2DDerInput(\n      dy: Tensor4D, filter: Tensor4D,\n      convInfo: backend_util.Conv2DInfo): Tensor4D {\n    assertNotComplex([dy, filter], 'depthwiseConv2DDerInput');\n\n    const dx = tf.buffer<Rank.R4>(convInfo.inShape, 'float32');\n    const dxValues = dx.values;\n    const [dxS0, dxS1, dxS2] = dx.strides;\n    const dyValues = this.readSync(dy.dataId) as TypedArray;\n    const [dyS0, dyS1, dyS2] = dy.strides;\n    const fltValues = this.readSync(filter.dataId) as TypedArray;\n    const [fltS0, fltS1, fltS2] = filter.strides;\n    const {\n      batchSize,\n      filterHeight,\n      filterWidth,\n      inChannels,\n      inHeight,\n      inWidth,\n      outChannels,\n      outHeight,\n      outWidth,\n      strideHeight,\n      strideWidth\n    } = convInfo;\n    const topPad = filterHeight - 1 - convInfo.padInfo.top;\n    const leftPad = filterWidth - 1 - convInfo.padInfo.left;\n    const chMul = outChannels / inChannels;\n\n    for (let b = 0; b < batchSize; ++b) {\n      for (let d1 = 0; d1 < inChannels; ++d1) {\n        for (let xR = 0; xR < inHeight; ++xR) {\n          const xRCorner = xR - topPad;\n          const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n          const yRMax =\n              Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);\n\n          for (let xC = 0; xC < inWidth; ++xC) {\n            const xCCorner = xC - leftPad;\n            const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n            const yCMax =\n                Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);\n\n            let dotProd = 0;\n            for (let yR = xRMin; yR < yRMax; ++yR) {\n              const wR = yR * strideHeight - xRCorner;\n\n              for (let yC = xCMin; yC < yCMax; ++yC) {\n                const wC = yC * strideWidth - xCCorner;\n                const dyOffset = dyS0 * b + dyS1 * yR + dyS2 * yC;\n                const fltOffset = fltS0 * (filterHeight - 1 - wR) +\n                    fltS1 * (filterWidth - 1 - wC) + fltS2 * d1;\n\n                for (let dm = 0; dm < chMul; ++dm) {\n                  const d2 = d1 * chMul + dm;\n                  const pixel = dyValues[dyOffset + d2];\n                  const weight = fltValues[fltOffset + dm];\n                  dotProd += pixel * weight;\n                }\n              }\n            }\n            dxValues[dxS0 * b + dxS1 * xR + dxS2 * xC + d1] = dotProd;\n          }\n        }\n      }\n    }\n    return dx.toTensor();\n  }\n\n  depthwiseConv2DDerFilter(\n      x: Tensor4D, dy: Tensor4D, convInfo: backend_util.Conv2DInfo): Tensor4D {\n    assertNotComplex([x, dy], 'depthwiseConv2DDerFilter');\n\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const dW = tf.buffer<Rank.R4>(convInfo.filterShape, 'float32');\n\n    const leftPad = convInfo.padInfo.left;\n    const topPad = convInfo.padInfo.top;\n    const chMul = convInfo.outChannels / convInfo.inChannels;\n\n    const xBuf = this.bufferSync(x);\n    const dyBuf = this.bufferSync(dy);\n    for (let wR = 0; wR < filterHeight; ++wR) {\n      const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n      const yRMax = Math.min(\n          convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);\n\n      for (let wC = 0; wC < filterWidth; ++wC) {\n        const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n        const yCMax = Math.min(\n            convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);\n\n        for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n          const d1 = Math.trunc(d2 / chMul);\n          const dm = d2 % chMul;\n\n          let dotProd = 0;\n          for (let b = 0; b < convInfo.batchSize; ++b) {\n            for (let yR = yRMin; yR < yRMax; ++yR) {\n              const xR = wR + yR * strideHeight - topPad;\n              for (let yC = yCMin; yC < yCMax; ++yC) {\n                const xC = wC + yC * strideWidth - leftPad;\n                dotProd += xBuf.get(b, xR, xC, d1) * dyBuf.get(b, yR, yC, d2);\n              }\n            }\n          }\n          dW.set(dotProd, wR, wC, d1, dm);\n        }\n      }\n    }\n    return dW.toTensor();\n  }\n\n  tile<T extends Tensor>(x: T, reps: number[]): T {\n    assertNotComplex(x, 'tile');\n    return tile(this.bufferSync(x), reps) as T;\n  }\n\n  pad<T extends Tensor>(\n      x: T, paddings: Array<[number, number]>, constantValue: number): T {\n    assertNotComplex(x, 'pad');\n\n    const outShape = paddings.map(\n        (p, i) => p[0] /* beforePad */ + x.shape[i] + p[1] /* afterPad */);\n    const start = paddings.map(p => p[0]);\n    const xBuffer = this.bufferSync(x);\n    const buffer = tf.buffer(outShape, x.dtype as 'float32');\n    if (constantValue !== 0) {\n      buffer.values.fill(constantValue);\n    }\n\n    for (let i = 0; i < x.size; i++) {\n      const coords = xBuffer.indexToLoc(i);\n      const outCoords = coords.map((c, i) => c + start[i]);\n      buffer.set(xBuffer.get(...coords), ...outCoords);\n    }\n    return buffer.toTensor() as T;\n  }\n\n  gather<T extends Tensor>(x: T, indices: Tensor1D, axis: number): T {\n    assertNotComplex([x, indices], 'gather');\n\n    const newShape: number[] = x.shape.slice();\n    const indicesValues = this.readSync(indices.dataId) as TypedArray;\n    newShape[axis] = indicesValues.length;\n    const result = tf.buffer(newShape, x.dtype);\n    const xBuf = this.bufferSync(x);\n\n    for (let i = 0; i < result.size; ++i) {\n      const newLoc = result.indexToLoc(i);\n\n      const originalLoc: number[] = newLoc.slice();\n      originalLoc[axis] = indicesValues[newLoc[axis]];\n\n      const originalIndex = xBuf.locToIndex(originalLoc);\n      result.values[i] = xBuf.values[originalIndex];\n    }\n    return result.toTensor() as T;\n  }\n\n  batchToSpaceND<T extends Tensor>(\n      x: T, blockShape: number[], crops: number[][]): T {\n    assertNotComplex([x], 'batchToSpaceND');\n\n    const prod = blockShape.reduce((a, b) => a * b);\n\n    const reshaped = backend_util.getReshaped(x.shape, blockShape, prod);\n    const permuted =\n        backend_util.getPermuted(reshaped.length, blockShape.length);\n    const reshapedPermuted =\n        backend_util.getReshapedPermuted(x.shape, blockShape, prod);\n    const sliceBeginCoords =\n        backend_util.getSliceBeginCoords(crops, blockShape.length);\n    const sliceSize =\n        backend_util.getSliceSize(reshapedPermuted, crops, blockShape.length);\n\n    return tf.transpose(x.reshape(reshaped), permuted)\n               .reshape(reshapedPermuted)\n               .slice(sliceBeginCoords, sliceSize) as T;\n  }\n\n  spaceToBatchND<T extends Tensor>(\n      x: T, blockShape: number[], paddings: Array<[number, number]>): T {\n    assertNotComplex([x], 'spaceToBatchND');\n\n    const prod = blockShape.reduce((a, b) => a * b);\n\n    const completePaddings: Array<[number, number]> = [[0, 0]];\n    completePaddings.push(...paddings);\n    for (let i = 1 + blockShape.length; i < x.shape.length; ++i) {\n      completePaddings.push([0, 0]);\n    }\n\n    const paddedX = x.pad(completePaddings);\n\n    const reshapedPaddedShape =\n        backend_util.getReshaped(paddedX.shape, blockShape, prod, false);\n    const permutedReshapedPaddedPermutation = backend_util.getPermuted(\n        reshapedPaddedShape.length, blockShape.length, false);\n    const flattenShape = backend_util.getReshapedPermuted(\n        paddedX.shape, blockShape, prod, false);\n\n    return tf.transpose(\n                 paddedX.reshape(reshapedPaddedShape),\n                 permutedReshapedPaddedPermutation)\n               .reshape(flattenShape) as T;\n  }\n\n  maxPool(x: Tensor4D, convInfo: backend_util.Conv2DInfo): Tensor4D {\n    assertNotComplex(x, 'maxPool');\n    const xValues = this.readSync(x.dataId) as TypedArray;\n    return pool(xValues, x.shape, x.dtype, x.strides, convInfo, 'max')\n               .toTensor() as Tensor4D;\n  }\n\n  maxPoolBackprop(\n      dy: Tensor4D, x: Tensor4D, y: Tensor4D,\n      convInfo: backend_util.Conv2DInfo): Tensor4D {\n    assertNotComplex([x, y], 'maxPoolBackprop');\n\n    const xValues = this.readSync(x.dataId) as TypedArray;\n    const maxPosBuf = buffer(\n        convInfo.outShape, x.dtype,\n        maxPoolPositions(xValues, x.shape, x.dtype, convInfo).values);\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n    const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n    const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n    const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n    const dx = tf.buffer<Rank.R4>(x.shape, 'float32');\n\n    const dyBuf = this.bufferSync(dy);\n\n    for (let b = 0; b < convInfo.batchSize; ++b) {\n      for (let d = 0; d < convInfo.inChannels; ++d) {\n        for (let dxR = 0; dxR < convInfo.inHeight; ++dxR) {\n          for (let dxC = 0; dxC < convInfo.inWidth; ++dxC) {\n            // Shader code begins.\n            const dyRCorner = dxR - padTop;\n            const dyCCorner = dxC - padLeft;\n            let dotProd = 0;\n            for (let wR = 0; wR < effectiveFilterHeight; wR += dilationHeight) {\n              const dyR = (dyRCorner + wR) / strideHeight;\n              if (dyR < 0 || dyR >= convInfo.outHeight ||\n                  Math.floor(dyR) !== dyR) {\n                continue;\n              }\n              for (let wC = 0; wC < effectiveFilterWidth; wC += dilationWidth) {\n                const dyC = (dyCCorner + wC) / strideWidth;\n                if (dyC < 0 || dyC >= convInfo.outWidth ||\n                    Math.floor(dyC) !== dyC) {\n                  continue;\n                }\n                const maxPos = effectiveFilterHeight * effectiveFilterWidth -\n                    1 - (maxPosBuf.get(b, dyR, dyC, d) as number);\n                const curPos = wR * effectiveFilterWidth + wC;\n\n                const mask = maxPos === curPos ? 1 : 0;\n                if (mask === 0) {\n                  continue;\n                }\n\n                const pixel = dyBuf.get(b, dyR, dyC, d);\n                dotProd += pixel * mask;\n              }\n            }\n            dx.set(dotProd, b, dxR, dxC, d);\n          }\n        }\n      }\n    }\n    return dx.toTensor();\n  }\n\n  avgPoolBackprop(dy: Tensor4D, x: Tensor4D, convInfo: backend_util.Conv2DInfo):\n      Tensor4D {\n    assertNotComplex([dy, x], 'avgPoolBackprop');\n\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n    const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n    const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n    const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n    const dx = tf.buffer<Rank.R4>(x.shape, 'float32');\n\n    const avgMultiplier = 1 / (filterHeight * filterWidth);\n\n    const dyBuf = this.bufferSync(dy);\n\n    for (let b = 0; b < convInfo.batchSize; ++b) {\n      for (let d = 0; d < convInfo.inChannels; ++d) {\n        for (let dxR = 0; dxR < convInfo.inHeight; ++dxR) {\n          for (let dxC = 0; dxC < convInfo.inWidth; ++dxC) {\n            // Shader code begins.\n            const dyRCorner = dxR - padTop;\n            const dyCCorner = dxC - padLeft;\n            let dotProd = 0;\n            for (let wR = 0; wR < effectiveFilterHeight; wR += dilationHeight) {\n              const dyR = (dyRCorner + wR) / strideHeight;\n              if (dyR < 0 || dyR >= convInfo.outHeight ||\n                  Math.floor(dyR) !== dyR) {\n                continue;\n              }\n              for (let wC = 0; wC < effectiveFilterWidth; wC += dilationWidth) {\n                const dyC = (dyCCorner + wC) / strideWidth;\n                if (dyC < 0 || dyC >= convInfo.outWidth ||\n                    Math.floor(dyC) !== dyC) {\n                  continue;\n                }\n\n                const pixel = dyBuf.get(b, dyR, dyC, d);\n                dotProd += pixel;\n              }\n            }\n            dx.set(dotProd * avgMultiplier, b, dxR, dxC, d);\n          }\n        }\n      }\n    }\n    return dx.toTensor();\n  }\n\n  private pool3d(\n      x: Tensor5D, convInfo: backend_util.Conv3DInfo,\n      poolType: 'max'|'avg'): Tensor5D {\n    assertNotComplex(x, 'pool3d');\n\n    const strideDepth = convInfo.strideDepth;\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const dilationDepth = convInfo.dilationDepth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const effectiveFilterDepth = convInfo.effectiveFilterDepth;\n    const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n    const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n    const padFront = convInfo.padInfo.front;\n    const padTop = convInfo.padInfo.top;\n    const padLeft = convInfo.padInfo.left;\n\n    const initialValue =\n        (poolType === 'max' ? Number.NEGATIVE_INFINITY :\n                              Number.POSITIVE_INFINITY);\n\n    const xValues = this.readSync(x.dataId) as TypedArray;\n    const output = tf.buffer(convInfo.outShape, x.dtype);\n    const outputVals = output.values;\n\n    const outputBatchStrides = convInfo.outShape[1] * convInfo.outShape[2] *\n        convInfo.outShape[3] * convInfo.outShape[4];\n    const outputDepthStrides =\n        convInfo.outShape[2] * convInfo.outShape[3] * convInfo.outShape[4];\n    const outputRowStrides = convInfo.outShape[3] * convInfo.outShape[4];\n    const outputColStrides = convInfo.outShape[4];\n\n    for (let batch = 0; batch < convInfo.batchSize; ++batch) {\n      const outputBatchOffset = batch * outputBatchStrides;\n      const inputBatchOffset = batch * x.strides[0];\n      for (let channel = 0; channel < convInfo.inChannels; ++channel) {\n        for (let yDepth = 0; yDepth < convInfo.outDepth; ++yDepth) {\n          const xDepthCorner = yDepth * strideDepth - padFront;\n          let xDepthMin = xDepthCorner;\n          while (xDepthMin < 0) {\n            xDepthMin += dilationDepth;\n          }\n          const xDepthMax =\n              Math.min(convInfo.inDepth, effectiveFilterDepth + xDepthCorner);\n          const outputDepthOffset =\n              outputBatchOffset + yDepth * outputDepthStrides;\n          for (let yRow = 0; yRow < convInfo.outHeight; ++yRow) {\n            const xRowCorner = yRow * strideHeight - padTop;\n            let xRowMin = xRowCorner;\n            while (xRowMin < 0) {\n              xRowMin += dilationHeight;\n            }\n            const xRowMax =\n                Math.min(convInfo.inHeight, effectiveFilterHeight + xRowCorner);\n            const outputRowOffset = outputDepthOffset + yRow * outputRowStrides;\n            for (let yCol = 0; yCol < convInfo.outWidth; ++yCol) {\n              const xColCorner = yCol * strideWidth - padLeft;\n              let xColMin = xColCorner;\n              while (xColMin < 0) {\n                xColMin += dilationWidth;\n              }\n              const xColMax =\n                  Math.min(convInfo.inWidth, effectiveFilterWidth + xColCorner);\n              // Shader code begins\n              const outputColOffset = outputRowOffset + yCol * outputColStrides;\n              let minMaxValue = initialValue;\n              let avgValue = 0;\n              let count = 0;\n              for (let xDepth = xDepthMin; xDepth < xDepthMax;\n                   xDepth += dilationDepth) {\n                const xDepthOffset = inputBatchOffset + xDepth * x.strides[1];\n                for (let xRow = xRowMin; xRow < xRowMax;\n                     xRow += dilationHeight) {\n                  const xRowOffset = xDepthOffset + xRow * x.strides[2];\n                  for (let xCol = xColMin; xCol < xColMax;\n                       xCol += dilationWidth) {\n                    const xColOffset = xRowOffset + xCol * x.strides[3];\n                    const pixel = xValues[xColOffset + channel];\n                    if ((poolType === 'max' && pixel > minMaxValue)) {\n                      minMaxValue = pixel;\n                    } else if (poolType === 'avg') {\n                      avgValue += pixel;\n                      count++;\n                    }\n                    if (isNaN(minMaxValue)) {\n                      break;\n                    }\n                  }\n                  if (isNaN(minMaxValue)) {\n                    break;\n                  }\n                }\n                if (isNaN(minMaxValue)) {\n                  break;\n                }\n              }\n              const outputOffset = outputColOffset + channel;\n              outputVals[outputOffset] =\n                  poolType === 'avg' ? avgValue / count : minMaxValue;\n            }\n          }\n        }\n      }\n    }\n    return output.toTensor() as Tensor5D;\n  }\n\n  avgPool3d(x: Tensor5D, convInfo: backend_util.Conv3DInfo): Tensor5D {\n    assertNotComplex(x, 'avgPool3d');\n\n    return this.pool3d(x, convInfo, 'avg').toFloat();\n  }\n\n  avgPool3dBackprop(\n      dy: Tensor5D, x: Tensor5D, convInfo: backend_util.Conv3DInfo): Tensor5D {\n    assertNotComplex([dy, x], 'avgPool3dBackprop');\n\n    const strideDepth = convInfo.strideDepth;\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const filterDepth = convInfo.filterDepth;\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const dilationDepth = convInfo.dilationDepth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const effectiveFilterDepth = convInfo.effectiveFilterDepth;\n    const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n    const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n    const padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;\n    const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n    const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n    const dx = tf.buffer<Rank.R5>(x.shape, 'float32');\n\n    const avgMultiplier = 1 / (filterDepth * filterHeight * filterWidth);\n\n    const dyBuf = this.bufferSync(dy);\n\n    for (let batch = 0; batch < convInfo.batchSize; ++batch) {\n      for (let channel = 0; channel < convInfo.inChannels; ++channel) {\n        for (let dxDepth = 0; dxDepth < convInfo.inDepth; ++dxDepth) {\n          for (let dxRow = 0; dxRow < convInfo.inHeight; ++dxRow) {\n            for (let dxCol = 0; dxCol < convInfo.inWidth; ++dxCol) {\n              // Shader code begins.\n              const dyDepthCorner = dxDepth - padFront;\n              const dyRowCorner = dxRow - padTop;\n              const dyColCorner = dxCol - padLeft;\n              let dotProd = 0;\n              for (let wDepth = 0; wDepth < effectiveFilterDepth;\n                   wDepth += dilationDepth) {\n                const dyDepth = (dyDepthCorner + wDepth) / strideDepth;\n                if (dyDepth < 0 || dyDepth >= convInfo.outDepth ||\n                    Math.floor(dyDepth) !== dyDepth) {\n                  continue;\n                }\n                for (let wRow = 0; wRow < effectiveFilterHeight;\n                     wRow += dilationHeight) {\n                  const dyRow = (dyRowCorner + wRow) / strideHeight;\n                  if (dyRow < 0 || dyRow >= convInfo.outHeight ||\n                      Math.floor(dyRow) !== dyRow) {\n                    continue;\n                  }\n                  for (let wCol = 0; wCol < effectiveFilterWidth;\n                       wCol += dilationWidth) {\n                    const dyCol = (dyColCorner + wCol) / strideWidth;\n                    if (dyCol < 0 || dyCol >= convInfo.outWidth ||\n                        Math.floor(dyCol) !== dyCol) {\n                      continue;\n                    }\n\n                    const pixel =\n                        dyBuf.get(batch, dyDepth, dyRow, dyCol, channel);\n                    dotProd += pixel;\n                  }\n                }\n              }\n              dx.set(\n                  dotProd * avgMultiplier, batch, dxDepth, dxRow, dxCol,\n                  channel);\n            }\n          }\n        }\n      }\n    }\n    return dx.toTensor();\n  }\n\n  maxPool3d(x: Tensor5D, convInfo: backend_util.Conv3DInfo): Tensor5D {\n    assertNotComplex(x, 'maxPool3d');\n\n    return this.pool3d(x, convInfo, 'max').toFloat();\n  }\n\n  private maxPool3dPositions(x: Tensor5D, convInfo: backend_util.Conv3DInfo):\n      Tensor5D {\n    const maxPositions = tf.buffer(convInfo.outShape, 'int32');\n    const strideDepth = convInfo.strideDepth;\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const dilationDepth = convInfo.dilationDepth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const effectiveFilterDepth = convInfo.effectiveFilterDepth;\n    const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n    const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n    const padFront = convInfo.padInfo.front;\n    const padTop = convInfo.padInfo.top;\n    const padLeft = convInfo.padInfo.left;\n\n    const xBuf = this.bufferSync(x);\n    for (let batch = 0; batch < convInfo.batchSize; ++batch) {\n      for (let channel = 0; channel < convInfo.inChannels; ++channel) {\n        for (let yDepth = 0; yDepth < convInfo.outDepth; ++yDepth) {\n          const xDepthCorner = yDepth * strideDepth - padFront;\n          let xDepthMin = xDepthCorner;\n          while (xDepthMin < 0) {\n            xDepthMin += dilationDepth;\n          }\n          const xDepthMax =\n              Math.min(convInfo.inDepth, effectiveFilterDepth + xDepthCorner);\n          for (let yRow = 0; yRow < convInfo.outHeight; ++yRow) {\n            const xRowCorner = yRow * strideHeight - padTop;\n            let xRowMin = xRowCorner;\n            while (xRowMin < 0) {\n              xRowMin += dilationHeight;\n            }\n            const xRowMax =\n                Math.min(convInfo.inHeight, effectiveFilterHeight + xRowCorner);\n            for (let yCol = 0; yCol < convInfo.outWidth; ++yCol) {\n              const xColCorner = yCol * strideWidth - padLeft;\n              let xColMin = xColCorner;\n              while (xColMin < 0) {\n                xColMin += dilationWidth;\n              }\n              const xColMax =\n                  Math.min(convInfo.inWidth, effectiveFilterWidth + xColCorner);\n\n              // Shader code begins\n              let maxValue = Number.NEGATIVE_INFINITY;\n              let maxPosition = -1;\n\n              for (let xDepth = xDepthMin; xDepth < xDepthMax;\n                   xDepth += dilationDepth) {\n                const wDepth = xDepth - xDepthCorner;\n                for (let xRow = xRowMin; xRow < xRowMax;\n                     xRow += dilationHeight) {\n                  const wRow = xRow - xRowCorner;\n                  for (let xCol = xColMin; xCol < xColMax;\n                       xCol += dilationWidth) {\n                    const wCol = xCol - xColCorner;\n                    const pixel = xBuf.get(batch, xDepth, xRow, xCol, channel);\n                    if (pixel >= maxValue) {\n                      maxValue = pixel;\n                      maxPosition = wDepth * effectiveFilterHeight *\n                              effectiveFilterWidth +\n                          wRow * effectiveFilterHeight + wCol;\n                    }\n                  }\n                }\n              }\n\n              maxPositions.set(maxPosition, batch, yDepth, yRow, yCol, channel);\n            }\n          }\n        }\n      }\n    }\n    return maxPositions.toTensor() as Tensor5D;\n  }\n\n  maxPool3dBackprop(\n      dy: Tensor5D, x: Tensor5D, y: Tensor5D,\n      convInfo: backend_util.Conv3DInfo): Tensor5D {\n    assertNotComplex([x, y], 'maxPool3dBackprop');\n\n    const maxPositions = this.maxPool3dPositions(x, convInfo);\n    const strideDepth = convInfo.strideDepth;\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const dilationDepth = convInfo.dilationDepth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const effectiveFilterDepth = convInfo.effectiveFilterDepth;\n    const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n    const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n    const padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;\n    const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n    const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n    const dx = tf.buffer<Rank.R5>(x.shape, 'float32');\n\n    const maxPosBuf = this.bufferSync(maxPositions);\n    const dyBuf = this.bufferSync(dy);\n\n    for (let batch = 0; batch < convInfo.batchSize; ++batch) {\n      for (let channel = 0; channel < convInfo.inChannels; ++channel) {\n        for (let dxDepth = 0; dxDepth < convInfo.inDepth; ++dxDepth) {\n          for (let dxRow = 0; dxRow < convInfo.inHeight; ++dxRow) {\n            for (let dxCol = 0; dxCol < convInfo.inWidth; ++dxCol) {\n              // Shader code begins\n              const dyDepthCorner = dxDepth - padFront;\n              const dyRowCorner = dxRow - padTop;\n              const dyColCorner = dxCol - padLeft;\n              let dotProd = 0;\n              for (let wDepth = 0; wDepth < effectiveFilterDepth;\n                   wDepth += dilationDepth) {\n                const dyDepth = (dyDepthCorner + wDepth) / strideDepth;\n                if (dyDepth < 0 || dyDepth >= convInfo.outDepth ||\n                    Math.floor(dyDepth) !== dyDepth) {\n                  continue;\n                }\n                for (let wRow = 0; wRow < effectiveFilterHeight;\n                     wRow += dilationHeight) {\n                  const dyRow = (dyRowCorner + wRow) / strideHeight;\n                  if (dyRow < 0 || dyRow >= convInfo.outHeight ||\n                      Math.floor(dyRow) !== dyRow) {\n                    continue;\n                  }\n                  for (let wCol = 0; wCol < effectiveFilterWidth;\n                       wCol += dilationWidth) {\n                    const dyCol = (dyColCorner + wCol) / strideWidth;\n                    if (dyCol < 0 || dyCol >= convInfo.outWidth ||\n                        Math.floor(dyCol) !== dyCol) {\n                      continue;\n                    }\n\n                    const maxPos = effectiveFilterDepth *\n                            effectiveFilterHeight * effectiveFilterWidth -\n                        1 -\n                        maxPosBuf.get(batch, dyDepth, dyRow, dyCol, channel);\n                    const curPos =\n                        wDepth * effectiveFilterHeight * effectiveFilterWidth +\n                        wRow * effectiveFilterWidth + wCol;\n\n                    const mask = maxPos === curPos ? 1 : 0;\n                    if (mask === 0) {\n                      continue;\n                    }\n\n                    const pixel =\n                        dyBuf.get(batch, dyDepth, dyRow, dyCol, channel);\n                    dotProd += pixel * mask;\n                  }\n                }\n              }\n              dx.set(dotProd, batch, dxDepth, dxRow, dxCol, channel);\n            }\n          }\n        }\n      }\n    }\n    return dx.toTensor();\n  }\n\n  cast<T extends Tensor>(x: T, dtype: DataType): T {\n    return backend_util.castTensor(x, dtype, this);\n  }\n\n  reshape<R extends Rank>(x: Tensor, shape: ShapeMap[R]): Tensor<R> {\n    return backend_util.reshapeTensor(x, shape);\n  }\n\n  avgPool(x: Tensor4D, convInfo: backend_util.Conv2DInfo): Tensor4D {\n    assertNotComplex(x, 'avgPool');\n    assertNotComplex(x, 'maxPool');\n    const xValues = this.readSync(x.dataId) as TypedArray;\n    return pool(xValues, x.shape, x.dtype, x.strides, convInfo, 'avg')\n               .toTensor()\n               .toFloat() as Tensor4D;\n  }\n\n  resizeBilinear(\n      x: Tensor4D, newHeight: number, newWidth: number,\n      alignCorners: boolean): Tensor4D {\n    assertNotComplex(x, 'resizeBilinear');\n\n    const [batch, oldHeight, oldWidth, numChannels] = x.shape;\n    const xValues = this.readSync(x.dataId) as TypedArray;\n    const result = new Float32Array(\n        util.sizeFromShape([batch, newHeight, newWidth, numChannels]));\n\n    const effectiveInputSize: [number, number] = [\n      (alignCorners && newHeight > 1) ? oldHeight - 1 : oldHeight,\n      (alignCorners && newWidth > 1) ? oldWidth - 1 : oldWidth\n    ];\n\n    const effectiveOutputSize: [number, number] = [\n      (alignCorners && newHeight > 1) ? newHeight - 1 : newHeight,\n      (alignCorners && newWidth > 1) ? newWidth - 1 : newWidth\n    ];\n    let outputIdx = 0;\n    const effectiveRowSizeRatio =\n        effectiveInputSize[0] / effectiveOutputSize[0];\n    const effectiveColSizeRatio =\n        effectiveInputSize[1] / effectiveOutputSize[1];\n    for (let b = 0; b < batch; b++) {\n      for (let r = 0; r < newHeight; r++) {\n        const sourceFracRow = effectiveRowSizeRatio * r;\n        const sourceRowFloor = Math.floor(sourceFracRow);\n        const rowFrac = sourceFracRow - sourceRowFloor;\n        const sourceRowCeil = Math.min(oldHeight - 1, Math.ceil(sourceFracRow));\n        const topRowOffset = b * x.strides[0] + sourceRowFloor * x.strides[1];\n        const botRowOffset = b * x.strides[0] + sourceRowCeil * x.strides[1];\n        for (let c = 0; c < newWidth; c++) {\n          const sourceFracCol = effectiveColSizeRatio * c;\n          const sourceColFloor = Math.floor(sourceFracCol);\n          const colFrac = sourceFracCol - sourceColFloor;\n          const sourceColCeil =\n              Math.min(oldWidth - 1, Math.ceil(sourceFracCol));\n          const topLeftOffest = topRowOffset + sourceColFloor * x.strides[2];\n          const botLeftOffset = botRowOffset + sourceColFloor * x.strides[2];\n          const topRightOffset = topRowOffset + sourceColCeil * x.strides[2];\n          const botRightOffest = botRowOffset + sourceColCeil * x.strides[2];\n          for (let d = 0; d < numChannels; d++) {\n            // Begin shader.\n\n            // Compute the fractional index of the source.\n            const topLeft = xValues[topLeftOffest + d];\n            const bottomLeft = xValues[botLeftOffset + d];\n            const topRight = xValues[topRightOffset + d];\n            const bottomRight = xValues[botRightOffest + d];\n\n            const top = topLeft + (topRight - topLeft) * colFrac;\n            const bottom = bottomLeft + (bottomRight - bottomLeft) * colFrac;\n            const newValue = top + (bottom - top) * rowFrac;\n\n            result[outputIdx++] = newValue;\n          }\n        }\n      }\n    }\n    return tf.tensor(result, [batch, newHeight, newWidth, numChannels]);\n  }\n\n  resizeBilinearBackprop(dy: Tensor4D, x: Tensor4D, alignCorners: boolean) {\n    assertNotComplex([dy, x], 'resizeBilinearBackprop');\n\n    const [batch, xHeight, xWidth, depth] = x.shape;\n    const [, yHeight, yWidth] = dy.shape;\n\n    const output = new Float32Array(batch * xHeight * xWidth * depth);\n\n    // In the backwards pass, we want to find the pixels that were generated\n    // for each pixel in the input image the forward pass and add the\n    // corresponding coefficient from dy to the gradient (with some\n    // interpolation).\n\n    const effectiveXSize: [number, number] = [\n      (alignCorners && yHeight > 1) ? xHeight - 1 : xHeight,\n      (alignCorners && yWidth > 1) ? xWidth - 1 : xWidth\n    ];\n\n    const effectiveYSize: [number, number] = [\n      (alignCorners && yHeight > 1) ? yHeight - 1 : yHeight,\n      (alignCorners && yWidth > 1) ? yWidth - 1 : yWidth\n    ];\n\n    const heightScale = effectiveXSize[0] / effectiveYSize[0];\n    const widthScale = effectiveXSize[1] / effectiveYSize[1];\n\n    // Reference implementation\n    // tslint:disable-next-line:max-line-length\n    // https://github.com/tensorflow/tensorflow/blob/3039375c86a5bbc9610c7725dcaa95d635f87ba2/tensorflow/core/kernels/resize_bilinear_op.cc#L275\n\n    const dyValues = this.readSync(dy.dataId) as TypedArray;\n    let offset = 0;\n    for (let b = 0; b < batch; b++) {\n      const bOffset = b * x.strides[0];\n      for (let r = 0; r < yHeight; r++) {\n        const dxR = r * heightScale;\n        const topDxRIndex = Math.floor(dxR);\n        const bottomDxRIndex = Math.min(Math.ceil(dxR), xHeight - 1);\n\n        const topDxROffset = bOffset + topDxRIndex * x.strides[1];\n        const bottomDxROffset = bOffset + bottomDxRIndex * x.strides[1];\n\n        const dxRLerp = dxR - topDxRIndex;\n        const inverseDxRLerp = 1.0 - dxRLerp;\n        for (let c = 0; c < yWidth; c++) {\n          const dxC = c * widthScale;\n          const leftDxCIndex = Math.floor(dxC);\n          const rightDxCIndex = Math.min(Math.ceil(dxC), xWidth - 1);\n          const dxCLerp = dxC - leftDxCIndex;\n          const inverseDxCLerp = 1.0 - dxCLerp;\n\n          const topLeftRCOffset = topDxROffset + leftDxCIndex * x.strides[2];\n          const topRightRCOffset = topDxROffset + rightDxCIndex * x.strides[2];\n          const bottomLeftRCOffset =\n              bottomDxROffset + leftDxCIndex * x.strides[2];\n          const bottomRightRCOffset =\n              bottomDxROffset + rightDxCIndex * x.strides[2];\n\n          const inverseDxRLerpTimesInverseDxCLerp =\n              inverseDxRLerp * inverseDxCLerp;\n          const inverseDxRLerpTimesDxCLerp = inverseDxRLerp * dxCLerp;\n          const dxRLerpTimesInverseDxCLerp = dxRLerp * inverseDxCLerp;\n          const dxRLerpTimesDxCLerp = dxRLerp * dxCLerp;\n          for (let d = 0; d < depth; d++) {\n            const dyVal = dyValues[offset++];\n            output[topLeftRCOffset + d] +=\n                dyVal * inverseDxRLerpTimesInverseDxCLerp;\n            output[topRightRCOffset + d] += dyVal * inverseDxRLerpTimesDxCLerp;\n            output[bottomLeftRCOffset + d] +=\n                dyVal * dxRLerpTimesInverseDxCLerp;\n            output[bottomRightRCOffset + d] += dyVal * dxRLerpTimesDxCLerp;\n          }\n        }\n      }\n    }\n    return tf.tensor4d(output, [batch, xWidth, xHeight, depth], x.dtype);\n  }\n\n  resizeNearestNeighbor(\n      x: Tensor4D, newHeight: number, newWidth: number,\n      alignCorners: boolean): Tensor4D {\n    assertNotComplex(x, 'resizeNearestNeighbor');\n\n    const [batch, oldHeight, oldWidth, numChannels] = x.shape;\n    const xValues = this.readSync(x.dataId) as TypedArray;\n    const output = new Float32Array(batch * newHeight * newWidth * numChannels);\n\n    const effectiveInputSize: [number, number] = [\n      (alignCorners && newHeight > 1) ? oldHeight - 1 : oldHeight,\n      (alignCorners && newWidth > 1) ? oldWidth - 1 : oldWidth\n    ];\n\n    const effectiveOutputSize: [number, number] = [\n      (alignCorners && newHeight > 1) ? newHeight - 1 : newHeight,\n      (alignCorners && newWidth > 1) ? newWidth - 1 : newWidth\n    ];\n\n    const effectiveRowSizeRatio =\n        effectiveInputSize[0] / effectiveOutputSize[0];\n    const effectiveColSizeRatio =\n        effectiveInputSize[1] / effectiveOutputSize[1];\n\n    let outputOffset = 0;\n    for (let b = 0; b < batch; b++) {\n      const batchOffset = b * x.strides[0];\n      for (let r = 0; r < newHeight; r++) {\n        const sourceFracRow = effectiveRowSizeRatio * r;\n        const sourceNearestRow = Math.min(\n            oldHeight - 1,\n            alignCorners ? Math.round(sourceFracRow) :\n                           Math.floor(sourceFracRow));\n        const rowOffset = batchOffset + sourceNearestRow * x.strides[1];\n        for (let c = 0; c < newWidth; c++) {\n          const sourceFracCol = effectiveColSizeRatio * c;\n          const sourceNearestCol = Math.min(\n              oldWidth - 1,\n              alignCorners ? Math.round(sourceFracCol) :\n                             Math.floor(sourceFracCol));\n          const colOffset = rowOffset + sourceNearestCol * x.strides[2];\n          for (let d = 0; d < numChannels; d++) {\n            // Begin shader.\n            // Compute the fractional index of the source.\n            const newVal = xValues[colOffset + d];\n            output[outputOffset++] = newVal;\n          }\n        }\n      }\n    }\n    return tf.tensor(\n        output, [batch, newHeight, newWidth, numChannels], x.dtype);\n  }\n\n  resizeNearestNeighborBackprop(\n      dy: Tensor4D, x: Tensor4D, alignCorners: boolean) {\n    assertNotComplex([dy, x], 'resizeNearestNeighborBackprop');\n\n    const [batch, xHeight, xWidth, depth] = x.shape;\n    const [, yHeight, yWidth] = dy.shape;\n\n    const output = new Float32Array(batch * xHeight * xWidth * depth);\n    const dyValues = this.readSync(dy.dataId) as TypedArray;\n\n    // In the backwards pass, we want to find the pixels that were generated\n    // for each pixel in the input image the forward pass\n\n    const effectiveXSize: [number, number] = [\n      (alignCorners && yHeight > 1) ? xHeight - 1 : xHeight,\n      (alignCorners && yWidth > 1) ? xWidth - 1 : xWidth\n    ];\n\n    const effectiveYSize: [number, number] = [\n      (alignCorners && yHeight > 1) ? yHeight - 1 : yHeight,\n      (alignCorners && yWidth > 1) ? yWidth - 1 : yWidth\n    ];\n\n    const heightScale = effectiveXSize[0] / effectiveYSize[0];\n    const widthScale = effectiveXSize[1] / effectiveYSize[1];\n\n    const invHeightScale = 1 / heightScale;\n    const invWidthScale = 1 / widthScale;\n\n    // This defines the size of the window of values around a particular\n    // index in dy that we want to search for contributions to dx.\n    const winHeight = (Math.ceil(invHeightScale) * 2) + 2;\n    const winWidth = (Math.ceil(invWidthScale) * 2) + 2;\n\n    // Loop over the output space.\n    for (let b = 0; b < batch; b++) {\n      const batchOffset = b * x.strides[0];\n      for (let r = 0; r < xHeight; r++) {\n        const rowOffset = batchOffset + r * x.strides[1];\n\n        // Compute bounds for where in dy we will look\n        const startRLerp = Math.floor(r * invHeightScale);\n        const startDyR = Math.floor(startRLerp - (winHeight / 2));\n        for (let c = 0; c < xWidth; c++) {\n          const colOffset = rowOffset + c * x.strides[2];\n\n          // Compute bounds for where in dy we will look\n          const startCLerp = Math.floor(c * invWidthScale);\n          const startDyC = Math.floor(startCLerp - (winWidth / 2));\n\n          for (let d = 0; d < depth; d++) {\n            let accum = 0;\n            // loop over dy\n\n            for (let dyRIndex = 0; dyRIndex < winHeight; dyRIndex++) {\n              const dyR = dyRIndex + startDyR;\n              // Guard against the window exceeding the bounds of dy\n              if (dyR < 0 || dyR >= yHeight) {\n                continue;\n              }\n\n              const dyROffset = batchOffset + dyR * dy.strides[1];\n              const sourceFracRow = dyR * heightScale;\n              const sourceNearestRow = Math.min(\n                  xHeight - 1,\n                  alignCorners ? Math.round(sourceFracRow) :\n                                 Math.floor(sourceFracRow));\n              if (r !== sourceNearestRow) {\n                continue;\n              }\n              for (let dyCIndex = 0; dyCIndex < winWidth; dyCIndex++) {\n                const dyC = dyCIndex + startDyC;\n                // Guard against the window exceeding the bounds of dy\n                if (dyC < 0 || dyC >= yWidth) {\n                  continue;\n                }\n\n                const dyCOffset = dyROffset + dyC * dy.strides[2];\n                const sourceFracCol = dyC * widthScale;\n                const sourceNearestCol = Math.min(\n                    xWidth - 1,\n                    alignCorners ? Math.round(sourceFracCol) :\n                                   Math.floor(sourceFracCol));\n\n                if (c === sourceNearestCol) {\n                  accum += dyValues[dyCOffset + d];\n                }\n              }\n            }\n            output[colOffset + d] = accum;\n          }\n        }\n      }\n    }\n    return tf.tensor4d(output, x.shape, x.dtype);\n  }\n\n  batchNorm(\n      x: Tensor4D, mean: Tensor4D|Tensor1D, variance: Tensor4D|Tensor1D,\n      offset?: Tensor4D|Tensor1D, scale?: Tensor4D|Tensor1D,\n      varianceEpsilon?: number): Tensor4D {\n    assertNotComplex([x, mean, variance, scale, offset], 'batchNorm');\n\n    const xVals = this.readSync(x.dataId) as TypedArray;\n    const mVals = this.readSync(mean.dataId) as TypedArray;\n    const varVals = this.readSync(variance.dataId) as TypedArray;\n    const sVals = scale ? this.readSync(scale.dataId) as TypedArray :\n                          new Float32Array([1]);\n    const offVals = offset ? this.readSync(offset.dataId) as TypedArray :\n                             new Float32Array([0]);\n    const outVals = new Float32Array(xVals.length);\n\n    const offValsLength = offVals.length;\n    const sValsLength = sVals.length;\n    const varValsLength = varVals.length;\n    const mValsLength = mVals.length;\n\n    let offi = 0;\n    let mi = 0;\n    let si = 0;\n    let vi = 0;\n    for (let i = 0; i < xVals.length; ++i) {\n      outVals[i] = offVals[offi++] +\n          (xVals[i] - mVals[mi++]) * sVals[si++] /\n              Math.sqrt(varVals[vi++] + varianceEpsilon);\n      if (offi >= offValsLength) {\n        offi = 0;\n      }\n      if (mi >= mValsLength) {\n        mi = 0;\n      }\n      if (si >= sValsLength) {\n        si = 0;\n      }\n      if (vi >= varValsLength) {\n        vi = 0;\n      }\n    }\n    return tf.tensor4d(outVals, x.shape);\n  }\n\n  localResponseNormalization4D(\n      x: Tensor4D, depthRadius: number, bias: number, alpha: number,\n      beta: number): Tensor4D {\n    assertNotComplex(x, 'localResponseNormalization4D');\n\n    const channels = x.shape[3];\n    const maxD = channels - 1;\n    const xValues = this.readSync(x.dataId) as TypedArray;\n    const size = x.size;\n    const result = new Float32Array(size);\n\n    function sumAcrossChannels(offset: number) {\n      const currentChannel = offset % channels;\n      let beginSumOffset =\n          offset - currentChannel + Math.max(0, currentChannel - depthRadius);\n      const endSumOffset = offset - currentChannel +\n          Math.min(currentChannel + depthRadius, maxD);\n\n      let sum = 0.0;\n      for (; beginSumOffset <= endSumOffset; beginSumOffset++) {\n        const z = xValues[beginSumOffset];\n        sum += z * z;\n      }\n      return sum;\n    }\n\n    for (let offset = 0; offset < size; offset++) {\n      const sum = sumAcrossChannels(offset);\n      const val = xValues[offset] * Math.pow(bias + alpha * sum, -beta);\n      result[offset] = val;\n    }\n\n    return tf.tensor4d(result, x.shape);\n  }\n\n  LRNGrad(\n      dy: Tensor4D, inputImage: Tensor4D, outputImage: Tensor4D,\n      depthRadius: number, bias: number, alpha: number,\n      beta: number): Tensor4D {\n    assertNotComplex(dy, 'LRNGrad');\n    const channels = dy.shape[3];\n    const dyValues = this.readSync(dy.dataId) as TypedArray;\n    const inputImageValues = this.readSync(inputImage.dataId) as TypedArray;\n    const outputImageValues = this.readSync(outputImage.dataId) as TypedArray;\n    const result = new Float32Array(dy.size);\n    const size = dy.size;\n\n    for (let offset = 0; offset < size; offset++) {\n      const currentChannel = offset % channels;\n      const depthBegin =\n          (offset - currentChannel) + Math.max(0, currentChannel - depthRadius);\n      const depthEnd = (offset - currentChannel) +\n          Math.min(channels, currentChannel + depthRadius + 1);\n\n      let norm = 0;\n      for (let k = depthBegin; k < depthEnd; k++) {\n        norm += Math.pow(inputImageValues[k], 2);\n      }\n      norm = alpha * norm + bias;\n\n      for (let k = depthBegin; k < depthEnd; k++) {\n        let dyi = -2 * alpha * beta * inputImageValues[k] *\n            outputImageValues[offset] / norm;\n        if (offset === k) {\n          dyi += Math.pow(norm, -beta);\n        }\n        dyi *= dyValues[offset];\n        result[k] += dyi;\n      }\n    }\n    return tf.tensor4d(result, dy.shape);\n  }\n\n  multinomial(\n      logits: Tensor2D, normalized: boolean, numSamples: number,\n      seed: number): Tensor2D {\n    assertNotComplex(logits, 'multinomial');\n\n    const probabilities = normalized ? logits : tf.softmax(logits);\n    const batchSize = probabilities.shape[0];\n    const numEvents = probabilities.shape[1];\n    const res = tf.zeros<Rank.R2>([batchSize, numSamples], 'int32');\n    const resVals = this.readSync(res.dataId) as TypedArray;\n    const probVals = this.readSync(probabilities.dataId) as TypedArray;\n\n    for (let b = 0; b < batchSize; ++b) {\n      const offset = b * numEvents;\n      // The cdf won't include the last event. It will be implicit if no other\n      // event happened.\n      const cdf = new Float32Array(numEvents - 1);\n      cdf[0] = probVals[offset];\n      for (let event = 1; event < cdf.length; ++event) {\n        cdf[event] = cdf[event - 1] + probVals[offset + event];\n      }\n\n      const random = seedrandom.alea(seed.toString());\n      const outOffset = b * numSamples;\n      for (let sampleId = 0; sampleId < numSamples; ++sampleId) {\n        const r = random();\n\n        // Assume last event happened by default.\n        resVals[outOffset + sampleId] = cdf.length;\n\n        for (let event = 0; event < cdf.length; event++) {\n          if (r < cdf[event]) {\n            resVals[outOffset + sampleId] = event;\n            break;\n          }\n        }\n      }\n    }\n    return res;\n  }\n\n  oneHot(indices: Tensor1D, depth: number, onValue: number, offValue: number):\n      Tensor2D {\n    assertNotComplex(indices, 'oneHot');\n\n    const res = new Float32Array(indices.size * depth);\n    res.fill(offValue);\n    const indicesVal = this.readSync(indices.dataId) as TypedArray;\n\n    for (let event = 0; event < indices.size; ++event) {\n      if (indicesVal[event] >= 0 && indicesVal[event] < depth) {\n        res[event * depth + indicesVal[event]] = onValue;\n      }\n    }\n    return tf.tensor2d(res, [indices.size, depth], 'int32');\n  }\n\n  nonMaxSuppression(\n      boxes: Tensor2D, scores: Tensor1D, maxOutputSize: number,\n      iouThreshold: number, scoreThreshold: number): Tensor1D {\n    assertNotComplex(boxes, 'nonMaxSuppression');\n\n    const boxesVals = this.readSync(boxes.dataId) as TypedArray;\n    const scoresVals = this.readSync(scores.dataId) as TypedArray;\n    return nonMaxSuppressionV3(\n        boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold);\n  }\n\n  fft(x: Tensor2D): Tensor2D {\n    return this.fftBatch(x, false);\n  }\n\n  ifft(x: Tensor2D): Tensor2D {\n    return this.fftBatch(x, true);\n  }\n\n  /**\n   * Calculate FFT of inner most elements of batch tensor.\n   */\n  private fftBatch(x: Tensor2D, inverse: boolean): Tensor2D {\n    const batch = x.shape[0];\n    const innerDim = x.shape[1];\n    // Collects real and imaginary values separately.\n    const realResult = tf.buffer(x.shape, 'float32');\n    const imagResult = tf.buffer(x.shape, 'float32');\n\n    const real = tf.real(x).as2D(batch, innerDim);\n    const imag = tf.imag(x).as2D(batch, innerDim);\n\n    for (let b = 0; b < batch; b++) {\n      // TODO: Support slice ops for complex type.\n      const r = real.slice([b, 0], [1, innerDim]);\n      const i = imag.slice([b, 0], [1, innerDim]);\n      const input = tf.complex(r, i);\n      // Run FFT by batch element.\n      const res =\n          this.readSync(this.fftImpl(input, inverse).dataId) as Float32Array;\n      for (let d = 0; d < innerDim; d++) {\n        const c = backend_util.getComplexWithIndex(res, d);\n        realResult.values[b * innerDim + d] = c.real;\n        imagResult.values[b * innerDim + d] = c.imag;\n      }\n    }\n\n    const t = tf.complex(realResult.toTensor(), imagResult.toTensor());\n    return t.as2D(batch, innerDim);\n  }\n\n  private fftImpl(x: Tensor2D, inverse: boolean): Tensor2D {\n    const x1D = x.as1D();\n\n    const n = x1D.size;\n\n    if (this.isExponentOf2(n)) {\n      let result = this.fftRadix2(x1D, n, inverse).as2D(x.shape[0], x.shape[1]);\n      if (inverse) {\n        result = tf.complex(\n                     tf.real(result).div(tf.scalar(n)),\n                     tf.imag(result).div(tf.scalar(n))) as Tensor2D;\n      }\n      return result;\n    } else {\n      const data = this.readSync(x.dataId) as TypedArray;\n      const rawOutput =\n          this.fourierTransformByMatmul(data, n, inverse) as Float32Array;\n      const output = backend_util.splitRealAndImagArrays(rawOutput);\n      return tf.complex(output.real, output.imag).as2D(x.shape[0], x.shape[1]);\n    }\n  }\n\n  private isExponentOf2(size: number): boolean {\n    return (size & size - 1) === 0;\n  }\n\n  // FFT using Cooley-Tukey algorithm on radix 2 dimensional input.\n  private fftRadix2(input: Tensor1D, size: number, inverse: boolean): Tensor1D {\n    if (size === 1) {\n      return input;\n    }\n    const data = this.readSync(input.dataId) as TypedArray as Float32Array;\n    const half = size / 2;\n    const evenComplex = backend_util.complexWithEvenIndex(data);\n    let evenTensor = tf.complex(evenComplex.real, evenComplex.imag).as1D();\n    const oddComplex = backend_util.complexWithOddIndex(data);\n    let oddTensor = tf.complex(oddComplex.real, oddComplex.imag).as1D();\n\n    // Recursive call for half part of original input.\n    evenTensor = this.fftRadix2(evenTensor, half, inverse);\n    oddTensor = this.fftRadix2(oddTensor, half, inverse);\n\n    const e = backend_util.exponents(size, inverse);\n    const exponent = tf.complex(e.real, e.imag).mul(oddTensor);\n\n    const addPart = evenTensor.add(exponent);\n    const subPart = evenTensor.sub(exponent);\n\n    const realTensor = tf.real(addPart).concat(tf.real(subPart));\n    const imagTensor = tf.imag(addPart).concat(tf.imag(subPart));\n\n    return tf.complex(realTensor, imagTensor).as1D();\n  }\n\n  // Calculate fourier transform by multplying sinusoid matrix.\n  private fourierTransformByMatmul(\n      data: TypedArray, size: number, inverse: boolean): TypedArray {\n    const ret = new Float32Array(size * 2);\n    // TODO: Use matmul instead once it supports complex64 type.\n    for (let r = 0; r < size; r++) {\n      let real = 0.0;\n      let imag = 0.0;\n      for (let c = 0; c < size; c++) {\n        const e = backend_util.exponent(r * c, size, inverse);\n        const term = backend_util.getComplexWithIndex(data as Float32Array, c);\n        real += term.real * e.real - term.imag * e.imag;\n        imag += term.real * e.imag + term.imag * e.real;\n      }\n      if (inverse) {\n        real /= size;\n        imag /= size;\n      }\n      backend_util.assignToTypedArray(ret, real, imag, r);\n    }\n    return ret;\n  }\n\n  depthToSpace(x: Tensor4D, blockSize: number, dataFormat: 'NHWC'|'NCHW'):\n      Tensor4D {\n    util.assert(\n        dataFormat === 'NHWC',\n        () => `Only NHWC dataFormat supported on CPU for depthToSpace. Got ${\n            dataFormat}`);\n    util.assert(\n        blockSize > 1,\n        () =>\n            `blockSize should be > 1 for depthToSpace, but was: ${blockSize}`);\n\n    const batchSize = x.shape[0];\n    const inputHeight = x.shape[1];\n    const inputWidth = x.shape[2];\n    const inputDepth = x.shape[3];\n\n    const outputHeight = inputHeight * blockSize;\n    const outputWidth = inputWidth * blockSize;\n    const outputDepth = inputDepth / (blockSize * blockSize);\n\n    const xValues = this.readSync(x.dataId) as TypedArray;\n    const result =\n        new Float32Array(batchSize * outputHeight * outputWidth * outputDepth);\n\n    let outputIdx = 0;\n    for (let b = 0; b < batchSize; ++b) {\n      for (let h = 0; h < outputHeight; ++h) {\n        const inH = Math.floor(h / blockSize);\n        const offsetH = (h % blockSize);\n        for (let w = 0; w < outputWidth; ++w) {\n          const inW = Math.floor(w / blockSize);\n          const offsetW = (w % blockSize);\n          const offsetD = (offsetH * blockSize + offsetW) * outputDepth;\n          for (let d = 0; d < outputDepth; ++d) {\n            const inD = d + offsetD;\n            const inputIdx =\n                inD + inputDepth * (inW + inputWidth * (inH + inputHeight * b));\n            result[outputIdx++] = xValues[inputIdx];\n          }\n        }\n      }\n    }\n    return tf.tensor4d(\n        result, [batchSize, outputHeight, outputWidth, outputDepth]);\n  }\n\n  private broadcastedBinaryOp(\n      a: Tensor, b: Tensor, dtype: DataType,\n      op: (a: number, b: number) => number): Tensor {\n    const newShape = backend_util.assertAndGetBroadcastShape(a.shape, b.shape);\n    const result = tf.buffer(newShape, dtype);\n    const aVals = this.readSync(a.dataId) as TypedArray;\n    const bVals = this.readSync(b.dataId) as TypedArray;\n    const aBroadcastDims = backend_util.getBroadcastDims(a.shape, newShape);\n    const bBroadcastDims = backend_util.getBroadcastDims(b.shape, newShape);\n\n    const resVals = result.values;\n    if (aBroadcastDims.length + bBroadcastDims.length === 0) {\n      for (let i = 0; i < resVals.length; ++i) {\n        resVals[i] = op(aVals[i % aVals.length], bVals[i % bVals.length]);\n      }\n    } else {\n      const aBuf = this.bufferSync(a);\n      const bBuf = this.bufferSync(b);\n      for (let i = 0; i < resVals.length; ++i) {\n        const loc = result.indexToLoc(i);\n\n        const aLoc = loc.slice(-a.rank);\n        aBroadcastDims.forEach(d => aLoc[d] = 0);\n        const aIndex = aBuf.locToIndex(aLoc);\n\n        const bLoc = loc.slice(-b.rank);\n        bBroadcastDims.forEach(d => bLoc[d] = 0);\n        const bIndex = bBuf.locToIndex(bLoc);\n\n        resVals[i] = op(aVals[aIndex], bVals[bIndex]);\n      }\n    }\n    return result.toTensor();\n  }\n\n  private broadcastedBinaryComplexOp(\n      a: Tensor, b: Tensor,\n      op:\n          (aReal: number, aImag: number, bReal: number,\n           bImag: number) => {real: number, imag: number}): Tensor {\n    const newShape = backend_util.assertAndGetBroadcastShape(a.shape, b.shape);\n    const realResult = tf.buffer(newShape, 'float32');\n    const imagResult = tf.buffer(newShape, 'float32');\n\n    const aVals = this.readSync(a.dataId) as TypedArray;\n    const bVals = this.readSync(b.dataId) as TypedArray;\n    const aBroadcastDims = backend_util.getBroadcastDims(a.shape, newShape);\n    const bBroadcastDims = backend_util.getBroadcastDims(b.shape, newShape);\n\n    const realVals = realResult.values;\n    const imagVals = imagResult.values;\n\n    if (aBroadcastDims.length + bBroadcastDims.length === 0) {\n      for (let i = 0; i < realVals.length; i++) {\n        const aIdx = i % aVals.length;\n        const bIdx = i % bVals.length;\n\n        const result =\n            op(aVals[aIdx * 2], aVals[aIdx * 2 + 1], bVals[bIdx * 2],\n               bVals[bIdx * 2 + 1]);\n\n        realVals[i] = result.real;\n        imagVals[i] = result.imag;\n      }\n    } else {\n      const aRealBuf =\n          this.bufferSync(this.data.get(a.dataId).complexTensors.real);\n      const bRealBuf =\n          this.bufferSync(this.data.get(b.dataId).complexTensors.real);\n      for (let i = 0; i < realVals.length; i++) {\n        const loc = realResult.indexToLoc(i);\n\n        const aLoc = loc.slice(-a.rank);\n        aBroadcastDims.forEach(d => aLoc[d] = 0);\n        const aIndex = aRealBuf.locToIndex(aLoc);\n\n        const bLoc = loc.slice(-b.rank);\n        bBroadcastDims.forEach(d => bLoc[d] = 0);\n        const bIndex = bRealBuf.locToIndex(bLoc);\n\n        const opResult =\n            op(aVals[aIndex * 2], aVals[aIndex * 2 + 1], bVals[bIndex * 2],\n               bVals[bIndex * 2 + 1]);\n\n        realVals[i] = opResult.real;\n        imagVals[i] = opResult.imag;\n      }\n    }\n    return this.complex(realResult.toTensor(), imagResult.toTensor());\n  }\n\n  split<T extends Tensor>(x: T, sizeSplits: number[], axis: number): T[] {\n    return split(x, sizeSplits, axis);\n  }\n\n  dispose() {}\n\n  floatPrecision(): 16|32 {\n    return 32;\n  }\n\n  /** Returns the smallest representable number.  */\n  epsilon(): number {\n    return super.epsilon();\n  }\n\n  cropAndResize(\n      images: Tensor4D,\n      boxes: Tensor2D,\n      boxIndex: Tensor1D,\n      cropSize: [number, number],\n      method: string,\n      extrapolationValue: number,\n  ) {\n    const [batch, imageHeight, imageWidth, numChannels] = images.shape;\n    const numBoxes = boxes.shape[0];\n\n    const [cropHeight, cropWidth] = cropSize;\n    const output =\n        tf.buffer([numBoxes, cropHeight, cropWidth, numChannels], 'float32');\n\n    const boxVals = this.readSync(boxes.dataId) as TypedArray;\n    const boxIndVals = this.readSync(boxIndex.dataId) as TypedArray;\n    const imageVals = this.readSync(images.dataId) as TypedArray;\n\n    const inStride = images.strides;   // to calculate flat indexes into image\n    const outStride = output.strides;  // to calculate flat indexes into output\n\n    // Reference implementation\n    // tslint:disable-next-line:max-line-length\n    // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/crop_and_resize_op.cc\n    for (let b = 0; b < numBoxes; b++) {\n      const startInd = b * 4;\n      const y1 = boxVals[startInd];\n      const x1 = boxVals[startInd + 1];\n      const y2 = boxVals[startInd + 2];\n      const x2 = boxVals[startInd + 3];\n\n      const bInd: number = boxIndVals[b];\n      if (bInd >= batch) {\n        continue;\n      }\n\n      const heightScale = (cropHeight > 1) ?\n          (y2 - y1) * (imageHeight - 1) / (cropHeight - 1) :\n          0;\n      const widthScale =\n          (cropWidth > 1) ? (x2 - x1) * (imageWidth - 1) / (cropWidth - 1) : 0;\n\n      for (let y = 0; y < cropHeight; y++) {\n        const yInd: number = (cropHeight > 1) ?\n            y1 * (imageHeight - 1) + y * (heightScale) :\n            0.5 * (y1 + y2) * (imageHeight - 1);\n\n        if (yInd < 0 || yInd > imageHeight - 1) {\n          for (let x = 0; x < cropWidth; x++) {\n            for (let c = 0; c < numChannels; c++) {\n              const ind =\n                  c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n              output.values[ind] = extrapolationValue;\n            }\n          }\n          continue;\n        }\n\n        if (method === 'bilinear') {\n          const topInd = Math.floor(yInd);\n          const bottomInd = Math.ceil(yInd);\n          const yLerp = yInd - topInd;\n\n          for (let x = 0; x < cropWidth; x++) {\n            const xInd = (cropWidth > 1) ?\n                x1 * (imageWidth - 1) + x * widthScale :\n                0.5 * (x1 + x2) * (imageWidth - 1);\n\n            if (xInd < 0 || xInd > imageWidth - 1) {\n              for (let c = 0; c < numChannels; c++) {\n                const ind =\n                    c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n                output.values[ind] = extrapolationValue;\n              }\n              continue;\n            }\n\n            const leftInd = Math.floor(xInd);\n            const rightInd = Math.ceil(xInd);\n            const xLerp = xInd - leftInd;\n\n            for (let c = 0; c < numChannels; c++) {\n              let ind = c + leftInd * inStride[2] + topInd * inStride[1] +\n                  bInd * inStride[0];\n              const topLeft = imageVals[ind];\n\n              ind = c + rightInd * inStride[2] + topInd * inStride[1] +\n                  bInd * inStride[0];\n              const topRight = imageVals[ind];\n\n              ind = c + leftInd * inStride[2] + bottomInd * inStride[1] +\n                  bInd * inStride[0];\n              const bottomLeft = imageVals[ind];\n\n              ind = c + rightInd * inStride[2] + bottomInd * inStride[1] +\n                  bInd * inStride[0];\n              const bottomRight = imageVals[ind];\n\n              const top = topLeft + (topRight - topLeft) * xLerp;\n              const bottom = bottomLeft + (bottomRight - bottomLeft) * xLerp;\n\n              ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n              output.values[ind] = top + ((bottom - top) * yLerp);\n            }\n          }\n        } else {  // method == \"nearest\"\n          for (let x = 0; x < cropWidth; ++x) {\n            const xInd = (cropWidth > 1) ?\n                x1 * (imageWidth - 1) + x * widthScale :\n                0.5 * (x1 + x2) * (imageWidth - 1);\n\n            if (xInd < 0 || xInd > imageWidth - 1) {\n              for (let c = 0; c < numChannels; c++) {\n                const ind =\n                    c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n                output.values[ind] = extrapolationValue;\n              }\n              continue;\n            }\n\n            const closestX = Math.round(xInd);\n            const closestY = Math.round(yInd);\n            for (let c = 0; c < numChannels; c++) {\n              const inInd = c + closestX * inStride[2] +\n                  closestY * inStride[1] + bInd * inStride[0];\n              const outInd =\n                  c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n              output.values[outInd] = imageVals[inInd];\n            }\n          }\n        }\n      }\n    }\n    return output.toTensor() as Tensor4D;\n  }\n\n  sparseToDense<R extends Rank>(\n      sparseIndices: Tensor, sparseValues: Tensor, outputShape: ShapeMap[R],\n      defaultValue: Scalar): Tensor<R> {\n    const {sliceRank, numUpdates, sliceSize, strides, outputSize} =\n        backend_util.calculateShapes(sparseValues, sparseIndices, outputShape);\n    const sumDupeIndices = false;\n    return this.scatter(\n        sparseIndices, sparseValues, outputShape, outputSize, sliceSize,\n        numUpdates, sliceRank, strides, defaultValue, sumDupeIndices);\n  }\n\n  gatherND(x: Tensor, indices: Tensor): Tensor {\n    const indicesShape = indices.shape;\n    const sliceRank = indicesShape[indicesShape.length - 1];\n\n    const [resultShape, numSlices, sliceSize, strides] =\n        backend_util.prepareAndValidate(x, indices);\n    if (numSlices === 0) {\n      return tf.tensor([], resultShape, x.dtype);\n    }\n\n    const buffer = new TensorBuffer([numSlices, sliceSize], x.dtype);\n    const indicesData = this.readSync(indices.dataId) as TypedArray;\n    const xData = this.readSync(x.dataId) as TypedArray;\n\n    for (let i = 0; i < numSlices; i++) {\n      const index = [];\n      let flattenIndex = 0;\n      for (let j = 0; j < sliceRank; j++) {\n        const dim = indicesData[i * sliceRank + j];\n        flattenIndex += dim * strides[j];\n        index.push(dim);\n      }\n      if (flattenIndex < 0 || flattenIndex >= x.size / sliceSize) {\n        throw new Error(\n            `Invalid indices: ${index} does not index into ${x.shape}`);\n      }\n\n      for (let k = 0; k < sliceSize; k++) {\n        buffer.values[i * sliceSize + k] = xData[flattenIndex * sliceSize + k];\n      }\n    }\n    return buffer.toTensor().reshape(resultShape);\n  }\n\n  scatterND<R extends Rank>(\n      indices: Tensor, updates: Tensor, shape: ShapeMap[R]): Tensor<R> {\n    const {sliceRank, numUpdates, sliceSize, strides, outputSize} =\n        backend_util.calculateShapes(updates, indices, shape);\n    const defaultValue = tf.scalar(0);\n    const sumDupeIndices = true;\n    return this.scatter(\n        indices, updates, shape, outputSize, sliceSize, numUpdates, sliceRank,\n        strides, defaultValue, sumDupeIndices);\n  }\n\n  fill<R extends Rank>(\n      shape: ShapeMap[R], value: number|string, dtype?: DataType): Tensor<R> {\n    dtype = dtype || util.inferDtype(value);\n    const values =\n        util.getArrayFromDType(dtype, util.sizeFromShape(shape)) as TypedArray;\n    values.fill(value as number);\n    return engine().makeTensor(values, shape, dtype, this) as Tensor<R>;\n  }\n\n  onesLike<R extends Rank>(x: Tensor<R>): Tensor<R> {\n    if (x.dtype === 'string') {\n      throw new Error('onesLike is not supported for string tensors');\n    } else {\n      return this.fill(x.shape, 1, x.dtype);\n    }\n  }\n\n  zerosLike<R extends Rank>(x: Tensor<R>): Tensor<R> {\n    const values = util.getArrayFromDType(\n                       x.dtype, util.sizeFromShape(x.shape)) as TypedArray;\n    return this.makeOutput(values, x.shape, x.dtype);\n  }\n\n  linspace(start: number, stop: number, num: number): Tensor1D {\n    return backend_util.linspaceImpl(start, stop, num);\n  }\n\n  private scatter<R extends Rank>(\n      indices: Tensor, updates: Tensor, shape: ShapeMap[R], outputSize: number,\n      sliceSize: number, numUpdates: number, sliceRank: number,\n      strides: number[], defaultValue: Scalar,\n      sumDupeIndices: boolean): Tensor<R> {\n    const flattenShape = [outputSize / sliceSize, sliceSize];\n\n    const indicesData = this.readSync(indices.dataId) as TypedArray;\n    const updatesData = this.readSync(updates.dataId) as TypedArray;\n\n    if (outputSize === 0) {\n      return tf.tensor([], shape, updates.dtype);\n    }\n\n    const buffer = new TensorBuffer(flattenShape, updates.dtype as 'float32');\n    buffer.values.fill((this.readSync(defaultValue.dataId) as TypedArray)[0]);\n\n    for (let i = 0; i < numUpdates; i++) {\n      const index = [];\n      let flattenIndex = 0;\n      for (let j = 0; j < sliceRank; j++) {\n        const dim = indicesData[i * sliceRank + j];\n        index.push(dim);\n        flattenIndex += dim * strides[j];\n      }\n\n      if (flattenIndex < 0 || flattenIndex >= outputSize / sliceSize) {\n        throw new Error(\n            `Invalid indices: ${index} does not index into ${shape}`);\n      }\n\n      for (let k = 0; k < sliceSize; k++) {\n        if (sumDupeIndices) {\n          buffer.values[flattenIndex * sliceSize + k] +=\n              updatesData[i * sliceSize + k];\n        } else {\n          buffer.values[flattenIndex * sliceSize + k] = updates.rank === 0 ?\n              updatesData[0] :\n              updatesData[i * sliceSize + k];\n        }\n      }\n    }\n    return buffer.toTensor().reshape(shape);\n  }\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {BinaryInputs, KernelConfig} from '@tensorflow/tfjs-core';\nimport {DataType, NumericDataType, TypedArray} from '@tensorflow/tfjs-core';\nimport {backend_util} from '@tensorflow/tfjs-core';\n\nimport {util} from '@tensorflow/tfjs-core';\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function createBinaryKernelConfig(\n    name: string,\n    op: (\n        aShape: number[], bShape: number[], aVals: TypedArray,\n        bVals: TypedArray,\n        dtype: DataType) => [TypedArray, number[]]): KernelConfig {\n  return {\n    kernelName: name,\n    backendName: 'cpu',\n    kernelFunc: ({inputs, backend}) => {\n      const {a, b} = inputs as BinaryInputs;\n      const cpuBackend = backend as MathBackendCPU;\n      assertNotComplex([a, b], name);\n\n      const aVals = cpuBackend.data.get(a.dataId).values as TypedArray;\n      const bVals = cpuBackend.data.get(b.dataId).values as TypedArray;\n\n      const [resultData, resultShape] =\n          op(a.shape, b.shape, aVals, bVals, a.dtype);\n\n      const dataId = cpuBackend.write(resultData, resultShape, a.dtype);\n      return {dataId, shape: resultShape, dtype: a.dtype};\n    }\n  };\n}\n\nexport function createBinaryKernelImpl(op: (a: number, b: number) => number) {\n  return (aShape: number[], bShape: number[], aVals: TypedArray,\n          bVals: TypedArray, dtype: DataType): [TypedArray, number[]] => {\n    const newShape = backend_util.assertAndGetBroadcastShape(aShape, bShape);\n\n    const resultRank = newShape.length;\n    const resultStrides = util.computeStrides(newShape);\n    const resultSize = util.sizeFromShape(newShape);\n\n    const result =\n        util.getTypedArrayFromDType(dtype as NumericDataType, resultSize);\n\n    const aRank = aShape.length;\n    const bRank = bShape.length;\n\n    const aStrides = util.computeStrides(aShape);\n    const bStrides = util.computeStrides(bShape);\n\n    const aBroadcastDims = backend_util.getBroadcastDims(aShape, newShape);\n    const bBroadcastDims = backend_util.getBroadcastDims(bShape, newShape);\n\n    if (aBroadcastDims.length + bBroadcastDims.length === 0) {\n      for (let i = 0; i < result.length; ++i) {\n        result[i] = op(aVals[i % aVals.length], bVals[i % bVals.length]);\n      }\n    } else {\n      for (let i = 0; i < result.length; ++i) {\n        const loc = util.indexToLoc(i, resultRank, resultStrides);\n\n        const aLoc = loc.slice(-aRank);\n        aBroadcastDims.forEach(d => aLoc[d] = 0);\n        const aIndex = util.locToIndex(aLoc, aRank, aStrides);\n\n        const bLoc = loc.slice(-bRank);\n        bBroadcastDims.forEach(d => bLoc[d] = 0);\n        const bIndex = util.locToIndex(bLoc, bRank, bStrides);\n\n        result[i] = op(aVals[aIndex], bVals[bIndex]);\n      }\n    }\n\n    return [result, newShape];\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {createBinaryKernelImpl} from '../utils/kernel_utils';\n\nexport const divImpl = createBinaryKernelImpl((a: number, b: number) => a / b);\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Div} from '@tensorflow/tfjs-core';\nimport {createBinaryKernelConfig} from '../utils/kernel_utils';\nimport {divImpl} from './Div_impl';\n\nexport const divConfig = createBinaryKernelConfig(Div, divImpl);\n","/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Max, MaxAttrs, MaxInputs} from '@tensorflow/tfjs-core';\nimport {backend_util, KernelConfig} from '@tensorflow/tfjs-core';\nimport {TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {maxImpl} from './Max_impl';\nimport {transposeImpl} from './Transpose_impl';\n\nexport const maxConfig: KernelConfig = {\n  kernelName: Max,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, attrs, backend}) => {\n    const {x} = inputs as MaxInputs;\n    const {reductionIndices} = attrs as {} as MaxAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n    let xShape = x.shape;\n    const xRank = xShape.length;\n\n    const origAxes = util.parseAxisParam(reductionIndices, xShape);\n    let axes = origAxes;\n    const permutedAxes = backend_util.getAxesPermutation(axes, xRank);\n    let xVals = cpuBackend.data.get(x.dataId).values as TypedArray;\n    if (permutedAxes != null) {\n      const newShape: number[] = new Array(xRank);\n      for (let i = 0; i < newShape.length; i++) {\n        newShape[i] = xShape[permutedAxes[i]];\n      }\n\n      xVals = transposeImpl(xVals, xShape, x.dtype, permutedAxes, newShape);\n      axes = backend_util.getInnerMostAxes(axes.length, xRank);\n\n      xShape = newShape;\n    }\n\n    assertNotComplex(x, 'max');\n    backend_util.assertAxesAreInnerMostDims('max', axes, xRank);\n    const [maxOutShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(xShape, axes);\n\n    const reduceSize = util.sizeFromShape(reduceShape);\n\n    const result = maxImpl(xVals, reduceSize, maxOutShape, x.dtype);\n    const dataId = cpuBackend.write(result, maxOutShape, x.dtype);\n    return {dataId, shape: maxOutShape, dtype: x.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// We explicitly import the modular kernels so they get registered in the\n// global registry when we compile the library. A modular build would replace\n// the contents of this file and import only the kernels that are needed.\nimport {KernelConfig, registerKernel} from '@tensorflow/tfjs-core';\n\nimport {divConfig} from './kernels/Div';\nimport {maxConfig} from './kernels/Max';\nimport {maxPoolWithArgmaxConfig} from './kernels/MaxPoolWithArgmax';\nimport {nonMaxSuppressionV5Config} from './kernels/NonMaxSuppressionV5';\nimport {squareConfig} from './kernels/Square';\nimport {squaredDifferenceConfig} from './kernels/SquaredDifference';\nimport {transposeConfig} from './kernels/Transpose';\n\n// List all kernel configs here\nconst kernelConfigs: KernelConfig[] = [\n  nonMaxSuppressionV5Config, squareConfig, squaredDifferenceConfig, divConfig,\n  transposeConfig, maxPoolWithArgmaxConfig, maxConfig\n];\n\nfor (const kernelConfig of kernelConfigs) {\n  registerKernel(kernelConfig);\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {MaxPoolWithArgmax, MaxPoolWithArgmaxAttrs, MaxPoolWithArgmaxInputs} from '@tensorflow/tfjs-core';\nimport {backend_util, KernelConfig, TypedArray} from '@tensorflow/tfjs-core';\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {maxPoolWithArgmaxImpl} from './MaxPoolWithArgmax_impl';\n\nexport const maxPoolWithArgmaxConfig: KernelConfig = {\n  kernelName: MaxPoolWithArgmax,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, attrs, backend}) => {\n    const {x} = inputs as MaxPoolWithArgmaxInputs;\n    const {filterSize, strides, pad, includeBatchInIndex} =\n        attrs as {} as MaxPoolWithArgmaxAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n    assertNotComplex(x, 'MaxPoolWithArgmax');\n\n    const values = cpuBackend.data.get(x.dataId).values as TypedArray;\n    const convInfo = backend_util.computePool2DInfo(\n        x.shape as [number, number, number, number], filterSize, strides,\n        [1, 1], pad);\n    const [pooled, indexes] = maxPoolWithArgmaxImpl(\n        values, x.shape, x.dtype, includeBatchInIndex, convInfo);\n\n    const pooledDataId =\n        cpuBackend.write(pooled as Float32Array, convInfo.outShape, x.dtype);\n    const indexesDataId =\n        cpuBackend.write(indexes as Int32Array, convInfo.outShape, x.dtype);\n    return [\n      {dataId: pooledDataId, shape: convInfo.outShape, dtype: x.dtype},\n      {dataId: indexesDataId, shape: convInfo.outShape, dtype: 'int32'}\n    ];\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {backend_util, DataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {maxPoolPositions, pool} from '../utils/pool_utils';\nexport function maxPoolWithArgmaxImpl(\n    xValues: TypedArray, xShape: number[], dtype: DataType,\n    includeBatchInIndex: boolean, convInfo: backend_util.Conv2DInfo) {\n  const strides = util.computeStrides(xShape);\n  const maxPools = pool(xValues, xShape, dtype, strides, convInfo, 'max');\n  const maxPositions = maxPoolPositions(\n      xValues, xShape, dtype, convInfo, true, includeBatchInIndex);\n\n  return [maxPools.values, maxPositions.values];\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {NonMaxSuppressionV5, NonMaxSuppressionV5Attrs, NonMaxSuppressionV5Inputs} from '@tensorflow/tfjs-core';\nimport {KernelConfig, TypedArray} from '@tensorflow/tfjs-core';\nimport {kernel_impls} from '@tensorflow/tfjs-core';\nconst nonMaxSuppressionV5 = kernel_impls.nonMaxSuppressionV5;\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport const nonMaxSuppressionV5Config: KernelConfig = {\n  kernelName: NonMaxSuppressionV5,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend, attrs}) => {\n    const {boxes, scores} = inputs as NonMaxSuppressionV5Inputs;\n    const {maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma} =\n        attrs as unknown as NonMaxSuppressionV5Attrs;\n\n    const cpuBackend = backend as MathBackendCPU;\n\n    assertNotComplex(boxes, 'NonMaxSuppressionWithScore');\n\n    const boxesVals = cpuBackend.data.get(boxes.dataId).values as TypedArray;\n    const scoresVals = cpuBackend.data.get(scores.dataId).values as TypedArray;\n\n    const maxOutputSizeVal = maxOutputSize;\n    const iouThresholdVal = iouThreshold;\n    const scoreThresholdVal = scoreThreshold;\n    const softNmsSigmaVal = softNmsSigma;\n\n    const {selectedIndices, selectedScores} = nonMaxSuppressionV5(\n        boxesVals, scoresVals, maxOutputSizeVal, iouThresholdVal,\n        scoreThresholdVal, softNmsSigmaVal);\n\n    return [selectedIndices, selectedScores];\n  }\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Square, SquareInputs} from '@tensorflow/tfjs-core';\nimport {KernelConfig} from '@tensorflow/tfjs-core';\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport const squareConfig: KernelConfig = {\n  kernelName: Square,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend}) => {\n    const {x} = inputs as SquareInputs;\n    const cpuBackend = backend as MathBackendCPU;\n    assertNotComplex(x, 'square');\n\n    const values = cpuBackend.data.get(x.dataId).values as Float32Array;\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      const value = values[i];\n      newValues[i] = value * value;\n    }\n    const dataId = cpuBackend.write(newValues, x.shape, x.dtype);\n    return {dataId, shape: x.shape, dtype: x.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {SquaredDifference} from '@tensorflow/tfjs-core';\nimport {createBinaryKernelImpl} from '../utils/kernel_utils';\nimport {createBinaryKernelConfig} from '../utils/kernel_utils';\n\nconst squaredDifferenceImpl = createBinaryKernelImpl((aVal, bVal) => {\n  const diff = aVal - bVal;\n  return diff * diff;\n});\n\nexport const squaredDifferenceConfig =\n    createBinaryKernelConfig(SquaredDifference, squaredDifferenceImpl);\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {Transpose, TransposeAttrs, TransposeInputs} from '@tensorflow/tfjs-core';\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {transposeImpl} from './Transpose_impl';\n\nexport const transposeConfig: KernelConfig = {\n  kernelName: Transpose,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, attrs, backend}) => {\n    const {x} = inputs as TransposeInputs;\n    const {perm} = attrs as {} as TransposeAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    assertNotComplex(x, 'transpose');\n\n    const xRank = x.shape.length;\n\n    const newShape: number[] = new Array(xRank);\n    for (let i = 0; i < newShape.length; i++) {\n      newShape[i] = x.shape[perm[i]];\n    }\n\n    const values = cpuBackend.data.get(x.dataId).values as TypedArray;\n    const result = transposeImpl(values, x.shape, x.dtype, perm, newShape);\n\n    const dataId = cpuBackend.write(result, newShape, x.dtype);\n    return {dataId, shape: newShape, dtype: x.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {registerBackend} from '@tensorflow/tfjs-core';\nimport {MathBackendCPU} from './base';\n\n// Side effects for default initialization of MathBackendCPU\nregisterBackend('cpu', () => new MathBackendCPU(), 1 /* priority */);\nimport './register_all_kernels';\n\n// All exports from this package should be in base.\nexport * from './base';\n","/** @license See the LICENSE file. */\n\n// This code is auto-generated, do not modify this file!\nconst version = '2.0.1';\nexport {version};\n"],"names":["maxImpl","aVals","reduceSize","outShape","dtype","vals","util","getTypedArrayFromDType","sizeFromShape","i","length","offset","max","j","value","transposeImpl","xVals","xShape","perm","newShape","xRank","xSize","xStrides","computeStrides","newStrides","result","loc","indexToLoc","newLoc","Array","i_1","locToIndex","assertNotComplex","tensor","opName","isArray","forEach","t","assert","pool","xValues","strides","convInfo","poolType","strideHeight","strideWidth","dilationHeight","dilationWidth","effectiveFilterHeight","effectiveFilterWidth","padTop","padInfo","top","padLeft","left","initialValue","Number","NEGATIVE_INFINITY","POSITIVE_INFINITY","output","buffer","outputVals","values","outputBatchStrides","outputRowStrides","outputColStrides","b","batchSize","outputBatchOffset","inputBatchOffset","d","inChannels","yR","outHeight","xRCorner","xRMin","Math","xRMax","min","inHeight","outputRowOffset","yC","outWidth","xCCorner","xCMin","xCMax","inWidth","minMaxValue","avgValue","count","xR","xROffset","xC","pixel","isNaN","maxPoolPositions","flattenPositions","includeBatchInIndex","maxPositions","xBuf","maxValue","maxPosition","wR","wC","get","set","nonMaxSuppressionV3","kernel_impls","split","tile","topkImpl","whereImpl","mapActivation","backend","x","activation","preluActivationWeights","linear","relu","elu","relu6","prelu","Error","_super","_this","data","DataStorage","engine","tslib_1.__extends","MathBackendCPU","shape","this","firstUse","env","backend_util","warn","dataId","numDataIds","readSync","_a","complexTensors","realValues","real","imagValues","imag","mergeRealAndImagArrays","decodedData","map","decodeString","tf.buffer","write","makeTensorFromDataId","has","dispose","delete","f","start","now","kernelMs","unreliable","reasons","makeOutput","keep","clone","input","begin","size","slice_util","isSliceContinous","flatOffset","computeFlatOffset","length_1","tf.tensor","subarray","bufferSync","xLoc","idx","toTensor","end","computeOutShape","some","axis","num","rank","outIndex","fill","slice","res","reshape","outLoc","inLoc","ax","tensors","reals","tf.real","imags","tf.imag","tf.complex","concat","tensors2D","innerSize","as2D","offset_1","colOffset_1","tVals","tIdx","row","resIdx","col","finalOutShape","multiply","tf.scalar","a","broadcastedBinaryComplexOp","cast","aReal","aImag","bReal","bImag","broadcastedBinaryOp","upcastType","aValue","bValue","resultVals","currVals","logits","dim","axes","parseAxisParam","maxLogit","expandedShape","expandShapeToKeepDim","subtract","exp","sumExp","sum","tf.div","pow","transposeA","transposeB","sharedDim","leftDim","rightDim","batchDim","aValues","bValues","aBatch","aOuterStep","aInnerStep","_b","bInnerStep","bOuterStep","bBatch","resVals","blockSize","b_1","i0","j0","k0","iBlock","jBlock","kBlock","k","bias","batchMatMul","add","floor","assertAxesAreInnerMostDims","reduceShape","resultDtype","tf.zeros","prod","segmentIds","numSegments","numIters","expandDims","segmentId","tf.equal","asType","mul","push","tf.stack","minIndex","max_1","maxIndex","exclusive","reverse","finalDim","indexAdjuster","prevIdx","aVal","bVal","newValues","Uint8Array","condition","index","condVals","sorted","rem","all","anyVal","diff","Float32Array","ceil","abs","Infinity","isFinite","base","expm1","log","log1p","sqrt","inVals","xValue","resultValues","v","dy","y","dyValues","scaleAlpha","SELU_SCALEALPHA","scale","SELU_SCALE","hypot","Int32Array","threshold","tooLarge","tooSmall","expX","sin","cos","tan","asin","acos","atan","atan2","sinh","cosh","tanh","asinh","acosh","atanh","p","ERF_P","a1","ERF_A1","a2","ERF_A2","a3","ERF_A3","a4","ERF_A4","a5","ERF_A5","sign","alpha","NaN","filter","conv2d","filterHeight","filterWidth","isChannelsLast","dataFormat","xBatchStride","xRowStride","xColStride","xChannelStride","yBatchStride","yRowStride","yColStride","yChannelStride","wVals","yVals","xOffset1","yOffset1","yOffset2","wOffset1","xOffset2","yOffset3","xOffset3","wOffset3","d1","xVal","d2","outChannels","filterDepth","dilationDepth","padFront","front","yF","outDepth","xFCorner","strideDepth","wF","xF","inDepth","wOffset2","yOffset4","xOffset4","wOffset4","dx","inShape","dxValues","fltValues","fltS0","fltS1","fltS2","topPad","leftPad","yRMax","yCMax","dotProd","dyOffset","fltOffset","dxS0","dxS1","dxS2","dxS3","dyS0","dyS1","dyS2","dyS3","_c","fltS3","frontPad","xFMin","yFMax","dW","filterShape","dyBuf","yRMin","yCMin","dw","dwValues","dwS0","dwS1","dwS2","dwS3","xS0","xS1","xS2","xS3","yFMin","depthwiseConv2D","chMul","q","dm","trunc","reps","paddings","constantValue","xBuffer","coords","outCoords","c","indices","indicesValues","originalLoc","originalIndex","blockShape","crops","reduce","reshaped","getReshaped","permuted","getPermuted","reshapedPermuted","getReshapedPermuted","sliceBeginCoords","getSliceBeginCoords","sliceSize","getSliceSize","tf.transpose","completePaddings","paddedX","pad","reshapedPaddedShape","permutedReshapedPaddedPermutation","flattenShape","maxPosBuf","dxR","dxC","dyRCorner","dyCCorner","dyR","dyC","mask","avgMultiplier","effectiveFilterDepth","outputDepthStrides","batch","channel","yDepth","xDepthCorner","xDepthMin","xDepthMax","outputDepthOffset","yRow","xRowCorner","xRowMin","xRowMax","yCol","xColCorner","xColMin","xColMax","outputColOffset","xDepth","xDepthOffset","xRow","xRowOffset","xCol","pool3d","toFloat","dxDepth","dxRow","dxCol","dyDepthCorner","dyRowCorner","dyColCorner","wDepth","dyDepth","wRow","dyRow","wCol","dyCol","maxPool3dPositions","castTensor","reshapeTensor","newHeight","newWidth","alignCorners","oldHeight","oldWidth","numChannels","effectiveInputSize","effectiveOutputSize","outputIdx","effectiveRowSizeRatio","effectiveColSizeRatio","r","sourceFracRow","sourceRowFloor","rowFrac","sourceRowCeil","topRowOffset","botRowOffset","sourceFracCol","sourceColFloor","colFrac","sourceColCeil","topLeftOffest","botLeftOffset","topRightOffset","botRightOffest","topLeft","bottomLeft","top_1","newValue","xHeight","xWidth","depth","yHeight","yWidth","effectiveXSize","effectiveYSize","heightScale","widthScale","bOffset","topDxRIndex","bottomDxRIndex","topDxROffset","bottomDxROffset","dxRLerp","inverseDxRLerp","leftDxCIndex","rightDxCIndex","dxCLerp","inverseDxCLerp","topLeftRCOffset","topRightRCOffset","bottomLeftRCOffset","bottomRightRCOffset","inverseDxRLerpTimesInverseDxCLerp","inverseDxRLerpTimesDxCLerp","dxRLerpTimesInverseDxCLerp","dxRLerpTimesDxCLerp","dyVal","tf.tensor4d","outputOffset","batchOffset","rowOffset","round","colOffset","newVal","invHeightScale","invWidthScale","winHeight","winWidth","startRLerp","startDyR","startCLerp","startDyC","accum","dyRIndex","dyROffset","dyCIndex","dyCOffset","mean","variance","varianceEpsilon","mVals","varVals","sVals","offVals","outVals","offValsLength","sValsLength","varValsLength","mValsLength","offi","mi","si","vi","depthRadius","beta","channels","maxD","sumAcrossChannels","currentChannel","beginSumOffset","endSumOffset","z","val","inputImage","outputImage","inputImageValues","outputImageValues","depthBegin","depthEnd","norm","dyi","normalized","numSamples","seed","probabilities","tf.softmax","numEvents","probVals","cdf","event_1","random","seedrandom.alea","toString","outOffset","sampleId","event_2","onValue","offValue","indicesVal","event_3","tf.tensor2d","boxes","scores","maxOutputSize","iouThreshold","scoreThreshold","boxesVals","scoresVals","fftBatch","inverse","innerDim","realResult","imagResult","fftImpl","getComplexWithIndex","x1D","as1D","n","isExponentOf2","fftRadix2","div","rawOutput","fourierTransformByMatmul","splitRealAndImagArrays","half","evenComplex","complexWithEvenIndex","evenTensor","oddComplex","complexWithOddIndex","oddTensor","e","exponents","exponent","addPart","subPart","sub","realTensor","imagTensor","ret","term","assignToTypedArray","inputHeight","inputWidth","inputDepth","outputHeight","outputWidth","outputDepth","h","inH","offsetH","w","inW","offsetD","inputIdx","op","assertAndGetBroadcastShape","bVals","aBroadcastDims","getBroadcastDims","bBroadcastDims","aBuf","bBuf","aLoc","aIndex","bLoc","bIndex","realVals","imagVals","aIdx","bIdx","aRealBuf","bRealBuf","opResult","complex","sizeSplits","epsilon","images","boxIndex","cropSize","method","extrapolationValue","imageHeight","imageWidth","numBoxes","cropHeight","cropWidth","boxVals","boxIndVals","imageVals","inStride","outStride","startInd","y1","x1","y2","x2","bInd","yInd","ind","topInd","bottomInd","yLerp","xInd","leftInd","rightInd","xLerp","topRight","top_2","bottom","closestX","closestY","inInd","outInd","sparseIndices","sparseValues","outputShape","defaultValue","sliceRank","numUpdates","outputSize","scatter","indicesShape","resultShape","numSlices","TensorBuffer","indicesData","xData","flattenIndex","updates","inferDtype","getArrayFromDType","makeTensor","stop","linspaceImpl","sumDupeIndices","updatesData","KernelBackend","createBinaryKernelConfig","name","kernelName","backendName","kernelFunc","inputs","cpuBackend","resultData","createBinaryKernelImpl","aShape","bShape","resultRank","resultStrides","resultSize","aRank","bRank","aStrides","bStrides","divImpl","divConfig","Div","maxConfig","Max","attrs","reductionIndices","permutedAxes","getAxesPermutation","getInnerMostAxes","maxOutShape","maxPoolWithArgmaxConfig","MaxPoolWithArgmax","filterSize","computePool2DInfo","maxPools","pooled","indexes","pooledDataId","indexesDataId","nonMaxSuppressionV5","nonMaxSuppressionV5Config","NonMaxSuppressionV5","softNmsSigma","_d","squareConfig","Square","squaredDifferenceImpl","kernelConfigs_1","SquaredDifference","Transpose","_i","kernelConfig","registerKernel"],"mappings":";;;;;;;;;;;;;;;;iUAmBgBA,EACZC,EAAmBC,EAAoBC,EACvCC,GAIF,IAHA,IAAMC,EAAOC,OAAKC,uBACdH,EAA0BE,OAAKE,cAAcL,IAExCM,EAAI,EAAGA,EAAIJ,EAAKK,SAAUD,EAAG,CAGpC,IAFA,IAAME,EAASF,EAAIP,EACfU,EAAMX,EAAMU,GACPE,EAAI,EAAGA,EAAIX,IAAcW,EAAG,CACnC,IAAMC,EAAQb,EAAMU,EAASE,GACzBC,EAAQF,IACVA,EAAME,GAGVT,EAAKI,GAAKG,EAEZ,OAAOP,WChBOU,EACZC,EAAmBC,EAAkBb,EAAiBc,EACtDC,GASF,IARA,IAAMC,EAAQH,EAAOP,OACfW,EAAQf,OAAKE,cAAcS,GAC3BK,EAAWhB,OAAKiB,eAAeN,GAC/BO,EAAalB,OAAKiB,eAAeJ,GAEjCM,EAASnB,OAAKC,uBAChBH,EAA0BE,OAAKE,cAAcW,IAExCV,EAAI,EAAGA,EAAIY,IAASZ,EAAG,CAK9B,IAJA,IAAMiB,EAAMpB,OAAKqB,WAAWlB,EAAGW,EAAOE,GAGhCM,EAAmB,IAAIC,MAAMH,EAAIhB,QAC9BoB,EAAI,EAAGA,EAAIF,EAAOlB,OAAQoB,IACjCF,EAAOE,GAAKJ,EAAIR,EAAKY,IAIvBL,EADiBnB,OAAKyB,WAAWH,EAAQR,EAAOI,IAC7BR,EAAMP,GAE3B,OAAOgB,2jDCxBOO,EACZC,EAAiCC,GAC9BL,MAAMM,QAAQF,KACjBA,EAAS,CAACA,IAEZA,EAAOG,SAAQ,SAAAC,GACJ,MAALA,GACF/B,OAAKgC,OACW,cAAZD,EAAEjC,OACF,WAAM,OACF8B,2ECVEK,EACZC,EAAqBvB,EAAkBb,EAAiBqC,EACxDC,EACAC,GAsBF,IArBA,IAAMC,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBC,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBC,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChCC,EAASR,EAASS,QAAQC,IAC1BC,EAAUX,EAASS,QAAQG,KAE3BC,EACY,QAAbZ,EAAqBa,OAAOC,kBACPD,OAAOE,kBAE3BC,EAASC,SAAOlB,EAASvC,SAAUC,GACnCyD,EAAaF,EAAOG,OAEpBC,EACFrB,EAASvC,SAAS,GAAKuC,EAASvC,SAAS,GAAKuC,EAASvC,SAAS,GAC9D6D,EAAmBtB,EAASvC,SAAS,GAAKuC,EAASvC,SAAS,GAC5D8D,EAAmBvB,EAASvC,SAAS,GAElC+D,EAAI,EAAGA,EAAIxB,EAASyB,YAAaD,EAGxC,IAFA,IAAME,EAAoBF,EAAIH,EACxBM,EAAmBH,EAAIzB,EAAQ,GAC5B6B,EAAI,EAAGA,EAAI5B,EAAS6B,aAAcD,EACzC,IAAK,IAAIE,EAAK,EAAGA,EAAK9B,EAAS+B,YAAaD,EAM1C,IALA,IAAME,EAAWF,EAAK5B,EAAeM,EAC/ByB,EAAQC,KAAKhE,IAAI,EAAG8D,GACpBG,EACFD,KAAKE,IAAIpC,EAASqC,SAAU/B,EAAwB0B,GAClDM,EAAkBZ,EAAoBI,EAAKR,EACxCiB,EAAK,EAAGA,EAAKvC,EAASwC,WAAYD,EAAI,CAQ7C,IAPA,IAAME,EAAWF,EAAKpC,EAAcQ,EAC9B+B,EAAQR,KAAKhE,IAAI,EAAGuE,GACpBE,EACFT,KAAKE,IAAIpC,EAAS4C,QAASrC,EAAuBkC,GAClDI,EAAchC,EACdiC,EAAW,EACXC,EAAQ,EACHC,EAAKf,EAAOe,EAAKb,EAAOa,GAAM5C,EAAgB,CAErD,IADA,IAAM6C,EAAWtB,EAAmBqB,EAAKjD,EAAQ,GACxCmD,EAAKR,EAAOQ,EAAKP,EAAOO,GAAM7C,EAAe,CACpD,IACM8C,EAAQrD,EADGmD,EAAWC,EAAKnD,EAAQ,GACR6B,GACf,QAAb3B,GAAsBkD,EAAQN,EACjCA,EAAcM,EACQ,QAAblD,IACT6C,GAAYK,EACZJ,KAGJ,GAAIK,MAAMP,GACR,MAIJ1B,EADqBmB,EAAkBC,EAAKhB,EAAmBK,GAE9C,QAAb3B,EAAqB6C,EAAWC,EAAQF,EAKpD,OAAO5B,WAGOoC,EACZvD,EAAqBvB,EAAkBb,EACvCsC,EAAmCsD,EACnCC,gBADmCD,mBACnCC,MAYF,IAXA,IAAMC,EAAetC,SAAOlB,EAASvC,SAAU,SACzCyC,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBC,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBC,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChCC,EAASR,EAASS,QAAQC,IAC1BC,EAAUX,EAASS,QAAQG,KAE3B6C,EAAOvC,SAAO3C,EAAQb,EAAOoC,GAC1B0B,EAAI,EAAGA,EAAIxB,EAASyB,YAAaD,EACxC,IAAK,IAAII,EAAI,EAAGA,EAAI5B,EAAS6B,aAAcD,EACzC,IAAK,IAAIE,EAAK,EAAGA,EAAK9B,EAAS+B,YAAaD,EAAI,CAG9C,IAFA,IAAME,EAAWF,EAAK5B,EAAeM,EACjCyB,EAAQD,EACLC,EAAQ,GACbA,GAAS7B,EAKX,IAFA,IAAM+B,EACFD,KAAKE,IAAIpC,EAASqC,SAAU/B,EAAwB0B,GAC/CO,EAAK,EAAGA,EAAKvC,EAASwC,WAAYD,EAAI,CAG7C,IAFA,IAAME,EAAWF,EAAKpC,EAAcQ,EAChC+B,EAAQD,EACLC,EAAQ,GACbA,GAASrC,EAOX,IALA,IAAMsC,EACFT,KAAKE,IAAIpC,EAAS4C,QAASrC,EAAuBkC,GAClDiB,EAAW5C,OAAOC,kBAClB4C,GAAe,EAEVX,EAAKf,EAAOe,EAAKb,EAAOa,GAAM5C,EAErC,IADA,IAAMwD,EAAKZ,EAAKhB,EACPkB,EAAKR,EAAOQ,EAAKP,EAAOO,GAAM7C,EAAe,CACpD,IAAMwD,EAAKX,EAAKT,EACVU,EAAQM,EAAKK,IAAItC,EAAGwB,EAAIE,EAAItB,GAC9BuB,EAAQO,IACVA,EAAWP,EAETQ,EADEL,EACYC,IACR/B,EAAIxB,EAASqC,SAAWW,GAAMhD,EAAS4C,QAAUM,GAC3ClD,EAAS6B,WACbD,GACHoB,EAAKhD,EAAS4C,QAAUM,GAAMlD,EAAS6B,WAAaD,EAE3CgC,EAAKrD,EAAuBsD,GAKlDL,EAAaO,IAAIJ,EAAanC,EAAGM,EAAIS,EAAIX,IAKjD,OAAO4B,EC9HT,IAAMQ,EAAsBC,eAAaD,oBACnCE,EAAQD,eAAaC,MACrBC,EAAOF,eAAaE,KACpBC,EAAWH,eAAaG,SACxBC,EAAYJ,eAAaI,UAO/B,SAASC,EACLC,EAAyBC,EAAWC,EACpCC,GACF,GAAmB,WAAfD,EACF,OAAOF,EAAQI,OAAOH,GACjB,GAAmB,SAAfC,EACT,OAAOF,EAAQK,KAAKJ,GACf,GAAmB,QAAfC,EACT,OAAOF,EAAQM,IAAIL,GACd,GAAmB,UAAfC,EACT,OAAOF,EAAQO,MAAMN,GAChB,GAAmB,UAAfC,EACT,OAAOF,EAAQQ,MAAMP,EAAGE,GAE1B,MAAM,IAAIM,MACN,cAAcP,sEAoBlB,aAAA,MACEQ,0BANKC,YAAY,GAGXA,YAAW,EAIjBA,EAAKC,KAAO,IAAIC,cAAYF,EAAMG,cAigHtC,kIAzgHoCC,MAWlCC,kBAAA,SAAMnE,EAAoCoE,EAAiB9H,GAErD+H,KAAKC,WACPD,KAAKC,UAAW,EACZC,QAAM7B,IAAI,YACZ8B,eAAaC,KACT,4dAYR,IAAMC,EAAS,GAEf,OADAL,KAAKN,KAAKpB,IAAI+B,EAAQ,CAAC1E,SAAQ1D,UACxBoI,GAGTP,iBAAA,SACIO,EAAgB1E,EAAoCoE,EACpD9H,GACF+H,KAAKN,KAAKpB,IAAI+B,EAAQ,CAAC1E,SAAQ1D,WAGjC6H,uBAAA,WACE,OAAOE,KAAKN,KAAKY,cAGbR,iBAAN,SAAWO,sEACT,SAAOL,KAAKO,SAASF,WAEvBP,qBAAA,SAASO,GACD,IAAAG,mBAACvI,UAAOwI,mBACd,GAAc,cAAVxI,EAAuB,CACzB,IAAMyI,EACFV,KAAKO,SAASE,EAAeE,KAAKN,QAChCO,EACFZ,KAAKO,SAASE,EAAeI,KAAKR,QACtC,OAAOF,eAAaW,uBAAuBJ,EAAYE,GAEzD,OAAOZ,KAAKN,KAAKrB,IAAIgC,GAAQ1E,QAGvBmE,uBAAR,SAAmC5F,GACjC,IAAMwF,EAAOM,KAAKO,SAASrG,EAAEmG,QACzBU,EAAcrB,EAClB,GAAgB,WAAZxF,EAAEjC,MACJ,IAEE8I,EAAerB,EAAsBsB,KAAI,SAAA7E,GAAK,OAAAhE,OAAK8I,aAAa9E,MAChE,SACA,MAAM,IAAIoD,MAAM,oDAGpB,OAAO2B,SAAUhH,EAAE6F,MAAO7F,EAAEjC,MAAO8I,IAG7BjB,uBAAR,SACInE,EAAoCoE,EAAiB9H,GACvD,IAAMoI,EAASL,KAAKmB,MAAMxF,EAAQoE,EAAO9H,GACzC,OAAO2H,WAASwB,qBAAqBf,EAAQN,EAAO9H,EAAO+H,OAG7DF,wBAAA,SAAYO,GACV,GAAIL,KAAKN,KAAK2B,IAAIhB,GAAS,CAClB,IAAAI,kCACe,MAAlBA,IACFA,EAAeE,KAAKW,UACpBb,EAAeI,KAAKS,WAEtBtB,KAAKN,KAAK6B,OAAOlB,KAIfP,iBAAN,SAAW0B,4EAIT,OAHMC,EAAQtJ,OAAKuJ,MACnBF,OAEO,CAACG,SADSxJ,OAAKuJ,MAAQD,WAIhC3B,mBAAA,WACE,MAAO,CAEL8B,YAAY,EACZC,QACI,CAAC,wHAKT/B,oBAAA,SAA0Ba,EAASE,GACjC,IAAMvH,EAAS0G,KAAK8B,WAAW,KAAMnB,EAAKZ,MAAO,aAWjD,OATmBC,KAAKN,KAAKrB,IAAI/E,EAAO+G,QAI7BI,eAAiB,CAC1BE,KAAMf,WAASmC,KAAKpB,EAAKqB,SACzBnB,KAAMjB,WAASmC,KAAKlB,EAAKmB,UAGpB1I,GAETwG,iBAAA,SAAuBmC,GAErB,OADmBjC,KAAKN,KAAKrB,IAAI4D,EAAM5B,QACrBI,eAAeE,KAAKqB,SAExClC,iBAAA,SAAuBmC,GAErB,OADmBjC,KAAKN,KAAKrB,IAAI4D,EAAM5B,QACrBI,eAAeI,KAAKmB,SAGxClC,kBAAA,SAAwBf,EAAMmD,EAAiBC,GAI7C,GAHAtI,EAAiBkF,EAAG,SAEAqD,aAAWC,iBAAiBtD,EAAEgB,MAAOmC,EAAOC,GAC/C,CACf,IAAMG,EAAaF,aAAWG,kBAAkBL,EAAOnD,EAAEzE,SACnDkI,EAASrK,OAAKE,cAAc8J,GAC5BjK,EAAO8H,KAAKO,SAASxB,EAAEsB,QAC7B,OAAOoC,SACIvK,EAAKwK,SAASJ,EAAYA,EAAaE,GAASL,EAChDpD,EAAE9G,OAKf,IAFA,IAAMwD,EAASyF,SAAUiB,EAAMpD,EAAE9G,OAC3B+F,EAAOgC,KAAK2C,WAAW5D,GACpBzG,EAAI,EAAGA,EAAImD,EAAO0G,OAAQ7J,EAAG,CACpC,IACMsK,EADMnH,EAAOjC,WAAWlB,GACb0I,KAAI,SAAC6B,EAAKnK,GAAM,OAAAmK,EAAMX,EAAMxJ,MAC7C+C,EAAOE,OAAOrD,GAAK0F,EAAKK,UAALL,EAAY4E,GAEjC,OAAOnH,EAAOqH,YAGhBhD,yBAAA,SACIf,EAAMmD,EAAiBa,EAAezI,GACxCT,EAAiBkF,EAAG,gBAEpB,IAAM/G,EAAWoK,aAAWY,gBAAgBd,EAAOa,EAAKzI,GAExD,GAAItC,EAASiL,MAAK,SAAAC,GAAQ,OAAS,IAATA,KACxB,OAAOT,SAAU,GAAIzK,GAKvB,IAFA,IAAMyD,EAASyF,SAAUlJ,EAAU+G,EAAE9G,OAC/B+F,EAAOgC,KAAK2C,WAAW5D,GACpBzG,EAAI,EAAGA,EAAImD,EAAO0G,KAAM7J,IAAK,CAIpC,IAHA,IAAMiB,EAAMkC,EAAOjC,WAAWlB,GAExBmB,EAAmB,IAAIC,MAAMH,EAAIhB,QAC9BG,EAAI,EAAGA,EAAIe,EAAOlB,OAAQG,IACjCe,EAAOf,GAAKa,EAAIb,GAAK4B,EAAQ5B,GAAKwJ,EAAMxJ,GAE1C+C,EAAO6C,UAAP7C,GAAWuC,EAAKK,UAALL,EAAYvE,WAAYF,IAGrC,OAAOkC,EAAOqH,YAGhBhD,iBAAA,SAAKf,GAIH,IAHA,IAAMlG,EAAQmH,KAAKO,SAASxB,EAAEsB,QACxB5E,EAASyF,SAAU,CAACnC,EAAEoD,KAAMpD,EAAEoD,MAAOpD,EAAE9G,OACvCC,EAAOuD,EAAOE,OACXrD,EAAI,EAAGA,EAAIO,EAAMN,OAAQD,IAChCJ,EAAKI,EAAIyG,EAAEoD,KAAO7J,GAAKO,EAAMP,GAE/B,OAAOmD,EAAOqH,YAGhBhD,oBAAA,SAAQf,EAAWmE,GAIjB,IAHA,IAAMC,EAAMpE,EAAEgB,MAAMmD,GACdlL,EAAqB,IAAI0B,MAAMqF,EAAEqE,KAAO,GAC1CC,EAAW,EACN/K,EAAI,EAAGA,EAAIyG,EAAEqE,KAAM9K,IACtBA,IAAM4K,IACRlL,EAASqL,KAActE,EAAEgB,MAAMzH,IAInC,IAAM4J,EAAQ,IAAIxI,MAAMqF,EAAEqE,MAAME,KAAK,GAC/BnB,EAAOpD,EAAEgB,MAAMwD,QACrBpB,EAAKe,GAAQ,EACb,IAAMM,EAAM,IAAI9J,MAAMyJ,GACtB,IAAS7K,EAAI,EAAGA,EAAIkL,EAAIjL,OAAQD,IAC9B4J,EAAMgB,GAAQ5K,EACdkL,EAAIlL,GAAK0H,KAAKuD,MAAMxE,EAAGmD,EAAOC,GAAMsB,QAAQzL,GAE9C,OAAOwL,GAGT1D,oBAAA,SAA0Bf,EAAMmE,GAC9BrJ,EAAiBkF,EAAG,WAKpB,IAHA,IAAMtD,EAASyF,SAAUnC,EAAEgB,MAAOhB,EAAE9G,OAC9B+F,EAAOgC,KAAK2C,WAAW5D,cAEpBzG,GACP,IAAMoL,EAASjI,EAAOjC,WAAWlB,GAC3BqL,EAAQD,EAAOH,QACrBL,EAAKjJ,SAAQ,SAAA2J,GAAM,OAAAD,EAAMC,GAAM7E,EAAEgB,MAAM6D,GAAM,EAAID,EAAMC,MACvDnI,EAAO6C,UAAP7C,GAAWuC,EAAKK,UAALL,EAAY2F,WAAWD,KAJ3BpL,EAAI,EAAGA,EAAImD,EAAO0G,KAAM7J,MAAxBA,GAOT,OAAOmD,EAAOqH,YAGhBhD,mBAAA,SAAO+D,EAAmBX,GAA1B,WACE,GAAyB,cAArBW,EAAQ,GAAG5L,MAAuB,CACpC,IAAM6L,EAAQD,EAAQ7C,KAAI,SAAC9G,GAAM,OAAA6J,OAAQ7J,MACnC8J,EAAQH,EAAQ7C,KAAI,SAAC9G,GAAM,OAAA+J,OAAQ/J,MACzC,OAAOgK,UAAWlE,KAAKmE,OAAOL,EAAOZ,GAAOlD,KAAKmE,OAAOH,EAAOd,IAEjE,IAAMkB,EAAYP,EAAQ7C,KAAI,SAAA9G,GAC5B,IAAMmK,EAAYlM,OAAKE,cAAc6B,EAAE6F,MAAMwD,MAAML,IACnD,OAAOhJ,EAAEoK,MAAM,EAAGD,MAEdrM,EACJmI,eAAa6C,gBAAgBoB,EAAUpD,KAAI,SAAA9G,GAAK,OAAAA,EAAE6F,SAAQ,GAEtDpE,EACFuF,SAAUlJ,EAA8B6L,EAAQ,GAAG5L,OAC9C0D,OACT,GAA8B,IAA1ByI,EAAU,GAAGrE,MAAM,GAAU,CAE/B,IAAIwE,EAAS,EACbH,EAAUnK,SAAQ,SAAAC,GAChByB,EAAO2C,IAAImB,EAAKc,SAASrG,EAAEmG,QAAuBkE,GAClDA,GAAUrK,EAAEiI,YAET,CACL,IAAIqC,EAAY,EAChBJ,EAAUnK,SAAQ,SAAAC,GAGhB,IAFA,IAAMuK,EAAQhF,EAAKc,SAASrG,EAAEmG,QAC1BqE,EAAO,EACFC,EAAM,EAAGA,EAAMzK,EAAE6F,MAAM,KAAM4E,EAEpC,IADA,IAAMC,EAASD,EAAM3M,EAAS,GAAKwM,EAC1BK,EAAM,EAAGA,EAAM3K,EAAE6F,MAAM,KAAM8E,EACpClJ,EAAOiJ,EAASC,GAAOJ,EAAMC,KAGjCF,GAAatK,EAAE6F,MAAM,MAGzB,IAAM+E,EACF3E,eAAa6C,gBAAgBa,EAAQ7C,KAAI,SAAA9G,GAAK,OAAAA,EAAE6F,SAAQmD,GAC5D,OAAOT,SAAU9G,EAAQmJ,EAAejB,EAAQ,GAAG5L,QAGrD6H,gBAAA,SAAsBf,GAGpB,OAFAlF,EAAiBkF,EAAG,OAEbiB,KAAK+E,SAASC,UAAW,GAAIjG,IAGtCe,gBAAA,SAAImF,EAAWlJ,GACb,MAAgB,cAAZkJ,EAAEhN,OAAqC,cAAZ8D,EAAE9D,MACxB+H,KAAKkF,2BACRD,EAAEE,KAAK,aAAcpJ,EAAEoJ,KAAK,cAC5B,SAACC,EAAOC,EAAOC,EAAOC,GACpB,MAAO,CAAC5E,KAAMyE,EAAQE,EAAOzE,KAAMwE,EAAQE,MAI5CvF,KAAKwF,oBACRP,EAAGlJ,EAAG0J,aAAWR,EAAEhN,MAAO8D,EAAE9D,QAC5B,SAACyN,EAAQC,GAAW,OAAAD,EAASC,MAGnC7F,iBAAA,SAAuB+D,GAAvB,WACEhK,EAAiBgK,EAAS,QAK1B,IAHA,IAAM3L,EAAO2L,EAAQ7C,KAAI,SAAA9G,GAAK,OAAAuF,EAAKc,SAASrG,EAAEmG,WACxC/G,EAAS4H,SAAU2C,EAAQ,GAAG9D,MAAO8D,EAAQ,GAAG5L,OAChD2N,EAAatM,EAAOqC,OACjBrD,EAAI,EAAGA,EAAIuL,EAAQtL,OAAQD,IAElC,IADA,IAAMuN,EAAW3N,EAAKI,GACbI,EAAI,EAAGA,EAAIkN,EAAWrN,OAAQG,IACrCkN,EAAWlN,IAAMmN,EAASnN,GAG9B,OAAOY,EAAOwJ,YAGhBhD,oBAAA,SAA0BgG,EAAWC,GACnC,IAAMC,EAAO7N,OAAK8N,eAAe,CAACF,GAAMD,EAAO/F,OAGzCmG,EAAWzN,MAAIqN,EAAQE,GACvBG,EACFhG,eAAaiG,qBAAqBF,EAASnG,MAAOiG,GAChDf,EAAIjF,KAAKqG,SAASP,EAAQI,EAASzC,QAAQ0C,IAC3CpK,EAAIiE,KAAKsG,IAAIrB,GACbsB,EAASvG,KAAKwG,IAAIzK,EAAGiK,GAAMvC,QAAQ0C,GAIzC,OAAOM,MAAO1K,EAAGwK,IAGnBzG,qBAAA,SAASmF,EAAWlJ,GAClB,MAAgB,cAAZkJ,EAAEhN,OAAqC,cAAZ8D,EAAE9D,MACxB+H,KAAKkF,2BACRD,EAAEE,KAAK,aAAcpJ,EAAEoJ,KAAK,cAC5B,SAACC,EAAOC,EAAOC,EAAOC,GACpB,MAAO,CAAC5E,KAAMyE,EAAQE,EAAOzE,KAAMwE,EAAQE,MAI5CvF,KAAKwF,oBACRP,EAAGlJ,EAAG0J,aAAWR,EAAEhN,MAAO8D,EAAE9D,QAC5B,SAACyN,EAAQC,GAAW,OAAAD,EAASC,MAGnC7F,gBAAA,SAAsBmF,EAAMlJ,GAG1B,OAFAlC,EAAiB,CAACoL,EAAGlJ,GAAI,OAElBiE,KAAKwF,oBACDP,EAAGlJ,EAAGkJ,EAAEhN,OAAO,SAACyN,EAAQC,GAAW,OAAAlJ,KAAKiK,IAAIhB,EAAQC,OAIjE7F,wBAAA,SACImF,EAAalJ,EAAa4K,EAC1BC,GACF/M,EAAiB,CAACoL,EAAGlJ,GAAI,UAqBzB,IAnBA,IAAM8K,EAAYF,EAAa1B,EAAElF,MAAM,GAAKkF,EAAElF,MAAM,GAC9C+G,EAAUH,EAAa1B,EAAElF,MAAM,GAAKkF,EAAElF,MAAM,GAC5CgH,EAAWH,EAAa7K,EAAEgE,MAAM,GAAKhE,EAAEgE,MAAM,GAC7CiH,EAAW/B,EAAElF,MAAM,GAEnBkH,EAAUjH,KAAKO,SAAS0E,EAAE5E,QAC1B6G,EAAUlH,KAAKO,SAASxE,EAAEsE,QAC1BG,gEAAC2G,OAAQC,OAAYC,OAGrBC,gEAACC,OAAYC,OAAYC,OAIzBtF,EAAO2E,EAAUC,EACjBzN,EAAS4H,SAAU,CAAC8F,EAAUF,EAASC,GAAW9B,EAAEhN,OACpDyP,EAAUpO,EAAOqC,OACjBgM,EAAY3H,KAAK2H,UAEdC,EAAI,EAAGA,EAAIZ,EAAUY,IAC5B,IAAK,IAAIC,EAAK,EAAGA,EAAKf,EAASe,GAAMF,EACnC,IAAK,IAAIG,EAAK,EAAGA,EAAKf,EAAUe,GAAMH,EACpC,IAAK,IAAII,EAAK,EAAGA,EAAKlB,EAAWkB,GAAMJ,EAMrC,IAJA,IAAMK,EAASvL,KAAKE,IAAIkL,EAAKF,EAAWb,GAClCmB,EAASxL,KAAKE,IAAImL,EAAKH,EAAWZ,GAClCmB,EAASzL,KAAKE,IAAIoL,EAAKJ,EAAWd,GAE/BvO,EAAIuP,EAAIvP,EAAI0P,EAAQ1P,IAC3B,IAAK,IAAII,EAAIoP,EAAIpP,EAAIuP,EAAQvP,IAAK,CAGhC,IAFA,IAAI8N,EAAM,EAED2B,EAAIJ,EAAII,EAAID,EAAQC,IAC3B3B,GAAOS,EAAQW,EAAIT,EAAS7O,EAAI8O,EAAae,EAAId,GAC7CH,EAAQiB,EAAIZ,EAAa7O,EAAI8O,EAAaI,EAAIH,GAEpDC,EAAQE,EAAIzF,GAAQ7J,EAAIyO,EAAWrO,KAAO8N,EAOtD,OAAOlN,EAAOwJ,YAGhBhD,6BAAA,SACIU,OAACyE,MAAGlJ,MAAG4K,eAAYC,eAAYwB,SAAMpJ,eAAYC,2BAE/C3F,EAAS0G,KAAKqI,YAAYpD,EAAGlJ,EAAG4K,EAAYC,GAShD,OARIwB,IACF9O,EAAS0G,KAAKsI,IAAIhP,EAAQ8O,IAExBpJ,IACF1F,EACIuF,EAAcmB,KAAM1G,EAAQ0F,EAAYC,IAGvC3F,GAGTwG,qBAAA,SAASmF,EAAWlJ,GAClB,MAAgB,cAAZkJ,EAAEhN,OAAqC,cAAZ8D,EAAE9D,MACxB+H,KAAKkF,2BACRD,EAAEE,KAAK,aAAcpJ,EAAEoJ,KAAK,cAC5B,SAACC,EAAOC,EAAOC,EAAOC,GACpB,MAAO,CACL5E,KAAMyE,EAAQE,EAAQD,EAAQE,EAC9B1E,KAAMuE,EAAQG,EAAQF,EAAQC,MAKjCtF,KAAKwF,oBACRP,EAAGlJ,EAAG0J,aAAWR,EAAEhN,MAAO8D,EAAE9D,QAC5B,SAACyN,EAAQC,GAAW,OAAAD,EAASC,MAGnC7F,qBAAA,SAASmF,EAAWlJ,GAClBlC,EAAiB,CAACoL,EAAGlJ,GAAI,YAIzB,OAAOiE,KAAKwF,oBAAoBP,EAAGlJ,EADf,SADT,SAACkJ,EAAWlJ,GAAc,OAAAU,KAAK8L,MAAMtD,EAAIlJ,OAKtD+D,gBAAA,SAAIf,EAAWiH,GACbnM,EAAiBkF,EAAG,OAEpBoB,eAAaqI,2BAA2B,MAAOxC,EAAMjH,EAAEqE,MASvD,IARM,IAAA5C,sDAACxI,OAAUyQ,OAEXC,EAAcjD,aAAW1G,EAAE9G,MAAO,SAClCqB,EAASqP,QAAS3Q,EAAU0Q,GAC5B3Q,EAAaI,OAAKE,cAAcoQ,GAChCvQ,EAAO8H,KAAKO,SAASjH,EAAO+G,QAE5BvI,EAAQkI,KAAKO,SAASxB,EAAEsB,QACrB/H,EAAI,EAAGA,EAAIJ,EAAKK,SAAUD,EAAG,CAGpC,IAFA,IAAME,EAASF,EAAIP,EACfyO,EAAM,EACD9N,EAAI,EAAGA,EAAIX,IAAcW,EAChC8N,GAAO1O,EAAMU,EAASE,GAExBR,EAAKI,GAAKkO,EAEZ,OAAOlN,GAGTwG,iBAAA,SAAKf,EAAWiH,GACdnM,EAAiBkF,EAAG,OAUpB,IARM,IAAAyB,sDAACxI,OAAUyQ,OAEXC,EAAcjD,aAAW1G,EAAE9G,MAAO,SAClCqB,EAASqP,QAAS3Q,EAAU0Q,GAC5B3Q,EAAaI,OAAKE,cAAcoQ,GAChCvQ,EAAO8H,KAAKO,SAASjH,EAAO+G,QAE5BvI,EAAQkI,KAAKO,SAASxB,EAAEsB,QACrB/H,EAAI,EAAGA,EAAIJ,EAAKK,SAAUD,EAAG,CAGpC,IAFA,IAAME,EAASF,EAAIP,EACf6Q,EAAO,EACFlQ,EAAI,EAAGA,EAAIX,IAAcW,EAChCkQ,GAAQ9Q,EAAMU,EAASE,GAEzBR,EAAKI,GAAKsQ,EAEZ,OAAOtP,GAGTwG,+BAAA,SACIf,EAAM8J,EAAsBC,GAC9BjP,EAAiBkF,EAAG,sBAOpB,IALA,IAAMyE,EAAM,GAINuF,EAAWhK,EAAEqE,KAAOyF,EAAWzF,KAC5B9K,EAAI,EAAGA,EAAIyQ,IAAYzQ,EAC9BuQ,EAAaA,EAAWG,WAAW1Q,EAAI,GAGzC,IAASA,EAAI,EAAGA,EAAIwQ,IAAexQ,EAAG,CACpC,IAAM2Q,EAAYjE,SAAU1M,EAAG,SAEzBkO,EADO0C,QAASD,EAAWJ,GAAYM,OAAO,WACnCC,IAAIrK,GAAGyH,IAAI,GAC5BhD,EAAI6F,KAAK7C,GAGX,OAAO8C,QAAS9F,IAGlB1D,mBAAA,SAAOf,EAAWmE,GAChBrJ,EAAiBkF,EAAG,UAEpB,IAAMiH,EAAO,CAAC9C,GACd/C,eAAaqI,2BAA2B,SAAUxC,EAAMjH,EAAEqE,MAQ1D,IAPM,IAAA5C,sDAACxI,OAAUyQ,OAEXnP,EAASqP,QAAS3Q,EAAU,SAC5BD,EAAaI,OAAKE,cAAcoQ,GAChCvQ,EAAO8H,KAAKO,SAASjH,EAAO+G,QAE5BvI,EAAQkI,KAAKO,SAASxB,EAAEsB,QACrB/H,EAAI,EAAGA,EAAIJ,EAAKK,SAAUD,EAAG,CAIpC,IAHA,IAAME,EAASF,EAAIP,EACf4E,EAAM7E,EAAMU,GACZ+Q,EAAW,EACN7Q,EAAI,EAAGA,EAAIX,IAAcW,EAAG,CACnC,IAAMC,EAAQb,EAAMU,EAASE,GACzBC,EAAQgE,IACVA,EAAMhE,EACN4Q,EAAW7Q,GAGfR,EAAKI,GAAKiR,EAEZ,OAAOjQ,GAGTwG,mBAAA,SAAOf,EAAWmE,GAChBrJ,EAAiBkF,EAAG,UAEpB,IAAMiH,EAAO,CAAC9C,GACd/C,eAAaqI,2BAA2B,SAAUxC,EAAMjH,EAAEqE,MAQ1D,IAPM,IAAA5C,sDAACxI,OAAUyQ,OAEXnP,EAASqP,QAAS3Q,EAAU,SAC5BD,EAAaI,OAAKE,cAAcoQ,GAChCvQ,EAAO8H,KAAKO,SAASjH,EAAO+G,QAE5BvI,EAAQkI,KAAKO,SAASxB,EAAEsB,QACrB/H,EAAI,EAAGA,EAAIJ,EAAKK,SAAUD,EAAG,CAIpC,IAHA,IAAME,EAASF,EAAIP,EACfyR,EAAM1R,EAAMU,GACZiR,EAAW,EACN/Q,EAAI,EAAGA,EAAIX,IAAcW,EAAG,CACnC,IAAMC,EAAQb,EAAMU,EAASE,GACzBC,EAAQ6Q,IACVA,EAAM7Q,EACN8Q,EAAW/Q,GAGfR,EAAKI,GAAKmR,EAEZ,OAAOnQ,GAGTwG,mBAAA,SAAOf,EAAWmE,EAAcwG,EAAoBC,GAIlD,GAFA9P,EAAiBkF,EAAG,UAEhBmE,IAASnE,EAAEqE,KAAO,EACpB,MAAM,IAAI7D,MACN,qDAAoDR,EAAEqE,KAAO,oBAC7CF,GAWtB,IATA,IAAMwF,EAAcjD,aAAW1G,EAAE9G,MAAO,SAClCqB,EAASqP,QAAS5J,EAAEgB,MAAO2I,GAC3BxQ,EAAO8H,KAAKO,SAASjH,EAAO+G,QAE5BvI,EAAQkI,KAAKO,SAASxB,EAAEsB,QACxBuJ,EAAW7K,EAAEgB,MAAMhB,EAAEqE,KAAO,GAC5ByG,EAAgBF,EAClB,SAACrR,EAAWI,GAAc,OAAAJ,EAAIsR,EAAWlR,EAAI,GAC7C,SAACJ,EAAWI,GAAc,OAAAJ,EAAII,GACzBJ,EAAI,EAAGA,EAAIR,EAAMS,OAAQD,GAAKsR,EACrC,IAAK,IAAIlR,EAAI,EAAGA,EAAIkR,EAAUlR,IAAK,CACjC,IAAMmK,EAAMgH,EAAcvR,EAAGI,GAC7B,GAAU,IAANA,EACFR,EAAK2K,GAAO6G,EAAY,EAAI5R,EAAM+K,OAC7B,CACL,IAAMiH,EAAUD,EAAcvR,EAAGI,EAAI,GACrCR,EAAK2K,GAAO6G,EAAY5R,EAAMgS,GAAW5R,EAAK4R,GACtBhS,EAAM+K,GAAO3K,EAAK4R,IAIhD,OAAOxQ,GAGTwG,kBAAA,SAAMmF,EAAWlJ,GAGf,OAFAlC,EAAiB,CAACoL,EAAGlJ,GAAI,SAElBiE,KAAKwF,oBAAoBP,EAAGlJ,EAAG,QAAQ,SAACgO,EAAMC,GACnD,OAAQD,IAASC,EAAQ,EAAI,MAIjClK,qBAAA,SAASmF,EAAWlJ,GAGlB,OAFAlC,EAAiB,CAACoL,EAAGlJ,GAAI,YAElBiE,KAAKwF,oBAAoBP,EAAGlJ,EAAG,QAAQ,SAACgO,EAAMC,GACnD,OAAQD,IAASC,EAAQ,EAAI,MAIjClK,iBAAA,SAAKmF,EAAWlJ,GAGd,OAFAlC,EAAiB,CAACoL,EAAGlJ,GAAI,QAElBiE,KAAKwF,oBAAoBP,EAAGlJ,EAAG,QAAQ,SAACgO,EAAMC,GACnD,OAAQD,EAAOC,EAAQ,EAAI,MAI/BlK,sBAAA,SAAUmF,EAAWlJ,GAGnB,OAFAlC,EAAiB,CAACoL,EAAGlJ,GAAI,aAElBiE,KAAKwF,oBAAoBP,EAAGlJ,EAAG,QAAQ,SAACgO,EAAMC,GACnD,OAAQD,GAAQC,EAAQ,EAAI,MAIhClK,oBAAA,SAAQmF,EAAWlJ,GAGjB,OAFAlC,EAAiB,CAACoL,EAAGlJ,GAAI,WAElBiE,KAAKwF,oBAAoBP,EAAGlJ,EAAG,QAAQ,SAACgO,EAAMC,GACnD,OAAQD,EAAOC,EAAQ,EAAI,MAI/BlK,yBAAA,SAAamF,EAAWlJ,GAGtB,OAFAlC,EAAiB,CAACoL,EAAGlJ,GAAI,gBAElBiE,KAAKwF,oBAAoBP,EAAGlJ,EAAG,QAAQ,SAACgO,EAAMC,GACnD,OAAQD,GAAQC,EAAQ,EAAI,MAIhClK,uBAAA,SAA6Bf,GAC3BlF,EAAiBkF,EAAG,cAIpB,IAFA,IAAMpD,EAASqE,KAAKO,SAASxB,EAAEsB,QACzB4J,EAAY,IAAIC,WAAWvO,EAAOpD,QAC/BD,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EACnC2R,EAAU3R,GAAKqD,EAAOrD,GAAK,EAAI,EAEjC,OAAO0H,KAAK8B,WAAWmI,EAAWlL,EAAEgB,MAAO,SAG7CD,uBAAA,SAAWmF,EAAWlJ,GAGpB,OAFAlC,EAAiB,CAACoL,EAAGlJ,GAAI,cAElBiE,KAAKwF,oBAAoBP,EAAGlJ,EAAG,QAAQ,SAACgO,EAAMC,GACnD,OAAOD,GAAQC,MAInBlK,sBAAA,SAAUmF,EAAWlJ,GAGnB,OAFAlC,EAAiB,CAACoL,EAAGlJ,GAAI,aAElBiE,KAAKwF,oBAAoBP,EAAGlJ,EAAG,QAAQ,SAACgO,EAAMC,GACnD,OAAOD,GAAQC,MAInBlK,mBAAA,SAAOqK,EAAmBlF,EAAWlJ,GACnClC,EAAiB,CAACsQ,EAAWlF,EAAGlJ,GAAI,UAYpC,IAVA,IAAMJ,EAASqE,KAAKO,SAAS4J,EAAU9J,QACjC4G,EAAUjH,KAAKO,SAAS0E,EAAE5E,QAC1B6G,EAAUlH,KAAKO,SAASxE,EAAEsE,QAC1B/G,EAASqP,QAAS1D,EAAElF,MAAO0F,aAAWR,EAAEhN,MAAO8D,EAAE9D,QACjDgS,EAAYjK,KAAKO,SAASjH,EAAO+G,QACnC+J,EAAQ,EACN5R,EAA4B,IAAnB2R,EAAU/G,MAAc+G,EAAU/G,KAAO,GAAgB,IAAX6B,EAAE7B,KAC3D,EACAjL,OAAKE,cAAc4M,EAAElF,MAAMwD,MAAM,IAE5BjL,EAAI,EAAGA,EAAIqD,EAAOpD,OAAQD,IACjC,IAAK,IAAII,EAAI,EAAGA,EAAIF,EAAQE,IACR,IAAdiD,EAAOrD,GACT2R,EAAUG,KAAWnD,EAAQ3O,GAE7B2R,EAAUG,KAAWlD,EAAQ5O,GAKnC,OAAOgB,GAGTwG,kBAAA,SAAMqK,GACJtQ,EAAiB,CAACsQ,GAAY,SAE9B,IAAME,EAAWrK,KAAKO,SAAS4J,EAAU9J,QACzC,OAAOzB,EAAUuL,EAAUpK,MAAOsK,IAGpCvK,iBAAA,SAAuBf,EAAMoJ,EAAWmC,GACtCzQ,EAAiBkF,EAAG,QAEpB,IAAMlG,EAAQmH,KAAKO,SAASxB,EAAEsB,QAC9B,OAAO1B,EAAS9F,EAAOkG,EAAEgB,MAAOhB,EAAE9G,MAA0BkQ,EAAGmC,IAGjExK,gBAAA,SAAIf,EAAWiH,GACbnM,EAAiBkF,EAAG,OAEpBoB,eAAaqI,2BAA2B,MAAOxC,EAAMjH,EAAEqE,MAQvD,IAPM,IAAA5C,sDAACxI,OAAUyQ,OAEXnP,EAASqP,QAAS3Q,EAAU+G,EAAE9G,OAC9BF,EAAaI,OAAKE,cAAcoQ,GAChCvQ,EAAO8H,KAAKO,SAASjH,EAAO+G,QAE5BvI,EAAQkI,KAAKO,SAASxB,EAAEsB,QACrB/H,EAAI,EAAGA,EAAIJ,EAAKK,SAAUD,EAAG,CAGpC,IAFA,IAAME,EAASF,EAAIP,EACf4E,EAAM7E,EAAMU,GACPE,EAAI,EAAGA,EAAIX,IAAcW,EAAG,CACnC,IAAMC,EAAQb,EAAMU,EAASE,GACzBC,EAAQgE,IACVA,EAAMhE,GAGVT,EAAKI,GAAKqE,EAEZ,OAAOrD,GAGTwG,oBAAA,SAAQmF,EAAWlJ,GAGjB,OAFAlC,EAAiB,CAACoL,EAAGlJ,GAAI,WAElBiE,KAAKwF,oBACRP,EAAGlJ,EAAGkJ,EAAEhN,OAAO,SAAC8R,EAAMC,GAAS,OAAAvN,KAAKE,IAAIoN,EAAMC,OAGpDlK,gBAAA,SAAImF,EAAWlJ,GAGb,OAFAlC,EAAiB,CAACoL,EAAGlJ,GAAI,OAElBiE,KAAKwF,oBAAoBP,EAAGlJ,EAAGkJ,EAAEhN,OAAO,SAAC8R,EAAMC,GACpD,IAAMO,EAAMR,EAAOC,EACnB,OAAKD,EAAO,GAAKC,EAAO,GAAOD,GAAQ,GAAKC,GAAQ,EAC3CO,GAECA,EAAMP,GAAQA,MAK5BlK,oBAAA,SAAQmF,EAAWlJ,GAGjB,OAFAlC,EAAiB,CAACoL,EAAGlJ,GAAI,WAElBiE,KAAKwF,oBACRP,EAAGlJ,EAAGkJ,EAAEhN,OAAO,SAAC8R,EAAMC,GAAS,OAAAvN,KAAKhE,IAAIsR,EAAMC,OAGpDlK,gBAAA,SAAIf,EAAWiH,GACbnM,EAAiBkF,EAAG,OAEpBoB,eAAaqI,2BAA2B,MAAOxC,EAAMjH,EAAEqE,MAQvD,IAPM,IAAA5C,sDAACxI,OAAUyQ,OAEXnP,EAASqP,QAAS3Q,EAAU+G,EAAE9G,OAC9BF,EAAaI,OAAKE,cAAcoQ,GAChCvQ,EAAO8H,KAAKO,SAASjH,EAAO+G,QAE5BvI,EAAQkI,KAAKO,SAASxB,EAAEsB,QACrB/H,EAAI,EAAGA,EAAIJ,EAAKK,SAAUD,EAAG,CAGpC,IAFA,IAAME,EAASF,EAAIP,EACfyS,EAAM1S,EAAMU,GACPE,EAAI,EAAGA,EAAIX,IAAcW,EAAG,CACnC,IAAMC,EAAQb,EAAMU,EAASE,GAC7B8R,EAAMA,GAAO7R,EAEfT,EAAKI,GAAKkS,EAEZ,OAAOlR,GAGTwG,gBAAA,SAAIf,EAAWiH,GACbnM,EAAiBkF,EAAG,OAEpBoB,eAAaqI,2BAA2B,MAAOxC,EAAMjH,EAAEqE,MAQvD,IAPM,IAAA5C,sDAACxI,OAAUyQ,OAEXnP,EAASqP,QAAS3Q,EAAU+G,EAAE9G,OAC9BF,EAAaI,OAAKE,cAAcoQ,GAChCvQ,EAAO8H,KAAKO,SAASjH,EAAO+G,QAE5BvI,EAAQkI,KAAKO,SAASxB,EAAEsB,QACrB/H,EAAI,EAAGA,EAAIJ,EAAKK,SAAUD,EAAG,CAGpC,IAFA,IAAME,EAASF,EAAIP,EACf0S,EAAS3S,EAAMU,GACVE,EAAI,EAAGA,EAAIX,IAAcW,EAAG,CACnC,IAAMC,EAAQb,EAAMU,EAASE,GAC7B+R,EAASA,GAAU9R,EAErBT,EAAKI,GAAKmS,EAEZ,OAAOnR,GAGTwG,8BAAA,SAAkBmF,EAAWlJ,GAG3B,OAFAlC,EAAiB,CAACoL,EAAGlJ,GAAI,qBAElBiE,KAAKwF,oBAAoBP,EAAGlJ,EAAGkJ,EAAEhN,OAAO,SAAC8R,EAAMC,GACpD,IAAMU,EAAOX,EAAOC,EACpB,OAAOU,EAAOA,MAIlB5K,iBAAA,SAAuBf,GACrBlF,EAAiBkF,EAAG,QAIpB,IAFA,IAAMpD,EAASqE,KAAKO,SAASxB,EAAEsB,QACzB4J,EAAY,IAAIU,aAAahP,EAAOpD,QACjCD,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EACnC2R,EAAU3R,GAAKmE,KAAKmO,KAAKjP,EAAOrD,IAElC,OAAO0H,KAAK8B,WAAWmI,EAAWlL,EAAEgB,MAAO,YAG7CD,kBAAA,SAAwBf,GACtBlF,EAAiBkF,EAAG,SAIpB,IAFA,IAAMpD,EAASqE,KAAKO,SAASxB,EAAEsB,QACzB4J,EAAY,IAAIU,aAAahP,EAAOpD,QACjCD,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EACnC2R,EAAU3R,GAAKmE,KAAK8L,MAAM5M,EAAOrD,IAEnC,OAAO0H,KAAK8B,WAAWmI,EAAWlL,EAAEgB,MAAO,YAG7CD,iBAAA,SAAuBf,GACrBlF,EAAiBkF,EAAG,KAIpB,IAFA,IAAMpD,EAASqE,KAAKO,SAASxB,EAAEsB,QACzB4J,EAAY,IAAIU,aAAahP,EAAOpD,QACjCD,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EAC/BqD,EAAOrD,GAAK,EACd2R,EAAU3R,IAAM,EACPqD,EAAOrD,GAAK,EACrB2R,EAAU3R,GAAK,EAEf2R,EAAU3R,GAAK,EAGnB,OAAO0H,KAAK8B,WAAWmI,EAAWlL,EAAEgB,MAAO,YAG7CD,kBAAA,SAAwBf,GACtBlF,EAAiBkF,EAAG,KAIpB,IAFA,IAAMpD,EAASqE,KAAKO,SAASxB,EAAEsB,QACzB4J,EAAY,IAAIC,WAAWvO,EAAOpD,QAC/BD,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EAC/B+C,OAAOsC,MAAMhC,EAAOrD,MACtB2R,EAAU3R,GAAK,GAGnB,OAAO0H,KAAK8B,WAAWmI,EAAWlL,EAAEgB,MAAO,SAG7CD,kBAAA,SAAwBf,GACtBlF,EAAiBkF,EAAG,KAIpB,IAFA,IAAMpD,EAASqE,KAAKO,SAASxB,EAAEsB,QACzB4J,EAAY,IAAIC,WAAWvO,EAAOpD,QAC/BD,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EAC/BmE,KAAKoO,IAAIlP,EAAOrD,MAAQwS,EAAAA,IAC1Bb,EAAU3R,GAAK,GAGnB,OAAO0H,KAAK8B,WAAWmI,EAAWlL,EAAEgB,MAAO,SAG7CD,qBAAA,SAA2Bf,GACzBlF,EAAiBkF,EAAG,KAIpB,IAFA,IAAMpD,EAASqE,KAAKO,SAASxB,EAAEsB,QACzB4J,EAAY,IAAIC,WAAWvO,EAAOpD,QAC/BD,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EAC/B+C,OAAO0P,SAASpP,EAAOrD,MACzB2R,EAAU3R,GAAK,GAGnB,OAAO0H,KAAK8B,WAAWmI,EAAWlL,EAAEgB,MAAO,SAG7CD,kBAAA,SAAwBf,GACtBlF,EAAiBkF,EAAG,SAIpB,IAFA,IAAMpD,EAASqE,KAAKO,SAASxB,EAAEsB,QACzB4J,EAAY,IAAIU,aAAahP,EAAOpD,QACjCD,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EAAG,CAEtC,IAAM0S,EAAOvO,KAAK8L,MAAM5M,EAAOrD,IAC3BqD,EAAOrD,GAAK0S,EAAO,GACrBf,EAAU3R,GAAKmE,KAAK8L,MAAM5M,EAAOrD,IACxBqD,EAAOrD,GAAK0S,EAAO,GAC5Bf,EAAU3R,GAAKmE,KAAKmO,KAAKjP,EAAOrD,IAG9B2R,EAAU3R,GADR0S,EAAO,GAAQ,EACFA,EAEAA,EAAO,EAI5B,OAAOhL,KAAK8B,WAAWmI,EAAWlL,EAAEgB,MAAO,YAG7CD,gBAAA,SAAsBf,GACpBlF,EAAiBkF,EAAG,OAIpB,IAFA,IAAMpD,EAASqE,KAAKO,SAASxB,EAAEsB,QACzB4J,EAAY,IAAIU,aAAahP,EAAOpD,QACjCD,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EACnC2R,EAAU3R,GAAKmE,KAAK6J,IAAI3K,EAAOrD,IAEjC,OAAO0H,KAAK8B,WAAWmI,EAAWlL,EAAEgB,MAAO,YAG7CD,kBAAA,SAAwBf,GACtBlF,EAAiBkF,EAAG,SAIpB,IAFA,IAAMpD,EAASqE,KAAKO,SAASxB,EAAEsB,QACzB4J,EAAY,IAAIU,aAAahP,EAAOpD,QACjCD,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EACnC2R,EAAU3R,GAAKmE,KAAKwO,MAAMtP,EAAOrD,IAEnC,OAAO0H,KAAK8B,WAAWmI,EAAWlL,EAAEgB,MAAO,YAG7CD,gBAAA,SAAsBf,GACpBlF,EAAiBkF,EAAG,OAIpB,IAFA,IAAMpD,EAASqE,KAAKO,SAASxB,EAAEsB,QACzB4J,EAAY,IAAIU,aAAahP,EAAOpD,QACjCD,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EAAG,CACtC,IAAMK,EAAQgD,EAAOrD,GACrB2R,EAAU3R,GAAKmE,KAAKyO,IAAIvS,GAE1B,OAAOqH,KAAK8B,WAAWmI,EAAWlL,EAAEgB,MAAO,YAG7CD,kBAAA,SAAwBf,GACtBlF,EAAiBkF,EAAG,SAIpB,IAFA,IAAMpD,EAASqE,KAAKO,SAASxB,EAAEsB,QACzB4J,EAAY,IAAIU,aAAahP,EAAOpD,QACjCD,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EAAG,CACtC,IAAMK,EAAQgD,EAAOrD,GACrB2R,EAAU3R,GAAKmE,KAAK0O,MAAMxS,GAE5B,OAAOqH,KAAK8B,WAAWmI,EAAWlL,EAAEgB,MAAO,YAG7CD,iBAAA,SAAuBf,GACrBlF,EAAiBkF,EAAG,QAIpB,IAFA,IAAMpD,EAASqE,KAAKO,SAASxB,EAAEsB,QACzB4J,EAAY,IAAIU,aAAahP,EAAOpD,QACjCD,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EAAG,CACtC,IAAMK,EAAQgD,EAAOrD,GACrB2R,EAAU3R,GAAKmE,KAAK2O,KAAKzS,GAE3B,OAAOqH,KAAK8B,WAAWmI,EAAWlL,EAAEgB,MAAO,YAG7CD,kBAAA,SAAwBf,GACtBlF,EAAiBkF,EAAG,SAIpB,IAFA,IAAMpD,EAASqE,KAAKO,SAASxB,EAAEsB,QACzB4J,EAAY,IAAIU,aAAahP,EAAOpD,QACjCD,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EAAG,CACtC,IAAMK,EAAQgD,EAAOrD,GACrB2R,EAAU3R,GAAK,EAAImE,KAAK2O,KAAKzS,GAE/B,OAAOqH,KAAK8B,WAAWmI,EAAWlL,EAAEgB,MAAO,YAG7CD,uBAAA,SAA6Bf,GAC3BlF,EAAiBkF,EAAG,cAIpB,IAFA,IAAMpD,EAASqE,KAAKO,SAASxB,EAAEsB,QACzB4J,EAAY,IAAIU,aAAahP,EAAOpD,QACjCD,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EACnC2R,EAAU3R,GAAK,EAAIqD,EAAOrD,GAE5B,OAAO0H,KAAK8B,WAAWmI,EAAWlL,EAAEgB,MAAO,YAG7CD,mBAAA,SAAyBf,GACvB,OAAOA,GAGTe,iBAAA,SAAuBf,GACrBlF,EAAiBkF,EAAG,QAKpB,IAHA,IAAMyE,EAAMmF,QAAS5J,EAAEgB,MAAOhB,EAAE9G,OAC1ByP,EAAU1H,KAAKO,SAASiD,EAAInD,QAC5BgL,EAASrL,KAAKO,SAASxB,EAAEsB,QACtB/H,EAAI,EAAGA,EAAI+S,EAAO9S,SAAUD,EACnCoP,EAAQpP,GAAKmE,KAAKhE,IAAI,EAAG4S,EAAO/S,IAElC,OAAOkL,GAGT1D,kBAAA,SAAwBf,GACtBlF,EAAiBkF,EAAG,QAKpB,IAHA,IAAMyE,EAAMmF,QAAS5J,EAAEgB,MAAOhB,EAAE9G,OAC1ByP,EAAU1H,KAAKO,SAASiD,EAAInD,QAC5BgL,EAASrL,KAAKO,SAASxB,EAAEsB,QACtB/H,EAAI,EAAGA,EAAI+S,EAAO9S,SAAUD,EACnCoP,EAAQpP,GAAKmE,KAAKE,IAAIF,KAAKhE,IAAI,EAAG4S,EAAO/S,IAAK,GAEhD,OAAOkL,GAGT1D,kBAAA,SAAwBf,EAAMkG,GAG5B,OAFApL,EAAiB,CAACkF,EAAGkG,GAAI,SAElBjF,KAAKwF,oBACDzG,EAAGkG,EAAGlG,EAAE9G,OACR,SAACqT,EAAQ5F,GAAW,OAAA4F,EAAS,EAAI5F,EAAS4F,EAASA,MAGhExL,gBAAA,SAAsBf,GACpBlF,EAAiBkF,EAAG,OAIpB,IAFA,IAAMwM,EAAe,IAAIZ,aAAa5L,EAAEoD,MAClCxG,EAASqE,KAAKO,SAASxB,EAAEsB,QACtB/H,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EAAG,CACtC,IAAMkT,EAAI7P,EAAOrD,GAEfiT,EAAajT,GADXkT,GAAK,EACWA,EAEC/O,KAAK6J,IAAIkF,GAAK,EAGrC,OAAOxL,KAAK8B,WAAWyJ,EAAcxM,EAAEgB,MAAO,YAGhDD,mBAAA,SAAyB2L,EAAOC,GAC9B7R,EAAiB,CAAC4R,EAAIC,GAAI,UAK1B,IAHA,IAAMH,EAAe,IAAIZ,aAAae,EAAEvJ,MAClCxG,EAASqE,KAAKO,SAASmL,EAAErL,QACzBsL,EAAW3L,KAAKO,SAASkL,EAAGpL,QACzB/H,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EAAG,CACtC,IAAMkT,EAAI7P,EAAOrD,GAEfiT,EAAajT,GADXkT,GAAK,EACWG,EAASrT,GAETqT,EAASrT,IAAMkT,EAAI,GAGzC,OAAOxL,KAAK8B,WAAWyJ,EAAcG,EAAE3L,MAAO,YAGhDD,iBAAA,SAAuBf,GACrBlF,EAAiBkF,EAAG,QASpB,IALA,IAAM6M,EAAazL,eAAa0L,gBAC1BC,EAAQ3L,eAAa4L,WAErBR,EAAe,IAAIZ,aAAa5L,EAAEoD,MAClCxG,EAASqE,KAAKO,SAASxB,EAAEsB,QACtB/H,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EAAG,CACtC,IAAMkT,EAAI7P,EAAOrD,GAEfiT,EAAajT,GADXkT,GAAK,EACWM,EAAQN,EAERI,GAAcnP,KAAK6J,IAAIkF,GAAK,GAGlD,OAAOxL,KAAK8B,WAAWyJ,EAAcxM,EAAEgB,MAAO,YAGhDD,iBAAA,SAAuBf,EAAMpC,EAAalE,GACxCoB,EAAiBkF,EAAG,QAIpB,IAFA,IAAMwM,EAAe,IAAIZ,aAAa5L,EAAEoD,MAClCxG,EAASqE,KAAKO,SAASxB,EAAEsB,QACtB/H,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EAAG,CACtC,IAAMkT,EAAI7P,EAAOrD,GACjBiT,EAAajT,GAAKkT,EAAI/S,EAAMA,EAAO+S,EAAI7O,EAAMA,EAAM6O,EAErD,OAAOxL,KAAK8B,WAAWyJ,EAAcxM,EAAEgB,MAAO,YAGhDD,gBAAA,SAAsBf,GAGpB,IAFA,IAAMwM,EAAe,IAAIZ,aAAa5L,EAAEoD,MAClCxG,EAASqE,KAAKO,SAASxB,EAAEsB,QACtB/H,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EACnCiT,EAAajT,GAAKmE,KAAKoO,IAAIlP,EAAOrD,IAGpC,OAAO0H,KAAK8B,WAAWyJ,EAAcxM,EAAEgB,MAAO,YAGhDD,uBAAA,SAA6Bf,GAI3B,IAHA,IAAMwM,EAAe,IAAIZ,aAAa5L,EAAEoD,MAClCxG,EAASqE,KAAKO,SAASxB,EAAEsB,QAEtB/H,EAAI,EAAGA,EAAIyG,EAAEoD,OAAQ7J,EAAG,CAC/B,IAAMqI,EAAOhF,EAAW,EAAJrD,GACduI,EAAOlF,EAAW,EAAJrD,EAAQ,GAC5BiT,EAAajT,GAAKmE,KAAKuP,MAAMrL,EAAME,GAErC,OAAOb,KAAK8B,WAAWyJ,EAAcxM,EAAEgB,MAAO,YAGhDD,gBAAA,SAAsBf,GACpBlF,EAAiBkF,EAAG,OAIpB,IAFA,IAAMwM,EAAe,IAAIU,WAAWlN,EAAEoD,MAChCxG,EAASqE,KAAKO,SAASxB,EAAEsB,QACtB/H,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EACnCiT,EAAajT,GAAKqD,EAAOrD,GAE3B,OAAO0H,KAAK8B,WAAWyJ,EAAcxM,EAAEgB,MAAO,UAGhDD,oBAAA,SAA0Bf,GACxBlF,EAAiBkF,EAAG,WAIpB,IAFA,IAAMwM,EAAe,IAAIZ,aAAa5L,EAAEoD,MAClCxG,EAASqE,KAAKO,SAASxB,EAAEsB,QACtB/H,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EACnCiT,EAAajT,GAAK,GAAK,EAAImE,KAAK6J,KAAK3K,EAAOrD,KAE9C,OAAO0H,KAAK8B,WAAWyJ,EAAcxM,EAAEgB,MAAO,YAGhDD,qBAAA,SAA2Bf,GACzBlF,EAAiBkF,EAAG,YAapB,IANA,IACMmN,EAAYzP,KAAKyO,IADP,uBACsB,EAEhCK,EAAe,IAAIZ,aAAa5L,EAAEoD,MAClCxG,EAASqE,KAAKO,SAASxB,EAAEsB,QAEtB/H,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EAAG,CAGtC,IAAM6T,EAAWxQ,EAAOrD,IAAM4T,EAIxBE,EAAWzQ,EAAOrD,GAAK4T,EAEvBG,EAAO5P,KAAK6J,IAAI3K,EAAOrD,IACzBgB,SAGFA,EADE8S,EACOC,EACAF,EACAxQ,EAAOrD,GAEPmE,KAAKyO,IAAI,EAAMmB,GAE1Bd,EAAajT,GAAKgB,EAEpB,OAAO0G,KAAK8B,WAAWyJ,EAAcxM,EAAEgB,MAAO,YAGhDD,gBAAA,SAAsBf,GACpBlF,EAAiBkF,EAAG,OAIpB,IAFA,IAAMwM,EAAe,IAAIZ,aAAa5L,EAAEoD,MAClCxG,EAASqE,KAAKO,SAASxB,EAAEsB,QACtB/H,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EACnCiT,EAAajT,GAAKmE,KAAK6P,IAAI3Q,EAAOrD,IAEpC,OAAO0H,KAAK8B,WAAWyJ,EAAcxM,EAAEgB,MAAO,YAGhDD,gBAAA,SAAsBf,GACpBlF,EAAiBkF,EAAG,OAIpB,IAFA,IAAMwM,EAAe,IAAIZ,aAAa5L,EAAEoD,MAClCxG,EAASqE,KAAKO,SAASxB,EAAEsB,QACtB/H,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EACnCiT,EAAajT,GAAKmE,KAAK8P,IAAI5Q,EAAOrD,IAEpC,OAAO0H,KAAK8B,WAAWyJ,EAAcxM,EAAEgB,MAAO,YAGhDD,gBAAA,SAAsBf,GACpBlF,EAAiBkF,EAAG,OAIpB,IAFA,IAAMwM,EAAe,IAAIZ,aAAa5L,EAAEoD,MAClCxG,EAASqE,KAAKO,SAASxB,EAAEsB,QACtB/H,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EACnCiT,EAAajT,GAAKmE,KAAK+P,IAAI7Q,EAAOrD,IAEpC,OAAO0H,KAAK8B,WAAWyJ,EAAcxM,EAAEgB,MAAO,YAGhDD,iBAAA,SAAuBf,GACrBlF,EAAiBkF,EAAG,QAIpB,IAFA,IAAMwM,EAAe,IAAIZ,aAAa5L,EAAEoD,MAClCxG,EAASqE,KAAKO,SAASxB,EAAEsB,QACtB/H,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EACnCiT,EAAajT,GAAKmE,KAAKgQ,KAAK9Q,EAAOrD,IAErC,OAAO0H,KAAK8B,WAAWyJ,EAAcxM,EAAEgB,MAAO,YAGhDD,iBAAA,SAAuBf,GACrBlF,EAAiBkF,EAAG,QAIpB,IAFA,IAAMwM,EAAe,IAAIZ,aAAa5L,EAAEoD,MAClCxG,EAASqE,KAAKO,SAASxB,EAAEsB,QACtB/H,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EACnCiT,EAAajT,GAAKmE,KAAKiQ,KAAK/Q,EAAOrD,IAErC,OAAO0H,KAAK8B,WAAWyJ,EAAcxM,EAAEgB,MAAO,YAGhDD,iBAAA,SAAuBf,GACrBlF,EAAiBkF,EAAG,QAIpB,IAFA,IAAMwM,EAAe,IAAIZ,aAAa5L,EAAEoD,MAClCxG,EAASqE,KAAKO,SAASxB,EAAEsB,QACtB/H,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EACnCiT,EAAajT,GAAKmE,KAAKkQ,KAAKhR,EAAOrD,IAErC,OAAO0H,KAAK8B,WAAWyJ,EAAcxM,EAAEgB,MAAO,YAGhDD,kBAAA,SAAwBmF,EAAMlJ,GAG5B,OAFAlC,EAAiB,CAACoL,EAAGlJ,GAAI,SAElBiE,KAAKwF,oBACDP,EAAGlJ,EAAGkJ,EAAEhN,OAAO,SAACyN,EAAQC,GAAW,OAAAlJ,KAAKmQ,MAAMlH,EAAQC,OAInE7F,iBAAA,SAAuBf,GACrBlF,EAAiBkF,EAAG,QAIpB,IAFA,IAAMwM,EAAe,IAAIZ,aAAa5L,EAAEoD,MAClCxG,EAASqE,KAAKO,SAASxB,EAAEsB,QACtB/H,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EACnCiT,EAAajT,GAAKmE,KAAKoQ,KAAKlR,EAAOrD,IAErC,OAAO0H,KAAK8B,WAAWyJ,EAAcxM,EAAEgB,MAAO,YAGhDD,iBAAA,SAAuBf,GACrBlF,EAAiBkF,EAAG,QAIpB,IAFA,IAAMwM,EAAe,IAAIZ,aAAa5L,EAAEoD,MAClCxG,EAASqE,KAAKO,SAASxB,EAAEsB,QACtB/H,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EACnCiT,EAAajT,GAAKmE,KAAKqQ,KAAKnR,EAAOrD,IAErC,OAAO0H,KAAK8B,WAAWyJ,EAAcxM,EAAEgB,MAAO,YAGhDD,iBAAA,SAAuBf,GACrBlF,EAAiBkF,EAAG,QAIpB,IAFA,IAAMwM,EAAe,IAAIZ,aAAa5L,EAAEoD,MAClCxG,EAASqE,KAAKO,SAASxB,EAAEsB,QACtB/H,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EACnCiT,EAAajT,GAAKH,OAAK4U,KAAKpR,EAAOrD,IAErC,OAAO0H,KAAK8B,WAAWyJ,EAAcxM,EAAEgB,MAAO,YAGhDD,kBAAA,SAAwBf,GACtBlF,EAAiBkF,EAAG,SAIpB,IAFA,IAAMwM,EAAe,IAAIZ,aAAa5L,EAAEoD,MAClCxG,EAASqE,KAAKO,SAASxB,EAAEsB,QACtB/H,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EACnCiT,EAAajT,GAAKmE,KAAKuQ,MAAMrR,EAAOrD,IAEtC,OAAO0H,KAAK8B,WAAWyJ,EAAcxM,EAAEgB,MAAO,YAGhDD,kBAAA,SAAwBf,GACtBlF,EAAiBkF,EAAG,SAIpB,IAFA,IAAMwM,EAAe,IAAIZ,aAAa5L,EAAEoD,MAClCxG,EAASqE,KAAKO,SAASxB,EAAEsB,QACtB/H,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EACnCiT,EAAajT,GAAKmE,KAAKwQ,MAAMtR,EAAOrD,IAEtC,OAAO0H,KAAK8B,WAAWyJ,EAAcxM,EAAEgB,MAAO,YAGhDD,kBAAA,SAAwBf,GACtBlF,EAAiBkF,EAAG,SAIpB,IAFA,IAAMwM,EAAe,IAAIZ,aAAa5L,EAAEoD,MAClCxG,EAASqE,KAAKO,SAASxB,EAAEsB,QACtB/H,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EACnCiT,EAAajT,GAAKmE,KAAKyQ,MAAMvR,EAAOrD,IAEtC,OAAO0H,KAAK8B,WAAWyJ,EAAcxM,EAAEgB,MAAO,YAGhDD,gBAAA,SAAsBf,GACpBlF,EAAiBkF,EAAG,OAUpB,IARA,IAAMwM,EAAe,IAAIZ,aAAa5L,EAAEoD,MAClCxG,EAASqE,KAAKO,SAASxB,EAAEsB,QACzB8M,EAAIhN,eAAaiN,MACjBC,EAAKlN,eAAamN,OAClBC,EAAKpN,eAAaqN,OAClBC,EAAKtN,eAAauN,OAClBC,EAAKxN,eAAayN,OAClBC,EAAK1N,eAAa2N,OACfxV,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EAAG,CACtC,IAAMyV,EAAOtR,KAAKsR,KAAKpS,EAAOrD,IACxBkT,EAAI/O,KAAKoO,IAAIlP,EAAOrD,IACpB4B,EAAI,GAAO,EAAMiT,EAAI3B,GAC3BD,EAAajT,GAAKyV,GACb,MACKF,EAAK3T,EAAIyT,GAAMzT,EAAKuT,GAAMvT,EAAIqT,GAAMrT,EAAImT,GAAMnT,EAC/CuC,KAAK6J,KAAKkF,EAAIA,IAEzB,OAAOxL,KAAK8B,WAAWyJ,EAAcxM,EAAEgB,MAAO,YAGhDD,iBAAA,SAAuBf,EAAMiP,gBAAAA,KAC3BnU,EAAiBkF,EAAG,QAIpB,IAFA,IAAMwM,EAAe,IAAIZ,aAAa5L,EAAEoD,MAClCxG,EAASqE,KAAKO,SAASxB,EAAEsB,QACtB/H,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EAAG,CACtC,IAAMK,EAAQgD,EAAOrD,GACjBqF,MAAMhF,GACR4S,EAAajT,GAAK2V,IAElB1C,EAAajT,GAAKK,EAAQ,EAAI,EAAIqV,EAGtC,OAAOhO,KAAK8B,WAAWyJ,EAAcxM,EAAEgB,MAAO,YAGhDD,wBAAA,SACIU,OAACyB,UAAOiM,WAAQ3T,aAAU6N,SAAMpJ,eAAYC,2BAE1C3F,EAAS0G,KAAKmO,OAAOlM,EAAOiM,EAAQ3T,GAUxC,OARI6N,IACF9O,EAAS0G,KAAKsI,IAAIhP,EAAQ8O,IAExBpJ,IACF1F,EACIuF,EAAcmB,KAAM1G,EAAQ0F,EAAYC,IAGvC3F,GAGTwG,mBAAA,SAAOf,EAAamP,EAAkB3T,GAEpCV,EAAiB,CAACkF,EAAGmP,GAAS,UAyB9B,IAvBA,IAAME,EAAe7T,EAAS6T,aACxBC,EAAc9T,EAAS8T,YACvB1T,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBM,EAAUX,EAASS,QAAQG,KAC3BJ,EAASR,EAASS,QAAQC,IAC1BqT,EAAyC,iBAAxB/T,EAASgU,WAE1B7C,EAAIxK,SAAU3G,EAASvC,SAAU+G,EAAE9G,OAEnCuW,EAAezP,EAAEzE,QAAQ,GACzBmU,EAAaH,EAAiBvP,EAAEzE,QAAQ,GAAKyE,EAAEzE,QAAQ,GACvDoU,EAAaJ,EAAiBvP,EAAEzE,QAAQ,GAAK,EAC7CqU,EAAiBL,EAAiB,EAAIvP,EAAEzE,QAAQ,GAChDsU,EAAelD,EAAEpR,QAAQ,GACzBuU,EAAaP,EAAiB5C,EAAEpR,QAAQ,GAAKoR,EAAEpR,QAAQ,GACvDwU,EAAaR,EAAiB5C,EAAEpR,QAAQ,GAAK,EAC7CyU,EAAiBT,EAAiB,EAAI5C,EAAEpR,QAAQ,GAEhDzB,EAAQmH,KAAKO,SAASxB,EAAEsB,QACxB2O,EAAQhP,KAAKO,SAAS2N,EAAO7N,QAC7B4O,EAAQvD,EAAE/P,OAEPI,EAAI,EAAGA,EAAIxB,EAASyB,YAAaD,EAGxC,IAFA,IAAMmT,EAAWnT,EAAIyS,EACfW,EAAWpT,EAAI6S,EACZvS,EAAK,EAAGA,EAAK9B,EAAS+B,YAAaD,EAG1C,IAFA,IAAM+S,EAAWD,EAAW9S,EAAKwS,EAC3BtS,EAAWF,EAAK9B,EAASE,aAAeM,EACrCoD,EAAK,EAAGA,EAAKiQ,EAAcjQ,IAAM,CACxC,IAAMZ,EAAKhB,EAAW4B,EAAKxD,EAC3B,KAAI4C,EAAK,GAAKA,GAAMhD,EAASqC,UAK7B,IAFA,IAAMyS,EAAWlR,EAAK+P,EAAO5T,QAAQ,GAC/BgV,EAAWJ,EAAW3R,EAAKkR,EACxB3R,EAAK,EAAGA,EAAKvC,EAASwC,WAAYD,EAGzC,IAFA,IAAMyS,EAAWH,EAAWtS,EAAKgS,EAC3B9R,EAAWF,EAAKvC,EAASG,YAAcQ,EACpCkD,EAAK,EAAGA,EAAKiQ,EAAajQ,IAAM,CACvC,IAAMX,EAAKT,EAAWoB,EAAKxD,EAC3B,KAAI6C,EAAK,GAAKA,GAAMlD,EAAS4C,SAM7B,IAHA,IACMqS,EAAWF,EAAW7R,EAAKiR,EAC7Be,EAFaJ,EAAWjR,EAAK8P,EAAO5T,QAAQ,GAGvCoV,EAAK,EAAGA,EAAKnV,EAAS6B,aAAcsT,EAAI,CAE/C,IADA,IAAMC,EAAO9W,EAAM2W,EAAWE,EAAKf,GAC1BiB,EAAK,EAAGA,EAAKrV,EAASsV,cAAeD,EAC5CX,EAAMM,EAAWK,EAAKb,IAClBY,EAAOX,EAAMS,EAAWG,GAE9BH,GAAYlV,EAASsV,cAOjC,OAAOnE,EAAE5I,YAGXhD,mBAAA,SAAOf,EAAamP,EAAkB3T,GAiBpC,IAfA,IAAMuV,EAAcvV,EAASuV,YACvB1B,EAAe7T,EAAS6T,aACxBC,EAAc9T,EAAS8T,YACvB0B,EAAgBxV,EAASwV,cACzBpV,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBoV,EAAWzV,EAASS,QAAQiV,MAC5B/U,EAAUX,EAASS,QAAQG,KAC3BJ,EAASR,EAASS,QAAQC,IAC1ByQ,EAAIxK,SAAmB3G,EAASvC,SAAU+G,EAAE9G,OAE5CY,EAAQmH,KAAKO,SAASxB,EAAEsB,QACxB2O,EAAQhP,KAAKO,SAAS2N,EAAO7N,QAC7B4O,EAAQvD,EAAE/P,OAEPI,EAAI,EAAGA,EAAIxB,EAASyB,YAAaD,EAGxC,IAFA,IAAMmT,EAAWnT,EAAIgD,EAAEzE,QAAQ,GACzB6U,EAAWpT,EAAI2P,EAAEpR,QAAQ,GACtB4V,EAAK,EAAGA,EAAK3V,EAAS4V,WAAYD,EAGzC,IAFA,IAAMd,EAAWD,EAAWe,EAAKxE,EAAEpR,QAAQ,GACrC8V,EAAWF,EAAK3V,EAAS8V,YAAcL,EACpCM,EAAK,EAAGA,EAAKR,EAAaQ,IAAM,CACvC,IAAMC,EAAKH,EAAWE,EAAKP,EAC3B,KAAIQ,EAAK,GAAKA,GAAMhW,EAASiW,SAM7B,IAHA,IAAMnB,EAAWiB,EAAKpC,EAAO5T,QAAQ,GAC/BgV,EAAWJ,EAAWqB,EAAKxR,EAAEzE,QAAQ,GAElC+B,EAAK,EAAGA,EAAK9B,EAAS+B,YAAaD,EAG1C,IAFA,IAAMkT,EAAWH,EAAW/S,EAAKqP,EAAEpR,QAAQ,GACrCiC,EAAWF,EAAK9B,EAASE,aAAeM,EACrCoD,EAAK,EAAGA,EAAKiQ,EAAcjQ,IAAM,CACxC,IAAMZ,EAAKhB,EAAW4B,EAAKxD,EAC3B,KAAI4C,EAAK,GAAKA,GAAMhD,EAASqC,UAK7B,IAFA,IAAM6T,EAAWpB,EAAWlR,EAAK+P,EAAO5T,QAAQ,GAC1CkV,EAAWF,EAAW/R,EAAKwB,EAAEzE,QAAQ,GAClCwC,EAAK,EAAGA,EAAKvC,EAASwC,WAAYD,EAGzC,IAFA,IAAM4T,EAAWnB,EAAWzS,EAAKvC,EAASsV,YACpC7S,EAAWF,EAAKvC,EAASG,YAAcQ,EACpCkD,EAAK,EAAGA,EAAKiQ,EAAajQ,IAAM,CACvC,IAAMX,EAAKT,EAAWoB,EAAKxD,EAC3B,KAAI6C,EAAK,GAAKA,GAAMlD,EAAS4C,SAM7B,IAHA,IAAMsS,EAAWgB,EAAWrS,EAAK8P,EAAO5T,QAAQ,GAC1CqW,EAAWnB,EAAW/R,EAAKlD,EAAS6B,WACtCwU,EAAWnB,EACNC,EAAK,EAAGA,EAAKnV,EAAS6B,aAAcsT,EAAI,CAE/C,IADA,IAAMC,EAAO9W,EAAM8X,EAAWjB,GACrBE,EAAK,EAAGA,EAAKrV,EAASsV,cAAeD,EAC5CX,EAAMyB,EAAWd,IAAOD,EAAOX,EAAM4B,EAAWhB,GAElDgB,GAAYrW,EAASsV,eASrC,OAAOnE,EAAE5I,YAGXhD,2BAAA,SACI2L,EAAcyC,EACd3T,GACFV,EAAiB,CAAC4R,EAAIyC,GAAS,kBAkC/B,IAhCA,IAAM2C,EAAK3P,SAAmB3G,EAASuW,QAAS,WAC1CC,EAAWF,EAAGlV,OACdgQ,EAAW3L,KAAKO,SAASkL,EAAGpL,QAC5B2Q,EAAYhR,KAAKO,SAAS2N,EAAO7N,QACjCG,YAACyQ,OAAOC,OAAOC,OAEnBnV,cACAoS,iBACAC,gBACAjS,eACAQ,aACAO,YACA0S,gBACAvT,cACAS,aACAtC,iBACAC,gBACA6T,eAEI6C,EAAShD,EAAe,EAAI7T,EAASS,QAAQC,IAC7CoW,EAAUhD,EAAc,EAAI9T,EAASS,QAAQG,KAE7CmT,EAAgC,iBAAfC,EACjBC,EAAeqC,EAAGvW,QAAQ,GAC1BmU,EAAaH,EAAiBuC,EAAGvW,QAAQ,GAAKuW,EAAGvW,QAAQ,GACzDoU,EAAaJ,EAAiBuC,EAAGvW,QAAQ,GAAK,EAC9CqU,EAAiBL,EAAiB,EAAIuC,EAAGvW,QAAQ,GACjDsU,EAAenD,EAAGnR,QAAQ,GAC1BuU,EAAaP,EAAiB7C,EAAGnR,QAAQ,GAAKmR,EAAGnR,QAAQ,GACzDwU,EAAaR,EAAiB7C,EAAGnR,QAAQ,GAAK,EAC9CyU,EAAiBT,EAAiB,EAAI7C,EAAGnR,QAAQ,GAE9CyB,EAAI,EAAGA,EAAIC,IAAaD,EAC/B,IAAK,IAAI2T,EAAK,EAAGA,EAAKtT,IAAcsT,EAClC,IAAK,IAAInS,EAAK,EAAGA,EAAKX,IAAYW,EAMhC,IALA,IAAMhB,EAAWgB,EAAK6T,EAChB5U,EAAQC,KAAKhE,IAAI,EAAGgE,KAAKmO,KAAKrO,EAAW9B,IACzC6W,EACF7U,KAAKE,IAAIL,GAAY8R,EAAe7R,GAAY9B,GAE3CgD,EAAK,EAAGA,EAAKN,IAAWM,EAAI,CAOnC,IANA,IAAMT,EAAWS,EAAK4T,EAChBpU,EAAQR,KAAKhE,IAAI,EAAGgE,KAAKmO,KAAK5N,EAAWtC,IACzC6W,EACF9U,KAAKE,IAAII,GAAWsR,EAAcrR,GAAYtC,GAE9C8W,EAAU,EACLnV,EAAKG,EAAOH,EAAKiV,IAASjV,EAGjC,IAFA,IAAM8B,EAAK9B,EAAK5B,EAAe8B,EAEtBO,EAAKG,EAAOH,EAAKyU,IAASzU,EAOjC,IANA,IACM2U,EACF7C,EAAe7S,EAAI8S,EAAaxS,EAAKyS,EAAahS,EAChD4U,EAAYT,GAAS7C,EAAe,EAAIjQ,GAC1C+S,GAAS7C,EAAc,GAJhBvR,EAAKpC,EAAcsC,IAIOmU,EAAQzB,EAEpCE,EAAK,EAAGA,EAAKC,IAAeD,EAAI,CAGvC4B,GAFc7F,EAAS8F,EAAW1C,EAAiBa,GACpCoB,EAAUU,EAAY9B,GAO3CmB,EAFiBvC,EAAezS,EAAI0S,EAAalR,EAC7CmR,EAAajR,EAAKkR,EAAiBe,GAClB8B,EAK7B,OAAOX,EAAG/N,YAGZhD,2BAAA,SACI2L,EAAcyC,EACd3T,GA6BF,IA5BA,IAAMsW,EAAK3P,SAAmB3G,EAASuW,QAAS,WAC1CC,EAAWF,EAAGlV,OACd6E,YAACmR,OAAMC,OAAMC,OAAMC,OACnBnG,EAAW3L,KAAKO,SAASkL,EAAGpL,QAC5BiH,YAACyK,OAAMC,OAAMC,OAAMC,OACnBlB,EAAYhR,KAAKO,SAAS2N,EAAO7N,QACjC8R,YAAClB,OAAOC,OAAOC,OAAOiB,OAE1BpW,cACA8T,gBACA1B,iBACAC,gBACAjS,eACAoU,YACA5T,aACAO,YACA0S,gBACAM,aACA7T,cACAS,aACAsT,gBACA5V,iBACAC,gBAEI2X,EAAWvC,EAAc,EAAIvV,EAASS,QAAQiV,MAC9CmB,EAAShD,EAAe,EAAI7T,EAASS,QAAQC,IAC7CoW,EAAUhD,EAAc,EAAI9T,EAASS,QAAQG,KAE1CY,EAAI,EAAGA,EAAIC,IAAaD,EAC/B,IAAK,IAAI2T,EAAK,EAAGA,EAAKtT,IAAcsT,EAElC,IAAK,IAAIa,EAAK,EAAGA,EAAKC,IAAWD,EAO/B,IANA,IAAMH,EAAWG,EAAK8B,EAChBC,EAAQ7V,KAAKhE,IAAI,EAAGgE,KAAKmO,KAAKwF,EAAWC,IACzCkC,EACF9V,KAAKE,IAAIwT,GAAWL,EAAcM,GAAYC,GAGzC9S,EAAK,EAAGA,EAAKX,IAAYW,EAMhC,IALA,IAAMhB,EAAWgB,EAAK6T,EAChB5U,EAAQC,KAAKhE,IAAI,EAAGgE,KAAKmO,KAAKrO,EAAW9B,IACzC6W,EACF7U,KAAKE,IAAIL,GAAY8R,EAAe7R,GAAY9B,GAE3CgD,EAAK,EAAGA,EAAKN,IAAWM,EAAI,CAOnC,IANA,IAAMT,EAAWS,EAAK4T,EAChBpU,EAAQR,KAAKhE,IAAI,EAAGgE,KAAKmO,KAAK5N,EAAWtC,IACzC6W,GACF9U,KAAKE,IAAII,GAAWsR,EAAcrR,GAAYtC,GAE9C8W,GAAU,EACLtB,GAAKoC,EAAOpC,GAAKqC,IAASrC,GAGjC,IAFA,IAAMI,GAAKJ,GAAKG,EAAcD,EAErB/T,GAAKG,EAAOH,GAAKiV,IAASjV,GAGjC,IAFA,IAAM8B,GAAK9B,GAAK5B,EAAe8B,EAEtBO,GAAKG,EAAOH,GAAKyU,KAASzU,GAQjC,IAPA,IACM2U,GACFM,EAAOhW,EAAIiW,EAAO9B,GAAK+B,EAAO5V,GAAK6V,EAAOpV,GACxC4U,GAAYT,GAASnB,EAAc,EAAIQ,IACzCY,GAAS9C,EAAe,EAAIjQ,IAC5BgT,GAAS9C,EAAc,GALhBvR,GAAKpC,EAAcsC,IAKOoV,EAAQ1C,EAEpCE,GAAK,EAAGA,GAAKC,IAAeD,GAAI,CAGvC4B,IAFc7F,EAAS8F,GAAW7B,IACnBoB,EAAUU,GAAY9B,IAM7CmB,EAASY,EAAO5V,EAAI6V,EAAOrB,EAAKsB,EAAOtU,EAAKuU,EAAOrU,EAAKiS,GACpD8B,GAMd,OAAOX,EAAG/N,YAGZhD,4BAAA,SAAgBf,EAAa0M,EAAclR,GAEzCV,EAAiB,CAACkF,EAAG0M,GAAK,mBAa1B,IAXA,IAAMhR,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvB0T,EAAe7T,EAAS6T,aACxBC,EAAc9T,EAAS8T,YACvBC,EAAyC,iBAAxB/T,EAASgU,WAC1BiE,EAAKtR,SAAmB3G,EAASkY,YAAa,WAE9CpB,EAAU9W,EAASS,QAAQG,KAC3BiW,EAAS7W,EAASS,QAAQC,IAC1B+C,EAAOgC,KAAK2C,WAAW5D,GACvB2T,EAAQ1S,KAAK2C,WAAW8I,GACrBtN,EAAK,EAAGA,EAAKiQ,IAAgBjQ,EAKpC,IAJA,IAAMwU,EAAQlW,KAAKhE,IAAI,EAAGgE,KAAKmO,MAAMwG,EAASjT,GAAM1D,IAC9C6W,EAAQ7U,KAAKE,IACfpC,EAAS+B,WAAY/B,EAASqC,SAAWwU,EAASjT,GAAM1D,GAEnD2D,EAAK,EAAGA,EAAKiQ,IAAejQ,EAKnC,IAJA,IAAMwU,EAAQnW,KAAKhE,IAAI,EAAGgE,KAAKmO,MAAMyG,EAAUjT,GAAM1D,IAC/C6W,EAAQ9U,KAAKE,IACfpC,EAASwC,UAAWxC,EAAS4C,QAAUkU,EAAUjT,GAAM1D,GAElDgV,EAAK,EAAGA,EAAKnV,EAAS6B,aAAcsT,EAC3C,IAAK,IAAIE,EAAK,EAAGA,EAAKrV,EAASsV,cAAeD,EAAI,CAGhD,IADA,IAAI4B,EAAU,EACLzV,EAAI,EAAGA,EAAIxB,EAASyB,YAAaD,EACxC,IAAK,IAAIM,EAAKsW,EAAOtW,EAAKiV,IAASjV,EAEjC,IADA,IAAMkB,EAAKY,EAAK9B,EAAK5B,EAAe2W,EAC3BtU,EAAK8V,EAAO9V,EAAKyU,IAASzU,EAAI,CACrC,IAAMW,EAAKW,EAAKtB,EAAKpC,EAAc2W,EAEjCG,GADElD,EAEEtQ,EAAKK,IAAItC,EAAGwB,EAAIE,EAAIiS,GAAMgD,EAAMrU,IAAItC,EAAGM,EAAIS,EAAI8S,GAG/C5R,EAAKK,IAAItC,EAAG2T,EAAInS,EAAIE,GAAMiV,EAAMrU,IAAItC,EAAG6T,EAAIvT,EAAIS,GAK3D0V,EAAGlU,IAAIkT,EAASrT,EAAIC,EAAIsR,EAAIE,GAKpC,OAAO4C,EAAG1P,YAGZhD,4BAAA,SAAgBf,EAAa0M,EAAclR,GAqBzC,IAnBA,IAAM8V,EAAc9V,EAAS8V,YACvB5V,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBoV,EAAcvV,EAASuV,YACvB1B,EAAe7T,EAAS6T,aACxBC,EAAc9T,EAAS8T,YAEvBwE,EAAK3R,SAAmB3G,EAASkY,YAAa,WAC9CK,EAAWD,EAAGlX,OACd6E,YAACuS,OAAMC,OAAMC,OAAMC,OACnBvH,EAAW3L,KAAKO,SAASkL,EAAGpL,QAC5BiH,YAACyK,OAAMC,OAAMC,OAAMC,OACnB7X,EAAU2F,KAAKO,SAASxB,EAAEsB,QAC1B8R,YAACgB,OAAKC,OAAKC,OAAKC,OAEhBjB,EAAW9X,EAASS,QAAQiV,MAC5BoB,EAAU9W,EAASS,QAAQG,KAC3BiW,EAAS7W,EAASS,QAAQC,IAEvBqV,EAAK,EAAGA,EAAKR,IAAeQ,EAMnC,IALA,IAAMiD,EAAQ9W,KAAKhE,IAAI,EAAGgE,KAAKmO,MAAMyH,EAAW/B,GAAMD,IAChDkC,EAAQ9V,KAAKE,IACfpC,EAAS4V,UAAW5V,EAASiW,QAAU6B,EAAW/B,GAAMD,GACtDhB,EAAWiB,EAAKyC,EAEb5U,EAAK,EAAGA,EAAKiQ,IAAgBjQ,EAOpC,IANA,IAAMwU,EAAQlW,KAAKhE,IAAI,EAAGgE,KAAKmO,MAAMwG,EAASjT,GAAM1D,IAC9C6W,EAAQ7U,KAAKE,IACfpC,EAAS+B,WACR/B,EAASqC,SAAWwU,EAASjT,GAAM1D,GAClCgW,EAAWtS,EAAK6U,EAAO3D,EAEpBjR,EAAK,EAAGA,EAAKiQ,IAAejQ,EAOnC,IANA,IAAMwU,EAAQnW,KAAKhE,IAAI,EAAGgE,KAAKmO,MAAMyG,EAAUjT,GAAM1D,IAC/C6W,EAAQ9U,KAAKE,IACfpC,EAASwC,UACRxC,EAAS4C,QAAUkU,EAAUjT,GAAM1D,GAClC+U,EAAWrR,EAAK6U,EAAOxC,EAEpBf,EAAK,EAAGA,EAAKnV,EAAS6B,aAAcsT,EAG3C,IAFA,IAAMkB,EAAWlB,EAAKwD,EAAOzD,EAEpBG,EAAK,EAAGA,EAAKrV,EAASsV,cAAeD,EAAI,CAEhD,IADA,IAAI4B,EAAU,EACLzV,EAAI,EAAGA,EAAIxB,EAASyB,YAAaD,EAIxC,IAHA,IAAMmT,EAAWnT,EAAIoX,EACfhE,EAAWpT,EAAIgW,EAEZ7B,EAAKqD,EAAOrD,EAAKqC,IAASrC,EAKjC,IAJA,IACMZ,GADKgB,EAAKJ,EAAKG,EAAcgC,GACbe,EAAMlE,EACtBE,EAAWc,EAAK8B,EAAO7C,EAEpB9S,GAAKsW,EAAOtW,GAAKiV,IAASjV,GAKjC,IAJA,IACMmT,IADKrR,EAAK9B,GAAK5B,EAAe2W,GACdiC,EAAM/D,EACtBC,GAAWlT,GAAK4V,EAAO7C,EAEpBtS,GAAK8V,EAAO9V,GAAKyU,IAASzU,GAAI,CACrC,IAEM4T,GAAW5T,GAAKoV,EAAO3C,GAE7BiC,GACInX,GALO+D,EAAKtB,GAAKpC,EAAc2W,GACbiC,EAAM9D,GAILE,GAAM/D,EAAS+E,GAAWd,GAKzDkD,EAASlC,EAAWhB,GAAM4B,EAMpC,OAAOqB,EAAG/P,YAGZhD,iCAAA,SACIU,OAACyB,UAAOiM,WAAQ3T,aAAU6N,SAAMpJ,eAAYC,2BAE1C3F,EAAS0G,KAAKwT,gBAAgBvR,EAAOiM,EAAQ3T,GAUjD,OARI6N,IACF9O,EAAS0G,KAAKsI,IAAIhP,EAAQ8O,IAExBpJ,IACF1F,EACIuF,EAAcmB,KAAM1G,EAAQ0F,EAAYC,IAGvC3F,GAGTwG,4BAAA,SACIf,EAAamP,EACb3T,GACFV,EAAiB,CAACkF,EAAGmP,GAAS,mBAc9B,IAZA,IAAME,EAAe7T,EAAS6T,aACxBC,EAAc9T,EAAS8T,YACvB1T,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBM,EAAUX,EAASS,QAAQG,KAC3BJ,EAASR,EAASS,QAAQC,IAC1BwY,EAAQlZ,EAASsV,YAActV,EAAS6B,WACxCsP,EAAIxK,SAAU3G,EAASvC,SAAU+G,EAAE9G,OACnCY,EAAQmH,KAAKO,SAASxB,EAAEsB,QACxB2O,EAAQhP,KAAKO,SAAS2N,EAAO7N,QAC7B4O,EAAQvD,EAAE/P,OAEPI,EAAI,EAAGA,EAAIxB,EAASyB,YAAaD,EAGxC,IAFA,IAAMmT,EAAWnT,EAAIgD,EAAEzE,QAAQ,GACzB6U,EAAWpT,EAAI2P,EAAEpR,QAAQ,GACtB+B,EAAK,EAAGA,EAAK9B,EAAS+B,YAAaD,EAG1C,IAFA,IAAM+S,EAAWD,EAAW9S,EAAKqP,EAAEpR,QAAQ,GACrCiC,EAAWF,EAAK9B,EAASE,aAAeS,EACrCiD,EAAK,EAAGA,EAAKiQ,IAAgBjQ,EAAI,CACxC,IAAMZ,EAAKhB,EAAW4B,EAAKxD,EAC3B,KAAI4C,EAAK,GAAKA,GAAMhD,EAASqC,UAK7B,IAFA,IAAMyS,EAAWlR,EAAK+P,EAAO5T,QAAQ,GAC/BgV,EAAWJ,EAAW3R,EAAKwB,EAAEzE,QAAQ,GAClCwC,EAAK,EAAGA,EAAKvC,EAASwC,WAAYD,EAGzC,IAFA,IAAMyS,EAAWH,EAAWtS,EAAK4O,EAAEpR,QAAQ,GACrC0C,EAAWF,EAAKvC,EAASG,YAAcK,EACpCqD,EAAK,EAAGA,EAAKiQ,IAAejQ,EAAI,CACvC,IAAMX,EAAKT,EAAWoB,EAAKxD,EAC3B,KAAI6C,EAAK,GAAKA,GAAMlD,EAAS4C,SAO7B,IAJA,IAAMsT,EAAWpB,EAAWjR,EAAK8P,EAAO5T,QAAQ,GAC1CkV,EAAWF,EAAW7R,EAAKlD,EAAS6B,WACtCsU,EAAWnB,EACXE,EAAWgB,EACNf,EAAK,EAAGA,EAAKnV,EAAS6B,aAAcsT,EAAI,CAE/C,IADA,IAAMC,EAAO9W,EAAM2W,EAAWE,GACrBgE,EAAI,EAAGA,EAAID,IAASC,EAC3BzE,EAAMyB,EAAWgD,IAAM/D,EAAOX,EAAMS,EAAWiE,GAEjDhD,GAAY+C,EACZhE,GAAYgE,IAQxB,OAAO/H,EAAE5I,YAGXhD,oCAAA,SACI2L,EAAcyC,EACd3T,GACFV,EAAiB,CAAC4R,EAAIyC,GAAS,2BA0B/B,IAxBA,IAAM2C,EAAK3P,SAAmB3G,EAASuW,QAAS,WAC1CC,EAAWF,EAAGlV,OACd6E,YAACmR,OAAMC,OAAMC,OACblG,EAAW3L,KAAKO,SAASkL,EAAGpL,QAC5BiH,YAACyK,OAAMC,OAAMC,OACbjB,EAAYhR,KAAKO,SAAS2N,EAAO7N,QACjC8R,YAAClB,OAAOC,OAAOC,OAEnBnV,cACAoS,iBACAC,gBACAjS,eACAQ,aACAO,YACA0S,gBACAvT,cACAS,aACAtC,iBACAC,gBAEI0W,EAAShD,EAAe,EAAI7T,EAASS,QAAQC,IAC7CoW,EAAUhD,EAAc,EAAI9T,EAASS,QAAQG,KAC7CsY,EAAQ5D,EAAczT,EAEnBL,EAAI,EAAGA,EAAIC,IAAaD,EAC/B,IAAK,IAAI2T,EAAK,EAAGA,EAAKtT,IAAcsT,EAClC,IAAK,IAAInS,EAAK,EAAGA,EAAKX,IAAYW,EAMhC,IALA,IAAMhB,EAAWgB,EAAK6T,EAChB5U,EAAQC,KAAKhE,IAAI,EAAGgE,KAAKmO,KAAKrO,EAAW9B,IACzC6W,EACF7U,KAAKE,IAAIL,GAAY8R,EAAe7R,GAAY9B,GAE3CgD,EAAK,EAAGA,EAAKN,IAAWM,EAAI,CAOnC,IANA,IAAMT,EAAWS,EAAK4T,EAChBpU,EAAQR,KAAKhE,IAAI,EAAGgE,KAAKmO,KAAK5N,EAAWtC,IACzC6W,EACF9U,KAAKE,IAAII,GAAWsR,EAAcrR,GAAYtC,GAE9C8W,EAAU,EACLnV,EAAKG,EAAOH,EAAKiV,IAASjV,EAGjC,IAFA,IAAM8B,EAAK9B,EAAK5B,EAAe8B,EAEtBO,EAAKG,EAAOH,EAAKyU,IAASzU,EAMjC,IALA,IACM2U,EAAWM,EAAOhW,EAAIiW,EAAO3V,EAAK4V,EAAOnV,EACzC4U,EAAYT,GAAS7C,EAAe,EAAIjQ,GAC1C+S,GAAS7C,EAAc,GAHhBvR,EAAKpC,EAAcsC,IAGOmU,EAAQzB,EAEpCiE,EAAK,EAAGA,EAAKF,IAASE,EAAI,CAIjCnC,GAFc7F,EAAS8F,GADZ/B,EAAK+D,EAAQE,IAET3C,EAAUU,EAAYiC,GAK3C5C,EAASY,EAAO5V,EAAI6V,EAAOrU,EAAKsU,EAAOpU,EAAKiS,GAAM8B,EAK1D,OAAOX,EAAG/N,YAGZhD,qCAAA,SACIf,EAAa0M,EAAclR,GAC7BV,EAAiB,CAACkF,EAAG0M,GAAK,4BAc1B,IAZA,IAAMhR,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvB0T,EAAe7T,EAAS6T,aACxBC,EAAc9T,EAAS8T,YACvBmE,EAAKtR,SAAmB3G,EAASkY,YAAa,WAE9CpB,EAAU9W,EAASS,QAAQG,KAC3BiW,EAAS7W,EAASS,QAAQC,IAC1BwY,EAAQlZ,EAASsV,YAActV,EAAS6B,WAExC4B,EAAOgC,KAAK2C,WAAW5D,GACvB2T,EAAQ1S,KAAK2C,WAAW8I,GACrBtN,EAAK,EAAGA,EAAKiQ,IAAgBjQ,EAKpC,IAJA,IAAMwU,EAAQlW,KAAKhE,IAAI,EAAGgE,KAAKmO,MAAMwG,EAASjT,GAAM1D,IAC9C6W,EAAQ7U,KAAKE,IACfpC,EAAS+B,WAAY/B,EAASqC,SAAWwU,EAASjT,GAAM1D,GAEnD2D,EAAK,EAAGA,EAAKiQ,IAAejQ,EAKnC,IAJA,IAAMwU,EAAQnW,KAAKhE,IAAI,EAAGgE,KAAKmO,MAAMyG,EAAUjT,GAAM1D,IAC/C6W,EAAQ9U,KAAKE,IACfpC,EAASwC,UAAWxC,EAAS4C,QAAUkU,EAAUjT,GAAM1D,GAElDkV,EAAK,EAAGA,EAAKrV,EAASsV,cAAeD,EAAI,CAKhD,IAJA,IAAMF,EAAKjT,KAAKmX,MAAMhE,EAAK6D,GACrBE,EAAK/D,EAAK6D,EAEZjC,EAAU,EACLzV,EAAI,EAAGA,EAAIxB,EAASyB,YAAaD,EACxC,IAAK,IAAIM,EAAKsW,EAAOtW,EAAKiV,IAASjV,EAEjC,IADA,IAAMkB,EAAKY,EAAK9B,EAAK5B,EAAe2W,EAC3BtU,EAAK8V,EAAO9V,EAAKyU,IAASzU,EAAI,CACrC,IAAMW,EAAKW,EAAKtB,EAAKpC,EAAc2W,EACnCG,GAAWxT,EAAKK,IAAItC,EAAGwB,EAAIE,EAAIiS,GAAMgD,EAAMrU,IAAItC,EAAGM,EAAIS,EAAI8S,GAIhE4C,EAAGlU,IAAIkT,EAASrT,EAAIC,EAAIsR,EAAIiE,GAIlC,OAAOnB,EAAG1P,YAGZhD,iBAAA,SAAuBf,EAAM8U,GAE3B,OADAha,EAAiBkF,EAAG,QACbL,EAAKsB,KAAK2C,WAAW5D,GAAI8U,IAGlC/T,gBAAA,SACIf,EAAM+U,EAAmCC,GAC3Cla,EAAiBkF,EAAG,OAEpB,IAAM/G,EAAW8b,EAAS9S,KACtB,SAACmM,EAAG7U,GAAM,OAAA6U,EAAE,GAAqBpO,EAAEgB,MAAMzH,GAAK6U,EAAE,MAC9C1L,EAAQqS,EAAS9S,KAAI,SAAAmM,GAAK,OAAAA,EAAE,MAC5B6G,EAAUhU,KAAK2C,WAAW5D,GAC1BtD,EAASyF,SAAUlJ,EAAU+G,EAAE9G,OACf,IAAlB8b,GACFtY,EAAOE,OAAO2H,KAAKyQ,GAGrB,IAAK,IAAIzb,EAAI,EAAGA,EAAIyG,EAAEoD,KAAM7J,IAAK,CAC/B,IAAM2b,EAASD,EAAQxa,WAAWlB,GAC5B4b,EAAYD,EAAOjT,KAAI,SAACmT,EAAG7b,GAAM,OAAA6b,EAAI1S,EAAMnJ,MACjDmD,EAAO6C,UAAP7C,GAAWuY,EAAQ3V,UAAR2V,EAAeC,WAAYC,IAExC,OAAOzY,EAAOqH,YAGhBhD,mBAAA,SAAyBf,EAAMqV,EAAmBlR,GAChDrJ,EAAiB,CAACkF,EAAGqV,GAAU,UAE/B,IAAMpb,EAAqB+F,EAAEgB,MAAMwD,QAC7B8Q,EAAgBrU,KAAKO,SAAS6T,EAAQ/T,QAC5CrH,EAASkK,GAAQmR,EAAc9b,OAI/B,IAHA,IAAMe,EAAS4H,SAAUlI,EAAU+F,EAAE9G,OAC/B+F,EAAOgC,KAAK2C,WAAW5D,GAEpBzG,EAAI,EAAGA,EAAIgB,EAAO6I,OAAQ7J,EAAG,CACpC,IAAMmB,EAASH,EAAOE,WAAWlB,GAE3Bgc,EAAwB7a,EAAO8J,QACrC+Q,EAAYpR,GAAQmR,EAAc5a,EAAOyJ,IAEzC,IAAMqR,EAAgBvW,EAAKpE,WAAW0a,GACtChb,EAAOqC,OAAOrD,GAAK0F,EAAKrC,OAAO4Y,GAEjC,OAAOjb,EAAOwJ,YAGhBhD,2BAAA,SACIf,EAAMyV,EAAsBC,GAC9B5a,EAAiB,CAACkF,GAAI,kBAEtB,IAAM6J,EAAO4L,EAAWE,QAAO,SAACzP,EAAGlJ,GAAM,OAAAkJ,EAAIlJ,KAEvC4Y,EAAWxU,eAAayU,YAAY7V,EAAEgB,MAAOyU,EAAY5L,GACzDiM,EACF1U,eAAa2U,YAAYH,EAASpc,OAAQic,EAAWjc,QACnDwc,EACF5U,eAAa6U,oBAAoBjW,EAAEgB,MAAOyU,EAAY5L,GACpDqM,EACF9U,eAAa+U,oBAAoBT,EAAOD,EAAWjc,QACjD4c,EACFhV,eAAaiV,aAAaL,EAAkBN,EAAOD,EAAWjc,QAElE,OAAO8c,YAAatW,EAAE0E,QAAQkR,GAAWE,GAC7BpR,QAAQsR,GACRxR,MAAM0R,EAAkBE,IAGtCrV,2BAAA,SACIf,EAAMyV,EAAsBV,GAC9Bja,EAAiB,CAACkF,GAAI,kBAEtB,IAAM6J,EAAO4L,EAAWE,QAAO,SAACzP,EAAGlJ,GAAM,OAAAkJ,EAAIlJ,KAEvCuZ,EAA4C,CAAC,CAAC,EAAG,IACvDA,EAAiBjM,WAAjBiM,EAAyBxB,GACzB,IAAK,IAAIxb,EAAI,EAAIkc,EAAWjc,OAAQD,EAAIyG,EAAEgB,MAAMxH,SAAUD,EACxDgd,EAAiBjM,KAAK,CAAC,EAAG,IAG5B,IAAMkM,EAAUxW,EAAEyW,IAAIF,GAEhBG,EACFtV,eAAayU,YAAYW,EAAQxV,MAAOyU,EAAY5L,GAAM,GACxD8M,EAAoCvV,eAAa2U,YACnDW,EAAoBld,OAAQic,EAAWjc,QAAQ,GAC7Cod,EAAexV,eAAa6U,oBAC9BO,EAAQxV,MAAOyU,EAAY5L,GAAM,GAErC,OAAOyM,YACME,EAAQ9R,QAAQgS,GAChBC,GACDjS,QAAQkS,IAGtB7V,oBAAA,SAAQf,EAAaxE,GAGnB,OAFAV,EAAiBkF,EAAG,WAEb3E,EADS4F,KAAKO,SAASxB,EAAEsB,QACXtB,EAAEgB,MAAOhB,EAAE9G,MAAO8G,EAAEzE,QAASC,EAAU,OAChDuI,YAGdhD,4BAAA,SACI2L,EAAc1M,EAAa2M,EAC3BnR,GACFV,EAAiB,CAACkF,EAAG2M,GAAI,mBAkBzB,IAhBA,IAAMrR,EAAU2F,KAAKO,SAASxB,EAAEsB,QAC1BuV,EAAYna,SACdlB,EAASvC,SAAU+G,EAAE9G,MACrB2F,EAAiBvD,EAAS0E,EAAEgB,MAAOhB,EAAE9G,MAAOsC,GAAUoB,QACpDlB,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBC,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBC,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChCI,EAAUJ,EAAuB,EAAIP,EAASS,QAAQG,KACtDJ,EAASF,EAAwB,EAAIN,EAASS,QAAQC,IACtD4V,EAAK3P,SAAmBnC,EAAEgB,MAAO,WAEjC2S,EAAQ1S,KAAK2C,WAAW8I,GAErB1P,EAAI,EAAGA,EAAIxB,EAASyB,YAAaD,EACxC,IAAK,IAAII,EAAI,EAAGA,EAAI5B,EAAS6B,aAAcD,EACzC,IAAK,IAAI0Z,EAAM,EAAGA,EAAMtb,EAASqC,WAAYiZ,EAC3C,IAAK,IAAIC,EAAM,EAAGA,EAAMvb,EAAS4C,UAAW2Y,EAAK,CAK/C,IAHA,IAAMC,EAAYF,EAAM9a,EAClBib,EAAYF,EAAM5a,EACpBsW,EAAU,EACLrT,EAAK,EAAGA,EAAKtD,EAAuBsD,GAAMxD,EAAgB,CACjE,IAAMsb,GAAOF,EAAY5X,GAAM1D,EAC/B,KAAIwb,EAAM,GAAKA,GAAO1b,EAAS+B,WAC3BG,KAAK8L,MAAM0N,KAASA,GAGxB,IAAK,IAAI7X,EAAK,EAAGA,EAAKtD,EAAsBsD,GAAMxD,EAAe,CAC/D,IAAMsb,GAAOF,EAAY5X,GAAM1D,EAC/B,KAAIwb,EAAM,GAAKA,GAAO3b,EAASwC,UAC3BN,KAAK8L,MAAM2N,KAASA,GADxB,CAIA,IAIMC,EAJStb,EAAwBC,EACnC,EAAK8a,EAAUvX,IAAItC,EAAGka,EAAKC,EAAK/Z,KACrBgC,EAAKrD,EAAuBsD,EAEV,EAAI,EACrC,GAAa,IAAT+X,EAKJ3E,GADckB,EAAMrU,IAAItC,EAAGka,EAAKC,EAAK/Z,GAClBga,IAGvBtF,EAAGvS,IAAIkT,EAASzV,EAAG8Z,EAAKC,EAAK3Z,GAKrC,OAAO0U,EAAG/N,YAGZhD,4BAAA,SAAgB2L,EAAc1M,EAAaxE,GAEzCV,EAAiB,CAAC4R,EAAI1M,GAAI,mBAkB1B,IAhBA,IAAMtE,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvB0T,EAAe7T,EAAS6T,aACxBC,EAAc9T,EAAS8T,YACvB1T,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBC,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChCI,EAAUJ,EAAuB,EAAIP,EAASS,QAAQG,KACtDJ,EAASF,EAAwB,EAAIN,EAASS,QAAQC,IACtD4V,EAAK3P,SAAmBnC,EAAEgB,MAAO,WAEjCqW,EAAgB,GAAKhI,EAAeC,GAEpCqE,EAAQ1S,KAAK2C,WAAW8I,GAErB1P,EAAI,EAAGA,EAAIxB,EAASyB,YAAaD,EACxC,IAAK,IAAII,EAAI,EAAGA,EAAI5B,EAAS6B,aAAcD,EACzC,IAAK,IAAI0Z,EAAM,EAAGA,EAAMtb,EAASqC,WAAYiZ,EAC3C,IAAK,IAAIC,EAAM,EAAGA,EAAMvb,EAAS4C,UAAW2Y,EAAK,CAK/C,IAHA,IAAMC,EAAYF,EAAM9a,EAClBib,EAAYF,EAAM5a,EACpBsW,EAAU,EACLrT,EAAK,EAAGA,EAAKtD,EAAuBsD,GAAMxD,EAAgB,CACjE,IAAMsb,GAAOF,EAAY5X,GAAM1D,EAC/B,KAAIwb,EAAM,GAAKA,GAAO1b,EAAS+B,WAC3BG,KAAK8L,MAAM0N,KAASA,GAGxB,IAAK,IAAI7X,EAAK,EAAGA,EAAKtD,EAAsBsD,GAAMxD,EAAe,CAC/D,IAAMsb,GAAOF,EAAY5X,GAAM1D,EAC/B,KAAIwb,EAAM,GAAKA,GAAO3b,EAASwC,UAC3BN,KAAK8L,MAAM2N,KAASA,GAKxB1E,GADckB,EAAMrU,IAAItC,EAAGka,EAAKC,EAAK/Z,IAIzC0U,EAAGvS,IAAIkT,EAAU4E,EAAera,EAAG8Z,EAAKC,EAAK3Z,GAKrD,OAAO0U,EAAG/N,YAGJhD,mBAAR,SACIf,EAAaxE,EACbC,GACFX,EAAiBkF,EAAG,UA8BpB,IA5BA,IAAMsR,EAAc9V,EAAS8V,YACvB5V,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBqV,EAAgBxV,EAASwV,cACzBpV,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzByb,EAAuB9b,EAAS8b,qBAChCxb,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChCkV,EAAWzV,EAASS,QAAQiV,MAC5BlV,EAASR,EAASS,QAAQC,IAC1BC,EAAUX,EAASS,QAAQG,KAE3BC,EACY,QAAbZ,EAAqBa,OAAOC,kBACPD,OAAOE,kBAE3BlB,EAAU2F,KAAKO,SAASxB,EAAEsB,QAC1B7E,EAAS0F,SAAU3G,EAASvC,SAAU+G,EAAE9G,OACxCyD,EAAaF,EAAOG,OAEpBC,EAAqBrB,EAASvC,SAAS,GAAKuC,EAASvC,SAAS,GAChEuC,EAASvC,SAAS,GAAKuC,EAASvC,SAAS,GACvCse,EACF/b,EAASvC,SAAS,GAAKuC,EAASvC,SAAS,GAAKuC,EAASvC,SAAS,GAC9D6D,EAAmBtB,EAASvC,SAAS,GAAKuC,EAASvC,SAAS,GAC5D8D,EAAmBvB,EAASvC,SAAS,GAElCue,EAAQ,EAAGA,EAAQhc,EAASyB,YAAaua,EAGhD,IAFA,IAAMta,EAAoBsa,EAAQ3a,EAC5BM,EAAmBqa,EAAQxX,EAAEzE,QAAQ,GAClCkc,EAAU,EAAGA,EAAUjc,EAAS6B,aAAcoa,EACrD,IAAK,IAAIC,EAAS,EAAGA,EAASlc,EAAS4V,WAAYsG,EAAQ,CAGzD,IAFA,IAAMC,EAAeD,EAASpG,EAAcL,EACxC2G,EAAYD,EACTC,EAAY,GACjBA,GAAa5G,EAMf,IAJA,IAAM6G,EACFna,KAAKE,IAAIpC,EAASiW,QAAS6F,EAAuBK,GAChDG,EACF5a,EAAoBwa,EAASH,EACxBQ,EAAO,EAAGA,EAAOvc,EAAS+B,YAAawa,EAAM,CAGpD,IAFA,IAAMC,EAAaD,EAAOrc,EAAeM,EACrCic,EAAUD,EACPC,EAAU,GACfA,GAAWrc,EAKb,IAHA,IAAMsc,EACFxa,KAAKE,IAAIpC,EAASqC,SAAU/B,EAAwBkc,GAClDla,EAAkBga,EAAoBC,EAAOjb,EAC1Cqb,EAAO,EAAGA,EAAO3c,EAASwC,WAAYma,EAAM,CAGnD,IAFA,IAAMC,EAAaD,EAAOxc,EAAcQ,EACpCkc,EAAUD,EACPC,EAAU,GACfA,GAAWxc,EASb,IAPA,IAAMyc,EACF5a,KAAKE,IAAIpC,EAAS4C,QAASrC,EAAuBqc,GAEhDG,EAAkBza,EAAkBqa,EAAOpb,EAC7CsB,EAAchC,EACdiC,EAAW,EACXC,EAAQ,EACHia,EAASZ,EAAWY,EAASX,EACjCW,GAAUxH,EAAe,CAE5B,IADA,IAAMyH,EAAetb,EAAmBqb,EAASxY,EAAEzE,QAAQ,GAClDmd,EAAOT,EAASS,EAAOR,EAC3BQ,GAAQ9c,EAAgB,CAE3B,IADA,IAAM+c,EAAaF,EAAeC,EAAO1Y,EAAEzE,QAAQ,GAC1Cqd,EAAOP,EAASO,EAAON,EAC3BM,GAAQ/c,EAAe,CAC1B,IACM8C,EAAQrD,EADKqd,EAAaC,EAAO5Y,EAAEzE,QAAQ,GACdkc,GAOnC,GANkB,QAAbhc,GAAsBkD,EAAQN,EACjCA,EAAcM,EACQ,QAAblD,IACT6C,GAAYK,EACZJ,KAEEK,MAAMP,GACR,MAGJ,GAAIO,MAAMP,GACR,MAGJ,GAAIO,MAAMP,GACR,MAIJ1B,EADqB4b,EAAkBd,GAEtB,QAAbhc,EAAqB6C,EAAWC,EAAQF,IAMtD,OAAO5B,EAAOsH,YAGhBhD,sBAAA,SAAUf,EAAaxE,GAGrB,OAFAV,EAAiBkF,EAAG,aAEbiB,KAAK4X,OAAO7Y,EAAGxE,EAAU,OAAOsd,WAGzC/X,8BAAA,SACI2L,EAAc1M,EAAaxE,GAC7BV,EAAiB,CAAC4R,EAAI1M,GAAI,qBAuB1B,IArBA,IAAMsR,EAAc9V,EAAS8V,YACvB5V,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBoV,EAAcvV,EAASuV,YACvB1B,EAAe7T,EAAS6T,aACxBC,EAAc9T,EAAS8T,YACvB0B,EAAgBxV,EAASwV,cACzBpV,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzByb,EAAuB9b,EAAS8b,qBAChCxb,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChCkV,EAAWqG,EAAuB,EAAI9b,EAASS,QAAQiV,MACvD/U,EAAUJ,EAAuB,EAAIP,EAASS,QAAQG,KACtDJ,EAASF,EAAwB,EAAIN,EAASS,QAAQC,IACtD4V,EAAK3P,SAAmBnC,EAAEgB,MAAO,WAEjCqW,EAAgB,GAAKtG,EAAc1B,EAAeC,GAElDqE,EAAQ1S,KAAK2C,WAAW8I,GAErB8K,EAAQ,EAAGA,EAAQhc,EAASyB,YAAaua,EAChD,IAAK,IAAIC,EAAU,EAAGA,EAAUjc,EAAS6B,aAAcoa,EACrD,IAAK,IAAIsB,EAAU,EAAGA,EAAUvd,EAASiW,UAAWsH,EAClD,IAAK,IAAIC,EAAQ,EAAGA,EAAQxd,EAASqC,WAAYmb,EAC/C,IAAK,IAAIC,EAAQ,EAAGA,EAAQzd,EAAS4C,UAAW6a,EAAO,CAMrD,IAJA,IAAMC,EAAgBH,EAAU9H,EAC1BkI,EAAcH,EAAQhd,EACtBod,EAAcH,EAAQ9c,EACxBsW,EAAU,EACL4G,EAAS,EAAGA,EAAS/B,EACzB+B,GAAUrI,EAAe,CAC5B,IAAMsI,GAAWJ,EAAgBG,GAAU/H,EAC3C,KAAIgI,EAAU,GAAKA,GAAW9d,EAAS4V,UACnC1T,KAAK8L,MAAM8P,KAAaA,GAG5B,IAAK,IAAIC,EAAO,EAAGA,EAAOzd,EACrByd,GAAQ3d,EAAgB,CAC3B,IAAM4d,GAASL,EAAcI,GAAQ7d,EACrC,KAAI8d,EAAQ,GAAKA,GAAShe,EAAS+B,WAC/BG,KAAK8L,MAAMgQ,KAAWA,GAG1B,IAAK,IAAIC,EAAO,EAAGA,EAAO1d,EACrB0d,GAAQ5d,EAAe,CAC1B,IAAM6d,GAASN,EAAcK,GAAQ9d,EACrC,KAAI+d,EAAQ,GAAKA,GAASle,EAASwC,UAC/BN,KAAK8L,MAAMkQ,KAAWA,GAM1BjH,GADIkB,EAAMrU,IAAIkY,EAAO8B,EAASE,EAAOE,EAAOjC,KAKlD3F,EAAGvS,IACCkT,EAAU4E,EAAeG,EAAOuB,EAASC,EAAOC,EAChDxB,GAMd,OAAO3F,EAAG/N,YAGZhD,sBAAA,SAAUf,EAAaxE,GAGrB,OAFAV,EAAiBkF,EAAG,aAEbiB,KAAK4X,OAAO7Y,EAAGxE,EAAU,OAAOsd,WAGjC/X,+BAAR,SAA2Bf,EAAaxE,GAiBtC,IAfA,IAAMwD,EAAemD,SAAU3G,EAASvC,SAAU,SAC5CqY,EAAc9V,EAAS8V,YACvB5V,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBqV,EAAgBxV,EAASwV,cACzBpV,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzByb,EAAuB9b,EAAS8b,qBAChCxb,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChCkV,EAAWzV,EAASS,QAAQiV,MAC5BlV,EAASR,EAASS,QAAQC,IAC1BC,EAAUX,EAASS,QAAQG,KAE3B6C,EAAOgC,KAAK2C,WAAW5D,GACpBwX,EAAQ,EAAGA,EAAQhc,EAASyB,YAAaua,EAChD,IAAK,IAAIC,EAAU,EAAGA,EAAUjc,EAAS6B,aAAcoa,EACrD,IAAK,IAAIC,EAAS,EAAGA,EAASlc,EAAS4V,WAAYsG,EAAQ,CAGzD,IAFA,IAAMC,EAAeD,EAASpG,EAAcL,EACxC2G,EAAYD,EACTC,EAAY,GACjBA,GAAa5G,EAIf,IAFA,IAAM6G,EACFna,KAAKE,IAAIpC,EAASiW,QAAS6F,EAAuBK,GAC7CI,EAAO,EAAGA,EAAOvc,EAAS+B,YAAawa,EAAM,CAGpD,IAFA,IAAMC,EAAaD,EAAOrc,EAAeM,EACrCic,EAAUD,EACPC,EAAU,GACfA,GAAWrc,EAIb,IAFA,IAAMsc,EACFxa,KAAKE,IAAIpC,EAASqC,SAAU/B,EAAwBkc,GAC/CG,EAAO,EAAGA,EAAO3c,EAASwC,WAAYma,EAAM,CAGnD,IAFA,IAAMC,EAAaD,EAAOxc,EAAcQ,EACpCkc,EAAUD,EACPC,EAAU,GACfA,GAAWxc,EASb,IAPA,IAAMyc,EACF5a,KAAKE,IAAIpC,EAAS4C,QAASrC,EAAuBqc,GAGlDlZ,EAAW5C,OAAOC,kBAClB4C,GAAe,EAEVqZ,EAASZ,EAAWY,EAASX,EACjCW,GAAUxH,EAEb,IADA,IAAMqI,EAASb,EAASb,EACfe,EAAOT,EAASS,EAAOR,EAC3BQ,GAAQ9c,EAEX,IADA,IAAM2d,EAAOb,EAAOV,EACXY,EAAOP,EAASO,EAAON,EAC3BM,GAAQ/c,EAAe,CAC1B,IAAM4d,EAAOb,EAAOR,EACdzZ,EAAQM,EAAKK,IAAIkY,EAAOgB,EAAQE,EAAME,EAAMnB,GAC9C9Y,GAASO,IACXA,EAAWP,EACXQ,EAAcka,EAASvd,EACfC,EACJwd,EAAOzd,EAAwB2d,GAM3Cza,EAAaO,IAAIJ,EAAaqY,EAAOE,EAAQK,EAAMI,EAAMV,KAMnE,OAAOzY,EAAa+E,YAGtBhD,8BAAA,SACI2L,EAAc1M,EAAa2M,EAC3BnR,GACFV,EAAiB,CAACkF,EAAG2M,GAAI,qBAoBzB,IAlBA,IAAM3N,EAAeiC,KAAK0Y,mBAAmB3Z,EAAGxE,GAC1C8V,EAAc9V,EAAS8V,YACvB5V,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBqV,EAAgBxV,EAASwV,cACzBpV,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzByb,EAAuB9b,EAAS8b,qBAChCxb,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChCkV,EAAWqG,EAAuB,EAAI9b,EAASS,QAAQiV,MACvD/U,EAAUJ,EAAuB,EAAIP,EAASS,QAAQG,KACtDJ,EAASF,EAAwB,EAAIN,EAASS,QAAQC,IACtD4V,EAAK3P,SAAmBnC,EAAEgB,MAAO,WAEjC6V,EAAY5V,KAAK2C,WAAW5E,GAC5B2U,EAAQ1S,KAAK2C,WAAW8I,GAErB8K,EAAQ,EAAGA,EAAQhc,EAASyB,YAAaua,EAChD,IAAK,IAAIC,EAAU,EAAGA,EAAUjc,EAAS6B,aAAcoa,EACrD,IAAK,IAAIsB,EAAU,EAAGA,EAAUvd,EAASiW,UAAWsH,EAClD,IAAK,IAAIC,EAAQ,EAAGA,EAAQxd,EAASqC,WAAYmb,EAC/C,IAAK,IAAIC,EAAQ,EAAGA,EAAQzd,EAAS4C,UAAW6a,EAAO,CAMrD,IAJA,IAAMC,EAAgBH,EAAU9H,EAC1BkI,EAAcH,EAAQhd,EACtBod,EAAcH,EAAQ9c,EACxBsW,EAAU,EACL4G,EAAS,EAAGA,EAAS/B,EACzB+B,GAAUrI,EAAe,CAC5B,IAAMsI,GAAWJ,EAAgBG,GAAU/H,EAC3C,KAAIgI,EAAU,GAAKA,GAAW9d,EAAS4V,UACnC1T,KAAK8L,MAAM8P,KAAaA,GAG5B,IAAK,IAAIC,EAAO,EAAGA,EAAOzd,EACrByd,GAAQ3d,EAAgB,CAC3B,IAAM4d,GAASL,EAAcI,GAAQ7d,EACrC,KAAI8d,EAAQ,GAAKA,GAAShe,EAAS+B,WAC/BG,KAAK8L,MAAMgQ,KAAWA,GAG1B,IAAK,IAAIC,EAAO,EAAGA,EAAO1d,EACrB0d,GAAQ5d,EAAe,CAC1B,IAAM6d,GAASN,EAAcK,GAAQ9d,EACrC,KAAI+d,EAAQ,GAAKA,GAASle,EAASwC,UAC/BN,KAAK8L,MAAMkQ,KAAWA,GAD1B,CAKA,IAQMtC,EARSE,EACPxb,EAAwBC,EAC5B,EACA8a,EAAUvX,IAAIkY,EAAO8B,EAASE,EAAOE,EAAOjC,KAE5C4B,EAASvd,EAAwBC,EACjCwd,EAAOxd,EAAuB0d,EAED,EAAI,EACrC,GAAa,IAATrC,EAMJ3E,GADIkB,EAAMrU,IAAIkY,EAAO8B,EAASE,EAAOE,EAAOjC,GACzBL,KAIzBtF,EAAGvS,IAAIkT,EAAS+E,EAAOuB,EAASC,EAAOC,EAAOxB,GAMxD,OAAO3F,EAAG/N,YAGZhD,iBAAA,SAAuBf,EAAM9G,GAC3B,OAAOkI,eAAawY,WAAW5Z,EAAG9G,EAAO+H,OAG3CF,oBAAA,SAAwBf,EAAWgB,GACjC,OAAOI,eAAayY,cAAc7Z,EAAGgB,IAGvCD,oBAAA,SAAQf,EAAaxE,GAInB,OAHAV,EAAiBkF,EAAG,WACpBlF,EAAiBkF,EAAG,WAEb3E,EADS4F,KAAKO,SAASxB,EAAEsB,QACXtB,EAAEgB,MAAOhB,EAAE9G,MAAO8G,EAAEzE,QAASC,EAAU,OAChDuI,WACA+U,WAGd/X,2BAAA,SACIf,EAAa8Z,EAAmBC,EAChCC,GACFlf,EAAiBkF,EAAG,kBAqBpB,IAnBM,IAAAyB,UAAC+V,OAAOyC,OAAWC,OAAUC,OAC7B7e,EAAU2F,KAAKO,SAASxB,EAAEsB,QAC1B/G,EAAS,IAAIqR,aACfxS,OAAKE,cAAc,CAACke,EAAOsC,EAAWC,EAAUI,KAE9CC,EAAuC,CAC1CJ,GAAgBF,EAAY,EAAKG,EAAY,EAAIA,EACjDD,GAAgBD,EAAW,EAAKG,EAAW,EAAIA,GAG5CG,EAAwC,CAC3CL,GAAgBF,EAAY,EAAKA,EAAY,EAAIA,EACjDE,GAAgBD,EAAW,EAAKA,EAAW,EAAIA,GAE9CO,EAAY,EACVC,EACFH,EAAmB,GAAKC,EAAoB,GAC1CG,EACFJ,EAAmB,GAAKC,EAAoB,GACvCrd,EAAI,EAAGA,EAAIwa,EAAOxa,IACzB,IAAK,IAAIyd,EAAI,EAAGA,EAAIX,EAAWW,IAO7B,IANA,IAAMC,EAAgBH,EAAwBE,EACxCE,EAAiBjd,KAAK8L,MAAMkR,GAC5BE,EAAUF,EAAgBC,EAC1BE,EAAgBnd,KAAKE,IAAIqc,EAAY,EAAGvc,KAAKmO,KAAK6O,IAClDI,EAAe9d,EAAIgD,EAAEzE,QAAQ,GAAKof,EAAiB3a,EAAEzE,QAAQ,GAC7Dwf,EAAe/d,EAAIgD,EAAEzE,QAAQ,GAAKsf,EAAgB7a,EAAEzE,QAAQ,GACzD6Z,EAAI,EAAGA,EAAI2E,EAAU3E,IAU5B,IATA,IAAM4F,EAAgBR,EAAwBpF,EACxC6F,EAAiBvd,KAAK8L,MAAMwR,GAC5BE,EAAUF,EAAgBC,EAC1BE,EACFzd,KAAKE,IAAIsc,EAAW,EAAGxc,KAAKmO,KAAKmP,IAC/BI,EAAgBN,EAAeG,EAAiBjb,EAAEzE,QAAQ,GAC1D8f,EAAgBN,EAAeE,EAAiBjb,EAAEzE,QAAQ,GAC1D+f,EAAiBR,EAAeK,EAAgBnb,EAAEzE,QAAQ,GAC1DggB,EAAiBR,EAAeI,EAAgBnb,EAAEzE,QAAQ,GACvD6B,EAAI,EAAGA,EAAI+c,EAAa/c,IAAK,CAIpC,IAAMoe,EAAUlgB,EAAQ8f,EAAgBhe,GAClCqe,EAAangB,EAAQ+f,EAAgBje,GAIrCse,EAAMF,GAHKlgB,EAAQggB,EAAiBle,GAGRoe,GAAWN,EAEvCS,EAAWD,GADFD,GAHKngB,EAAQigB,EAAiBne,GAGFqe,GAAcP,EACxBQ,GAAOd,EAExCrgB,EAAO+f,KAAeqB,EAK9B,OAAOjY,SAAUnJ,EAAQ,CAACid,EAAOsC,EAAWC,EAAUI,KAGxDpZ,mCAAA,SAAuB2L,EAAc1M,EAAaga,GAChDlf,EAAiB,CAAC4R,EAAI1M,GAAI,0BA+B1B,IA7BM,IAAAyB,UAAC+V,OAAOoE,OAASC,OAAQC,OACzBvT,UAAGwT,OAASC,OAEZvf,EAAS,IAAImP,aAAa4L,EAAQoE,EAAUC,EAASC,GAOrDG,EAAmC,CACtCjC,GAAgB+B,EAAU,EAAKH,EAAU,EAAIA,EAC7C5B,GAAgBgC,EAAS,EAAKH,EAAS,EAAIA,GAGxCK,EAAmC,CACtClC,GAAgB+B,EAAU,EAAKA,EAAU,EAAIA,EAC7C/B,GAAgBgC,EAAS,EAAKA,EAAS,EAAIA,GAGxCG,EAAcF,EAAe,GAAKC,EAAe,GACjDE,EAAaH,EAAe,GAAKC,EAAe,GAMhDtP,EAAW3L,KAAKO,SAASkL,EAAGpL,QAC9B7H,EAAS,EACJuD,EAAI,EAAGA,EAAIwa,EAAOxa,IAEzB,IADA,IAAMqf,EAAUrf,EAAIgD,EAAEzE,QAAQ,GACrBkf,EAAI,EAAGA,EAAIsB,EAAStB,IAU3B,IATA,IAAM3D,EAAM2D,EAAI0B,EACVG,EAAc5e,KAAK8L,MAAMsN,GACzByF,EAAiB7e,KAAKE,IAAIF,KAAKmO,KAAKiL,GAAM8E,EAAU,GAEpDY,EAAeH,EAAUC,EAActc,EAAEzE,QAAQ,GACjDkhB,EAAkBJ,EAAUE,EAAiBvc,EAAEzE,QAAQ,GAEvDmhB,EAAU5F,EAAMwF,EAChBK,EAAiB,EAAMD,EACpBtH,EAAI,EAAGA,EAAI4G,EAAQ5G,IAmB1B,IAlBA,IAAM2B,EAAM3B,EAAIgH,EACVQ,EAAelf,KAAK8L,MAAMuN,GAC1B8F,EAAgBnf,KAAKE,IAAIF,KAAKmO,KAAKkL,GAAM8E,EAAS,GAClDiB,EAAU/F,EAAM6F,EAChBG,EAAiB,EAAMD,EAEvBE,EAAkBR,EAAeI,EAAe5c,EAAEzE,QAAQ,GAC1D0hB,EAAmBT,EAAeK,EAAgB7c,EAAEzE,QAAQ,GAC5D2hB,EACFT,EAAkBG,EAAe5c,EAAEzE,QAAQ,GACzC4hB,EACFV,EAAkBI,EAAgB7c,EAAEzE,QAAQ,GAE1C6hB,EACFT,EAAiBI,EACfM,EAA6BV,EAAiBG,EAC9CQ,EAA6BZ,EAAUK,EACvCQ,EAAsBb,EAAUI,EAC7B1f,EAAI,EAAGA,EAAI0e,EAAO1e,IAAK,CAC9B,IAAMogB,EAAQ5Q,EAASnT,KACvBgD,EAAOugB,EAAkB5f,IACrBogB,EAAQJ,EACZ3gB,EAAOwgB,EAAmB7f,IAAMogB,EAAQH,EACxC5gB,EAAOygB,EAAqB9f,IACxBogB,EAAQF,EACZ7gB,EAAO0gB,EAAsB/f,IAAMogB,EAAQD,EAKnD,OAAOE,WAAYhhB,EAAQ,CAAC+a,EAAOqE,EAAQD,EAASE,GAAQ9b,EAAE9G,QAGhE6H,kCAAA,SACIf,EAAa8Z,EAAmBC,EAChCC,GACFlf,EAAiBkF,EAAG,yBAsBpB,IApBM,IAAAyB,UAAC+V,OAAOyC,OAAWC,OAAUC,OAC7B7e,EAAU2F,KAAKO,SAASxB,EAAEsB,QAC1B7E,EAAS,IAAImP,aAAa4L,EAAQsC,EAAYC,EAAWI,GAEzDC,EAAuC,CAC1CJ,GAAgBF,EAAY,EAAKG,EAAY,EAAIA,EACjDD,GAAgBD,EAAW,EAAKG,EAAW,EAAIA,GAG5CG,EAAwC,CAC3CL,GAAgBF,EAAY,EAAKA,EAAY,EAAIA,EACjDE,GAAgBD,EAAW,EAAKA,EAAW,EAAIA,GAG5CQ,EACFH,EAAmB,GAAKC,EAAoB,GAC1CG,EACFJ,EAAmB,GAAKC,EAAoB,GAE5CqD,EAAe,EACV1gB,EAAI,EAAGA,EAAIwa,EAAOxa,IAEzB,IADA,IAAM2gB,EAAc3gB,EAAIgD,EAAEzE,QAAQ,GACzBkf,EAAI,EAAGA,EAAIX,EAAWW,IAO7B,IANA,IAAMC,EAAgBH,EAAwBE,EAKxCmD,EAAYD,EAJOjgB,KAAKE,IAC1Bqc,EAAY,EACZD,EAAetc,KAAKmgB,MAAMnD,GACXhd,KAAK8L,MAAMkR,IACqB1a,EAAEzE,QAAQ,GACpD6Z,EAAI,EAAGA,EAAI2E,EAAU3E,IAO5B,IANA,IAAM4F,EAAgBR,EAAwBpF,EAKxC0I,EAAYF,EAJOlgB,KAAKE,IAC1Bsc,EAAW,EACXF,EAAetc,KAAKmgB,MAAM7C,GACXtd,KAAK8L,MAAMwR,IACmBhb,EAAEzE,QAAQ,GAClD6B,EAAI,EAAGA,EAAI+c,EAAa/c,IAAK,CAGpC,IAAM2gB,EAASziB,EAAQwiB,EAAY1gB,GACnCX,EAAOihB,KAAkBK,EAKjC,OAAOra,SACHjH,EAAQ,CAAC+a,EAAOsC,EAAWC,EAAUI,GAAcna,EAAE9G,QAG3D6H,0CAAA,SACI2L,EAAc1M,EAAaga,GAC7Blf,EAAiB,CAAC4R,EAAI1M,GAAI,iCAiC1B,IA/BM,IAAAyB,UAAC+V,OAAOoE,OAASC,OAAQC,OACzBvT,UAAGwT,OAASC,OAEZvf,EAAS,IAAImP,aAAa4L,EAAQoE,EAAUC,EAASC,GACrDlP,EAAW3L,KAAKO,SAASkL,EAAGpL,QAK5B2a,EAAmC,CACtCjC,GAAgB+B,EAAU,EAAKH,EAAU,EAAIA,EAC7C5B,GAAgBgC,EAAS,EAAKH,EAAS,EAAIA,GAGxCK,EAAmC,CACtClC,GAAgB+B,EAAU,EAAKA,EAAU,EAAIA,EAC7C/B,GAAgBgC,EAAS,EAAKA,EAAS,EAAIA,GAGxCG,EAAcF,EAAe,GAAKC,EAAe,GACjDE,EAAaH,EAAe,GAAKC,EAAe,GAEhD8B,EAAiB,EAAI7B,EACrB8B,EAAgB,EAAI7B,EAIpB8B,EAAyC,EAA5BxgB,KAAKmO,KAAKmS,GAAuB,EAC9CG,EAAuC,EAA3BzgB,KAAKmO,KAAKoS,GAAsB,EAGzCjhB,EAAI,EAAGA,EAAIwa,EAAOxa,IAEzB,IADA,IAAM2gB,EAAc3gB,EAAIgD,EAAEzE,QAAQ,GACzBkf,EAAI,EAAGA,EAAImB,EAASnB,IAM3B,IALA,IAAMmD,EAAYD,EAAclD,EAAIza,EAAEzE,QAAQ,GAGxC6iB,EAAa1gB,KAAK8L,MAAMiR,EAAIuD,GAC5BK,EAAW3gB,KAAK8L,MAAM4U,EAAcF,EAAY,GAC7C9I,EAAI,EAAGA,EAAIyG,EAAQzG,IAO1B,IANA,IAAM0I,EAAYF,EAAYxI,EAAIpV,EAAEzE,QAAQ,GAGtC+iB,EAAa5gB,KAAK8L,MAAM4L,EAAI6I,GAC5BM,EAAW7gB,KAAK8L,MAAM8U,EAAcH,EAAW,GAE5C/gB,EAAI,EAAGA,EAAI0e,EAAO1e,IAAK,CAI9B,IAHA,IAAIohB,EAAQ,EAGHC,EAAW,EAAGA,EAAWP,EAAWO,IAAY,CACvD,IAAMvH,EAAMuH,EAAWJ,EAEvB,KAAInH,EAAM,GAAKA,GAAO6E,GAAtB,CAIA,IAAM2C,EAAYf,EAAczG,EAAMxK,EAAGnR,QAAQ,GAC3Cmf,EAAgBxD,EAAMiF,EAK5B,GAAI1B,IAJqB/c,KAAKE,IAC1Bge,EAAU,EACV5B,EAAetc,KAAKmgB,MAAMnD,GACXhd,KAAK8L,MAAMkR,IAI9B,IAAK,IAAIiE,EAAW,EAAGA,EAAWR,EAAUQ,IAAY,CACtD,IAAMxH,EAAMwH,EAAWJ,EAEvB,KAAIpH,EAAM,GAAKA,GAAO6E,GAAtB,CAIA,IAAM4C,EAAYF,EAAYvH,EAAMzK,EAAGnR,QAAQ,GACzCyf,EAAgB7D,EAAMiF,EAMxBhH,IALqB1X,KAAKE,IAC1Bie,EAAS,EACT7B,EAAetc,KAAKmgB,MAAM7C,GACXtd,KAAK8L,MAAMwR,MAG5BwD,GAAS5R,EAASgS,EAAYxhB,OAIpCX,EAAOqhB,EAAY1gB,GAAKohB,EAKhC,OAAOf,WAAYhhB,EAAQuD,EAAEgB,MAAOhB,EAAE9G,QAGxC6H,sBAAA,SACIf,EAAa6e,EAAyBC,EACtCrlB,EAA4BsT,EAC5BgS,GACFjkB,EAAiB,CAACkF,EAAG6e,EAAMC,EAAU/R,EAAOtT,GAAS,aAoBrD,IAlBA,IAAMK,EAAQmH,KAAKO,SAASxB,EAAEsB,QACxB0d,EAAQ/d,KAAKO,SAASqd,EAAKvd,QAC3B2d,EAAUhe,KAAKO,SAASsd,EAASxd,QACjC4d,EAAQnS,EAAQ9L,KAAKO,SAASuL,EAAMzL,QACpB,IAAIsK,aAAa,CAAC,IAClCuT,EAAU1lB,EAASwH,KAAKO,SAAS/H,EAAO6H,QACrB,IAAIsK,aAAa,CAAC,IACrCwT,EAAU,IAAIxT,aAAa9R,EAAMN,QAEjC6lB,EAAgBF,EAAQ3lB,OACxB8lB,EAAcJ,EAAM1lB,OACpB+lB,EAAgBN,EAAQzlB,OACxBgmB,EAAcR,EAAMxlB,OAEtBimB,EAAO,EACPC,EAAK,EACLC,EAAK,EACLC,EAAK,EACArmB,EAAI,EAAGA,EAAIO,EAAMN,SAAUD,EAClC6lB,EAAQ7lB,GAAK4lB,EAAQM,MAChB3lB,EAAMP,GAAKylB,EAAMU,MAASR,EAAMS,KAC7BjiB,KAAK2O,KAAK4S,EAAQW,KAAQb,GAC9BU,GAAQJ,IACVI,EAAO,GAELC,GAAMF,IACRE,EAAK,GAEHC,GAAML,IACRK,EAAK,GAEHC,GAAML,IACRK,EAAK,GAGT,OAAOnC,WAAY2B,EAASpf,EAAEgB,QAGhCD,yCAAA,SACIf,EAAa6f,EAAqBxW,EAAc4F,EAChD6Q,GACFhlB,EAAiBkF,EAAG,gCAEpB,IAAM+f,EAAW/f,EAAEgB,MAAM,GACnBgf,EAAOD,EAAW,EAClBzkB,EAAU2F,KAAKO,SAASxB,EAAEsB,QAC1B8B,EAAOpD,EAAEoD,KACT7I,EAAS,IAAIqR,aAAaxI,GAEhC,SAAS6c,EAAkBxmB,GAQzB,IAPA,IAAMymB,EAAiBzmB,EAASsmB,EAC5BI,EACA1mB,EAASymB,EAAiBxiB,KAAKhE,IAAI,EAAGwmB,EAAiBL,GACrDO,EAAe3mB,EAASymB,EAC1BxiB,KAAKE,IAAIsiB,EAAiBL,EAAaG,GAEvCvY,EAAM,EACH0Y,GAAkBC,EAAcD,IAAkB,CACvD,IAAME,EAAI/kB,EAAQ6kB,GAClB1Y,GAAO4Y,EAAIA,EAEb,OAAO5Y,EAGT,IAAK,IAAIhO,EAAS,EAAGA,EAAS2J,EAAM3J,IAAU,CAC5C,IAAMgO,EAAMwY,EAAkBxmB,GACxB6mB,EAAMhlB,EAAQ7B,GAAUiE,KAAKiK,IAAI0B,EAAO4F,EAAQxH,GAAMqY,GAC5DvlB,EAAOd,GAAU6mB,EAGnB,OAAO7C,WAAYljB,EAAQyF,EAAEgB,QAG/BD,oBAAA,SACI2L,EAAc6T,EAAsBC,EACpCX,EAAqBxW,EAAc4F,EACnC6Q,GACFhlB,EAAiB4R,EAAI,WAQrB,IAPA,IAAMqT,EAAWrT,EAAG1L,MAAM,GACpB4L,EAAW3L,KAAKO,SAASkL,EAAGpL,QAC5Bmf,EAAmBxf,KAAKO,SAAS+e,EAAWjf,QAC5Cof,EAAoBzf,KAAKO,SAASgf,EAAYlf,QAC9C/G,EAAS,IAAIqR,aAAac,EAAGtJ,MAC7BA,EAAOsJ,EAAGtJ,KAEP3J,EAAS,EAAGA,EAAS2J,EAAM3J,IAAU,CAQ5C,IAPA,IAAMymB,EAAiBzmB,EAASsmB,EAC1BY,EACDlnB,EAASymB,EAAkBxiB,KAAKhE,IAAI,EAAGwmB,EAAiBL,GACvDe,EAAYnnB,EAASymB,EACvBxiB,KAAKE,IAAImiB,EAAUG,EAAiBL,EAAc,GAElDgB,EAAO,EACFzX,EAAIuX,EAAYvX,EAAIwX,EAAUxX,IACrCyX,GAAQnjB,KAAKiK,IAAI8Y,EAAiBrX,GAAI,GAExCyX,EAAO5R,EAAQ4R,EAAOxX,EAEtB,IAASD,EAAIuX,EAAYvX,EAAIwX,EAAUxX,IAAK,CAC1C,IAAI0X,GAAO,EAAI7R,EAAQ6Q,EAAOW,EAAiBrX,GAC3CsX,EAAkBjnB,GAAUonB,EAC5BpnB,IAAW2P,IACb0X,GAAOpjB,KAAKiK,IAAIkZ,GAAOf,IAEzBgB,GAAOlU,EAASnT,GAChBc,EAAO6O,IAAM0X,GAGjB,OAAOrD,WAAYljB,EAAQmS,EAAG1L,QAGhCD,wBAAA,SACIgG,EAAkBga,EAAqBC,EACvCC,GACFnmB,EAAiBiM,EAAQ,eASzB,IAPA,IAAMma,EAAgBH,EAAaha,EAASoa,UAAWpa,GACjD9J,EAAYikB,EAAclgB,MAAM,GAChCogB,EAAYF,EAAclgB,MAAM,GAChCyD,EAAMmF,QAAkB,CAAC3M,EAAW+jB,GAAa,SACjDrY,EAAU1H,KAAKO,SAASiD,EAAInD,QAC5B+f,EAAWpgB,KAAKO,SAAS0f,EAAc5f,QAEpCtE,EAAI,EAAGA,EAAIC,IAAaD,EAAG,CAClC,IAAMvD,EAASuD,EAAIokB,EAGbE,EAAM,IAAI1V,aAAawV,EAAY,GACzCE,EAAI,GAAKD,EAAS5nB,GAClB,IAAK,IAAI8nB,EAAQ,EAAGA,EAAQD,EAAI9nB,SAAU+nB,EACxCD,EAAIC,GAASD,EAAIC,EAAQ,GAAKF,EAAS5nB,EAAS8nB,GAKlD,IAFA,IAAMC,EAASC,OAAgBR,EAAKS,YAC9BC,EAAY3kB,EAAIgkB,EACbY,EAAW,EAAGA,EAAWZ,IAAcY,EAAU,CACxD,IAAMnH,EAAI+G,IAGV7Y,EAAQgZ,EAAYC,GAAYN,EAAI9nB,OAEpC,IAAK,IAAIqoB,EAAQ,EAAGA,EAAQP,EAAI9nB,OAAQqoB,IACtC,GAAIpH,EAAI6G,EAAIO,GAAQ,CAClBlZ,EAAQgZ,EAAYC,GAAYC,EAChC,QAKR,OAAOpd,GAGT1D,mBAAA,SAAOsU,EAAmByG,EAAegG,EAAiBC,GAExDjnB,EAAiBua,EAAS,UAE1B,IAAM5Q,EAAM,IAAImH,aAAayJ,EAAQjS,KAAO0Y,GAC5CrX,EAAIF,KAAKwd,GAGT,IAFA,IAAMC,EAAa/gB,KAAKO,SAAS6T,EAAQ/T,QAEhC2gB,EAAQ,EAAGA,EAAQ5M,EAAQjS,OAAQ6e,EACtCD,EAAWC,IAAU,GAAKD,EAAWC,GAASnG,IAChDrX,EAAIwd,EAAQnG,EAAQkG,EAAWC,IAAUH,GAG7C,OAAOI,WAAYzd,EAAK,CAAC4Q,EAAQjS,KAAM0Y,GAAQ,UAGjD/a,8BAAA,SACIohB,EAAiBC,EAAkBC,EACnCC,EAAsBC,GACxBznB,EAAiBqnB,EAAO,qBAExB,IAAMK,EAAYvhB,KAAKO,SAAS2gB,EAAM7gB,QAChCmhB,EAAaxhB,KAAKO,SAAS4gB,EAAO9gB,QACxC,OAAO9B,EACHgjB,EAAWC,EAAYJ,EAAeC,EAAcC,IAG1DxhB,gBAAA,SAAIf,GACF,OAAOiB,KAAKyhB,SAAS1iB,GAAG,IAG1Be,iBAAA,SAAKf,GACH,OAAOiB,KAAKyhB,SAAS1iB,GAAG,IAMlBe,qBAAR,SAAiBf,EAAa2iB,GAU5B,IATA,IAAMnL,EAAQxX,EAAEgB,MAAM,GAChB4hB,EAAW5iB,EAAEgB,MAAM,GAEnB6hB,EAAa1gB,SAAUnC,EAAEgB,MAAO,WAChC8hB,EAAa3gB,SAAUnC,EAAEgB,MAAO,WAEhCY,EAAOoD,OAAQhF,GAAGuF,KAAKiS,EAAOoL,GAC9B9gB,EAAOoD,OAAQlF,GAAGuF,KAAKiS,EAAOoL,GAE3B5lB,EAAI,EAAGA,EAAIwa,EAAOxa,IAQzB,IANA,IAAMyd,EAAI7Y,EAAK4C,MAAM,CAACxH,EAAG,GAAI,CAAC,EAAG4lB,IAC3BrpB,EAAIuI,EAAK0C,MAAM,CAACxH,EAAG,GAAI,CAAC,EAAG4lB,IAC3B1f,EAAQiC,UAAWsV,EAAGlhB,GAEtBkL,EACFxD,KAAKO,SAASP,KAAK8hB,QAAQ7f,EAAOyf,GAASrhB,QACtClE,EAAI,EAAGA,EAAIwlB,EAAUxlB,IAAK,CACjC,IAAMgY,EAAIhU,eAAa4hB,oBAAoBve,EAAKrH,GAChDylB,EAAWjmB,OAAOI,EAAI4lB,EAAWxlB,GAAKgY,EAAExT,KACxCkhB,EAAWlmB,OAAOI,EAAI4lB,EAAWxlB,GAAKgY,EAAEtT,KAK5C,OADUqD,UAAW0d,EAAW9e,WAAY+e,EAAW/e,YAC9CwB,KAAKiS,EAAOoL,IAGf7hB,oBAAR,SAAgBf,EAAa2iB,GAC3B,IAAMM,EAAMjjB,EAAEkjB,OAERC,EAAIF,EAAI7f,KAEd,GAAInC,KAAKmiB,cAAcD,GAAI,CACzB,IAAI5oB,EAAS0G,KAAKoiB,UAAUJ,EAAKE,EAAGR,GAASpd,KAAKvF,EAAEgB,MAAM,GAAIhB,EAAEgB,MAAM,IAMtE,OALI2hB,IACFpoB,EAAS4K,UACIH,OAAQzK,GAAQ+oB,IAAIrd,SAAUkd,IAC9Bje,OAAQ3K,GAAQ+oB,IAAIrd,SAAUkd,MAEtC5oB,EAEP,IAAMoG,EAAOM,KAAKO,SAASxB,EAAEsB,QACvBiiB,EACFtiB,KAAKuiB,yBAAyB7iB,EAAMwiB,EAAGR,GACrClmB,EAAS2E,eAAaqiB,uBAAuBF,GACnD,OAAOpe,UAAW1I,EAAOmF,KAAMnF,EAAOqF,MAAMyD,KAAKvF,EAAEgB,MAAM,GAAIhB,EAAEgB,MAAM,KAIjED,0BAAR,SAAsBqC,GACpB,OAA6B,IAArBA,EAAOA,EAAO,IAIhBrC,sBAAR,SAAkBmC,EAAiBE,EAAcuf,GAC/C,GAAa,IAATvf,EACF,OAAOF,EAET,IAAMvC,EAAOM,KAAKO,SAAS0B,EAAM5B,QAC3BoiB,EAAOtgB,EAAO,EACdugB,EAAcviB,eAAawiB,qBAAqBjjB,GAClDkjB,EAAa1e,UAAWwe,EAAY/hB,KAAM+hB,EAAY7hB,MAAMohB,OAC1DY,EAAa1iB,eAAa2iB,oBAAoBpjB,GAChDqjB,EAAY7e,UAAW2e,EAAWliB,KAAMkiB,EAAWhiB,MAAMohB,OAG7DW,EAAa5iB,KAAKoiB,UAAUQ,EAAYH,EAAMf,GAC9CqB,EAAY/iB,KAAKoiB,UAAUW,EAAWN,EAAMf,GAE5C,IAAMsB,EAAI7iB,eAAa8iB,UAAU9gB,EAAMuf,GACjCwB,EAAWhf,UAAW8e,EAAEriB,KAAMqiB,EAAEniB,MAAMuI,IAAI2Z,GAE1CI,EAAUP,EAAWta,IAAI4a,GACzBE,EAAUR,EAAWS,IAAIH,GAEzBI,EAAavf,OAAQof,GAAShf,OAAOJ,OAAQqf,IAC7CG,EAAatf,OAAQkf,GAAShf,OAAOF,OAAQmf,IAEnD,OAAOlf,UAAWof,EAAYC,GAAYtB,QAIpCniB,qCAAR,SACIJ,EAAkByC,EAAcuf,GAGlC,IAFA,IAAM8B,EAAM,IAAI7Y,aAAoB,EAAPxI,GAEpBqX,EAAI,EAAGA,EAAIrX,EAAMqX,IAAK,CAG7B,IAFA,IAAI7Y,EAAO,EACPE,EAAO,EACFsT,EAAI,EAAGA,EAAIhS,EAAMgS,IAAK,CAC7B,IAAM6O,EAAI7iB,eAAa+iB,SAAS1J,EAAIrF,EAAGhS,EAAMuf,GACvC+B,EAAOtjB,eAAa4hB,oBAAoBriB,EAAsByU,GACpExT,GAAQ8iB,EAAK9iB,KAAOqiB,EAAEriB,KAAO8iB,EAAK5iB,KAAOmiB,EAAEniB,KAC3CA,GAAQ4iB,EAAK9iB,KAAOqiB,EAAEniB,KAAO4iB,EAAK5iB,KAAOmiB,EAAEriB,KAEzC+gB,IACF/gB,GAAQwB,EACRtB,GAAQsB,GAEVhC,eAAaujB,mBAAmBF,EAAK7iB,EAAME,EAAM2Y,GAEnD,OAAOgK,GAGT1jB,yBAAA,SAAaf,EAAa4I,EAAmB4G,GAE3CpW,OAAKgC,OACc,SAAfoU,GACA,WAAM,MAAA,+DACFA,KACRpW,OAAKgC,OACDwN,EAAY,GACZ,WACI,MAAA,sDAAsDA,KAgB9D,IAdA,IAAM3L,EAAY+C,EAAEgB,MAAM,GACpB4jB,EAAc5kB,EAAEgB,MAAM,GACtB6jB,EAAa7kB,EAAEgB,MAAM,GACrB8jB,EAAa9kB,EAAEgB,MAAM,GAErB+jB,EAAeH,EAAchc,EAC7Boc,EAAcH,EAAajc,EAC3Bqc,EAAcH,GAAclc,EAAYA,GAExCtN,EAAU2F,KAAKO,SAASxB,EAAEsB,QAC1B/G,EACF,IAAIqR,aAAa3O,EAAY8nB,EAAeC,EAAcC,GAE1D3K,EAAY,EACPtd,EAAI,EAAGA,EAAIC,IAAaD,EAC/B,IAAK,IAAIkoB,EAAI,EAAGA,EAAIH,IAAgBG,EAGlC,IAFA,IAAMC,EAAMznB,KAAK8L,MAAM0b,EAAItc,GACrBwc,EAAWF,EAAItc,EACZyc,EAAI,EAAGA,EAAIL,IAAeK,EAIjC,IAHA,IAAMC,EAAM5nB,KAAK8L,MAAM6b,EAAIzc,GAErB2c,GAAWH,EAAUxc,EADVyc,EAAIzc,GAC6Bqc,EACzC7nB,EAAI,EAAGA,EAAI6nB,IAAe7nB,EAAG,CACpC,IACMooB,EADMpoB,EAAImoB,EAENT,GAAcQ,EAAMT,GAAcM,EAAMP,EAAc5nB,IAChEzC,EAAO+f,KAAehf,EAAQkqB,GAKtC,OAAO/H,WACHljB,EAAQ,CAAC0C,EAAW8nB,EAAcC,EAAaC,KAG7ClkB,gCAAR,SACImF,EAAWlJ,EAAW9D,EACtBusB,GACF,IAAMxrB,EAAWmH,eAAaskB,2BAA2Bxf,EAAElF,MAAOhE,EAAEgE,OAC9DzG,EAAS4H,SAAUlI,EAAUf,GAC7BH,EAAQkI,KAAKO,SAAS0E,EAAE5E,QACxBqkB,EAAQ1kB,KAAKO,SAASxE,EAAEsE,QACxBskB,EAAiBxkB,eAAaykB,iBAAiB3f,EAAElF,MAAO/G,GACxD6rB,EAAiB1kB,eAAaykB,iBAAiB7oB,EAAEgE,MAAO/G,GAExD0O,EAAUpO,EAAOqC,OACvB,GAAIgpB,EAAepsB,OAASssB,EAAetsB,SAAW,EACpD,IAAK,IAAID,EAAI,EAAGA,EAAIoP,EAAQnP,SAAUD,EACpCoP,EAAQpP,GAAKksB,EAAG1sB,EAAMQ,EAAIR,EAAMS,QAASmsB,EAAMpsB,EAAIosB,EAAMnsB,aAG3D,CAAA,IAAMusB,EAAO9kB,KAAK2C,WAAWsC,GACvB8f,EAAO/kB,KAAK2C,WAAW5G,cACpBzD,GACP,IAAMiB,EAAMD,EAAOE,WAAWlB,GAExB0sB,EAAOzrB,EAAIgK,OAAO0B,EAAE7B,MAC1BuhB,EAAe1qB,SAAQ,SAAAkC,GAAK,OAAA6oB,EAAK7oB,GAAK,KACtC,IAAM8oB,EAASH,EAAKlrB,WAAWorB,GAEzBE,EAAO3rB,EAAIgK,OAAOxH,EAAEqH,MAC1ByhB,EAAe5qB,SAAQ,SAAAkC,GAAK,OAAA+oB,EAAK/oB,GAAK,KACtC,IAAMgpB,EAASJ,EAAKnrB,WAAWsrB,GAE/Bxd,EAAQpP,GAAKksB,EAAG1sB,EAAMmtB,GAASP,EAAMS,KAXvC,IAAS7sB,EAAI,EAAGA,EAAIoP,EAAQnP,SAAUD,IAA7BA,GAcX,OAAOgB,EAAOwJ,YAGRhD,uCAAR,SACImF,EAAWlJ,EACXyoB,GAGF,IAAMxrB,EAAWmH,eAAaskB,2BAA2Bxf,EAAElF,MAAOhE,EAAEgE,OAC9D6hB,EAAa1gB,SAAUlI,EAAU,WACjC6oB,EAAa3gB,SAAUlI,EAAU,WAEjClB,EAAQkI,KAAKO,SAAS0E,EAAE5E,QACxBqkB,EAAQ1kB,KAAKO,SAASxE,EAAEsE,QACxBskB,EAAiBxkB,eAAaykB,iBAAiB3f,EAAElF,MAAO/G,GACxD6rB,EAAiB1kB,eAAaykB,iBAAiB7oB,EAAEgE,MAAO/G,GAExDosB,EAAWxD,EAAWjmB,OACtB0pB,EAAWxD,EAAWlmB,OAE5B,GAAIgpB,EAAepsB,OAASssB,EAAetsB,SAAW,EACpD,IAAK,IAAID,EAAI,EAAGA,EAAI8sB,EAAS7sB,OAAQD,IAAK,CACxC,IAAMgtB,EAAOhtB,EAAIR,EAAMS,OACjBgtB,EAAOjtB,EAAIosB,EAAMnsB,OAEjBe,EACFkrB,EAAG1sB,EAAa,EAAPwtB,GAAWxtB,EAAa,EAAPwtB,EAAW,GAAIZ,EAAa,EAAPa,GAC5Cb,EAAa,EAAPa,EAAW,IAExBH,EAAS9sB,GAAKgB,EAAOqH,KACrB0kB,EAAS/sB,GAAKgB,EAAOuH,SAGvB,CAAA,IAAM2kB,EACFxlB,KAAK2C,WAAW3C,KAAKN,KAAKrB,IAAI4G,EAAE5E,QAAQI,eAAeE,MACrD8kB,EACFzlB,KAAK2C,WAAW3C,KAAKN,KAAKrB,IAAItC,EAAEsE,QAAQI,eAAeE,iBAClDrI,GACP,IAAMiB,EAAMqoB,EAAWpoB,WAAWlB,GAE5B0sB,EAAOzrB,EAAIgK,OAAO0B,EAAE7B,MAC1BuhB,EAAe1qB,SAAQ,SAAAkC,GAAK,OAAA6oB,EAAK7oB,GAAK,KACtC,IAAM8oB,EAASO,EAAS5rB,WAAWorB,GAE7BE,EAAO3rB,EAAIgK,OAAOxH,EAAEqH,MAC1ByhB,EAAe5qB,SAAQ,SAAAkC,GAAK,OAAA+oB,EAAK/oB,GAAK,KACtC,IAAMgpB,EAASM,EAAS7rB,WAAWsrB,GAE7BQ,EACFlB,EAAG1sB,EAAe,EAATmtB,GAAantB,EAAe,EAATmtB,EAAa,GAAIP,EAAe,EAATS,GAChDT,EAAe,EAATS,EAAa,IAE1BC,EAAS9sB,GAAKotB,EAAS/kB,KACvB0kB,EAAS/sB,GAAKotB,EAAS7kB,MAhBzB,IAASvI,EAAI,EAAGA,EAAI8sB,EAAS7sB,OAAQD,MAA5BA,GAmBX,OAAO0H,KAAK2lB,QAAQ/D,EAAW9e,WAAY+e,EAAW/e,aAGxDhD,kBAAA,SAAwBf,EAAM6mB,EAAsB1iB,GAClD,OAAOzE,EAAMM,EAAG6mB,EAAY1iB,IAG9BpD,oBAAA,aAEAA,2BAAA,WACE,OAAO,IAITA,oBAAA,WACE,OAAON,YAAMqmB,oBAGf/lB,0BAAA,SACIgmB,EACA5E,EACA6E,EACAC,EACAC,EACAC,GAmBF,IAjBM,IAAA1lB,UAAC+V,OAAO4P,OAAaC,OAAYlN,OACjCmN,EAAWnF,EAAMnhB,MAAM,GAEtBumB,OAAYC,OACb/qB,EACF0F,SAAU,CAACmlB,EAAUC,EAAYC,EAAWrN,GAAc,WAExDsN,EAAUxmB,KAAKO,SAAS2gB,EAAM7gB,QAC9BomB,EAAazmB,KAAKO,SAASwlB,EAAS1lB,QACpCqmB,EAAY1mB,KAAKO,SAASulB,EAAOzlB,QAEjCsmB,EAAWb,EAAOxrB,QAClBssB,EAAYprB,EAAOlB,QAKhByB,EAAI,EAAGA,EAAIsqB,EAAUtqB,IAAK,CACjC,IAAM8qB,EAAe,EAAJ9qB,EACX+qB,EAAKN,EAAQK,GACbE,EAAKP,EAAQK,EAAW,GACxBG,EAAKR,EAAQK,EAAW,GACxBI,EAAKT,EAAQK,EAAW,GAExBK,EAAeT,EAAW1qB,GAChC,KAAImrB,GAAQ3Q,GAUZ,IANA,IAAM2E,EAAeoL,EAAa,GAC7BU,EAAKF,IAAOX,EAAc,IAAMG,EAAa,GAC9C,EACEnL,EACDoL,EAAY,GAAMU,EAAKF,IAAOX,EAAa,IAAMG,EAAY,GAAK,EAE9D7a,EAAI,EAAGA,EAAI4a,EAAY5a,IAAK,CACnC,IAAMyb,EAAgBb,EAAa,EAC/BQ,GAAMX,EAAc,GAAKza,IACzB,IAAOob,EAAKE,IAAOb,EAAc,GAErC,GAAIgB,EAAO,GAAKA,EAAOhB,EAAc,EACnC,IAAK,IAAIpnB,EAAI,EAAGA,EAAIwnB,EAAWxnB,IAC7B,IAAK,IAAIoV,EAAI,EAAGA,EAAI+E,EAAa/E,IAAK,CACpC,IAAMiT,EACFjT,EAAIpV,EAAI6nB,EAAU,GAAKlb,EAAIkb,EAAU,GAAK7qB,EAAI6qB,EAAU,GAC5DprB,EAAOG,OAAOyrB,GAAOlB,OAM3B,GAAe,aAAXD,EACF,CAAA,IAAMoB,EAAS5qB,KAAK8L,MAAM4e,GACpBG,EAAY7qB,KAAKmO,KAAKuc,GACtBI,EAAQJ,EAAOE,EAErB,IAAStoB,EAAI,EAAGA,EAAIwnB,EAAWxnB,IAAK,CAKlC,IAJMyoB,EAAQjB,EAAY,EACtBQ,GAAMX,EAAa,GAAKrnB,EAAIoc,EAC5B,IAAO4L,EAAKE,IAAOb,EAAa,IAEzB,GAAKoB,EAAOpB,EAAa,EAClC,IAASjS,EAAI,EAAGA,EAAI+E,EAAa/E,IAAK,CAC9BiT,EACFjT,EAAIpV,EAAI6nB,EAAU,GAAKlb,EAAIkb,EAAU,GAAK7qB,EAAI6qB,EAAU,GAC5DprB,EAAOG,OAAOyrB,GAAOlB,MAKzB,CAAA,IAAMuB,EAAUhrB,KAAK8L,MAAMif,GACrBE,EAAWjrB,KAAKmO,KAAK4c,GACrBG,EAAQH,EAAOC,EAErB,IAAStT,EAAI,EAAGA,EAAI+E,EAAa/E,IAAK,CACpC,IAEMoG,EAAUmM,EAFZU,EAAMjT,EAAIsT,EAAUd,EAAS,GAAKU,EAASV,EAAS,GACpDO,EAAOP,EAAS,IAKdiB,EAAWlB,EAFjBU,EAAMjT,EAAIuT,EAAWf,EAAS,GAAKU,EAASV,EAAS,GACjDO,EAAOP,EAAS,IAKdnM,EAAakM,EAFnBU,EAAMjT,EAAIsT,EAAUd,EAAS,GAAKW,EAAYX,EAAS,GACnDO,EAAOP,EAAS,IAOdkB,EAAMtN,GAAWqN,EAAWrN,GAAWoN,EACvCG,EAAStN,GAHKkM,EAFpBU,EAAMjT,EAAIuT,EAAWf,EAAS,GAAKW,EAAYX,EAAS,GACpDO,EAAOP,EAAS,IAIuBnM,GAAcmN,EAEzDP,EAAMjT,EAAIpV,EAAI6nB,EAAU,GAAKlb,EAAIkb,EAAU,GAAK7qB,EAAI6qB,EAAU,GAC9DprB,EAAOG,OAAOyrB,GAAOS,GAAQC,EAASD,GAAON,UAIjD,IAASxoB,EAAI,EAAGA,EAAIwnB,IAAaxnB,EAAG,CAClC,IAAMyoB,EAIN,IAJMA,EAAQjB,EAAY,EACtBQ,GAAMX,EAAa,GAAKrnB,EAAIoc,EAC5B,IAAO4L,EAAKE,IAAOb,EAAa,IAEzB,GAAKoB,EAAOpB,EAAa,EAClC,IAASjS,EAAI,EAAGA,EAAI+E,EAAa/E,IAAK,CAC9BiT,EACFjT,EAAIpV,EAAI6nB,EAAU,GAAKlb,EAAIkb,EAAU,GAAK7qB,EAAI6qB,EAAU,GAC5DprB,EAAOG,OAAOyrB,GAAOlB,MAKzB,CAAA,IAAM6B,EAAWtrB,KAAKmgB,MAAM4K,GACtBQ,EAAWvrB,KAAKmgB,MAAMuK,GAC5B,IAAShT,EAAI,EAAGA,EAAI+E,EAAa/E,IAAK,CACpC,IAAM8T,EAAQ9T,EAAI4T,EAAWpB,EAAS,GAClCqB,EAAWrB,EAAS,GAAKO,EAAOP,EAAS,GACvCuB,EACF/T,EAAIpV,EAAI6nB,EAAU,GAAKlb,EAAIkb,EAAU,GAAK7qB,EAAI6qB,EAAU,GAC5DprB,EAAOG,OAAOusB,GAAUxB,EAAUuB,OAM5C,OAAOzsB,EAAOsH,YAGhBhD,0BAAA,SACIqoB,EAAuBC,EAAsBC,EAC7CC,GACI,IAAA9nB,wCAAC+nB,cAAWC,eAAYrT,cAAW7a,YAASmuB,eAGlD,OAAOzoB,KAAK0oB,QACRP,EAAeC,EAAcC,EAAaI,EAAYtT,EACtDqT,EAAYD,EAAWjuB,EAASguB,GAHb,IAMzBxoB,qBAAA,SAASf,EAAWqV,GAClB,IAAMuU,EAAevU,EAAQrU,MACvBwoB,EAAYI,EAAaA,EAAapwB,OAAS,GAE/CiI,yCAACooB,OAAaC,OAAW1T,OAAW7a,OAE1C,GAAkB,IAAduuB,EACF,OAAOpmB,SAAU,GAAImmB,EAAa7pB,EAAE9G,OAOtC,IAJA,IAAMwD,EAAS,IAAIqtB,eAAa,CAACD,EAAW1T,GAAYpW,EAAE9G,OACpD8wB,EAAc/oB,KAAKO,SAAS6T,EAAQ/T,QACpC2oB,EAAQhpB,KAAKO,SAASxB,EAAEsB,QAErB/H,EAAI,EAAGA,EAAIuwB,EAAWvwB,IAAK,CAGlC,IAFA,IAAM8R,EAAQ,GACV6e,EAAe,EACVvwB,EAAI,EAAGA,EAAI6vB,EAAW7vB,IAAK,CAClC,IAAMqN,EAAMgjB,EAAYzwB,EAAIiwB,EAAY7vB,GACxCuwB,GAAgBljB,EAAMzL,EAAQ5B,GAC9B0R,EAAMf,KAAKtD,GAEb,GAAIkjB,EAAe,GAAKA,GAAgBlqB,EAAEoD,KAAOgT,EAC/C,MAAM,IAAI5V,MACN,oBAAoB6K,0BAA6BrL,EAAEgB,OAGzD,IAAK,IAAIoI,EAAI,EAAGA,EAAIgN,EAAWhN,IAC7B1M,EAAOE,OAAOrD,EAAI6c,EAAYhN,GAAK6gB,EAAMC,EAAe9T,EAAYhN,GAGxE,OAAO1M,EAAOqH,WAAWW,QAAQmlB,IAGnC9oB,sBAAA,SACIsU,EAAiB8U,EAAiBnpB,GAC9B,IAAAS,wCAAC+nB,cAAWC,eAAYrT,cAAW7a,YAASmuB,eAE5CH,EAAetjB,SAAU,GAE/B,OAAOhF,KAAK0oB,QACRtU,EAAS8U,EAASnpB,EAAO0oB,EAAYtT,EAAWqT,EAAYD,EAC5DjuB,EAASguB,GAHU,IAMzBxoB,iBAAA,SACIC,EAAoBpH,EAAsBV,GAC5CA,EAAQA,GAASE,OAAKgxB,WAAWxwB,GACjC,IAAMgD,EACFxD,OAAKixB,kBAAkBnxB,EAAOE,OAAKE,cAAc0H,IAErD,OADApE,EAAO2H,KAAK3K,GACLiH,WAASypB,WAAW1tB,EAAQoE,EAAO9H,EAAO+H,OAGnDF,qBAAA,SAAyBf,GACvB,GAAgB,WAAZA,EAAE9G,MACJ,MAAM,IAAIsH,MAAM,gDAEhB,OAAOS,KAAKsD,KAAKvE,EAAEgB,MAAO,EAAGhB,EAAE9G,QAInC6H,sBAAA,SAA0Bf,GACxB,IAAMpD,EAASxD,OAAKixB,kBACDrqB,EAAE9G,MAAOE,OAAKE,cAAc0G,EAAEgB,QACjD,OAAOC,KAAK8B,WAAWnG,EAAQoD,EAAEgB,MAAOhB,EAAE9G,QAG5C6H,qBAAA,SAAS2B,EAAe6nB,EAAcnmB,GACpC,OAAOhD,eAAaopB,aAAa9nB,EAAO6nB,EAAMnmB,IAGxCrD,oBAAR,SACIsU,EAAiB8U,EAAiBnpB,EAAoB0oB,EACtDtT,EAAmBqT,EAAoBD,EACvCjuB,EAAmBguB,EACnBkB,GACF,IAAM7T,EAAe,CAAC8S,EAAatT,EAAWA,GAExC4T,EAAc/oB,KAAKO,SAAS6T,EAAQ/T,QACpCopB,EAAczpB,KAAKO,SAAS2oB,EAAQ7oB,QAE1C,GAAmB,IAAfooB,EACF,OAAOhmB,SAAU,GAAI1C,EAAOmpB,EAAQjxB,OAGtC,IAAMwD,EAAS,IAAIqtB,eAAanT,EAAcuT,EAAQjxB,OACtDwD,EAAOE,OAAO2H,KAAMtD,KAAKO,SAAS+nB,EAAajoB,QAAuB,IAEtE,IAAK,IAAI/H,EAAI,EAAGA,EAAIkwB,EAAYlwB,IAAK,CAGnC,IAFA,IAAM8R,EAAQ,GACV6e,EAAe,EACVvwB,EAAI,EAAGA,EAAI6vB,EAAW7vB,IAAK,CAClC,IAAMqN,EAAMgjB,EAAYzwB,EAAIiwB,EAAY7vB,GACxC0R,EAAMf,KAAKtD,GACXkjB,GAAgBljB,EAAMzL,EAAQ5B,GAGhC,GAAIuwB,EAAe,GAAKA,GAAgBR,EAAatT,EACnD,MAAM,IAAI5V,MACN,oBAAoB6K,0BAA6BrK,GAGvD,IAAK,IAAIoI,EAAI,EAAGA,EAAIgN,EAAWhN,IACzBqhB,EACF/tB,EAAOE,OAAOstB,EAAe9T,EAAYhN,IACrCshB,EAAYnxB,EAAI6c,EAAYhN,GAEhC1M,EAAOE,OAAOstB,EAAe9T,EAAYhN,GAAsB,IAAjB+gB,EAAQ9lB,KAClDqmB,EAAY,GACZA,EAAYnxB,EAAI6c,EAAYhN,GAItC,OAAO1M,EAAOqH,WAAWW,QAAQ1D,OAvgHD2pB,0BCtCpBC,EACZC,EACApF,GAIF,MAAO,CACLqF,WAAYD,EACZE,YAAa,MACbC,WAAY,SAACvpB,OAACwpB,WAAQlrB,YACdwI,IAACrC,MAAGlJ,MACJkuB,EAAanrB,EACnBjF,EAAiB,CAACoL,EAAGlJ,GAAI6tB,GAEzB,IAAM9xB,EAAQmyB,EAAWvqB,KAAKrB,IAAI4G,EAAE5E,QAAQ1E,OACtC+oB,EAAQuF,EAAWvqB,KAAKrB,IAAItC,EAAEsE,QAAQ1E,OAEtCwW,iCAAC+X,OAAYtB,OAInB,MAAO,CAACvoB,OADO4pB,EAAW9oB,MAAM+oB,EAAYtB,EAAa3jB,EAAEhN,OAC3C8H,MAAO6oB,EAAa3wB,MAAOgN,EAAEhN,kBAKnCkyB,EAAuB3F,GACrC,OAAO,SAAC4F,EAAkBC,EAAkBvyB,EACpC4sB,EAAmBzsB,GACzB,IAAMe,EAAWmH,eAAaskB,2BAA2B2F,EAAQC,GAE3DC,EAAatxB,EAAST,OACtBgyB,EAAgBpyB,OAAKiB,eAAeJ,GACpCwxB,EAAaryB,OAAKE,cAAcW,GAEhCM,EACFnB,OAAKC,uBAAuBH,EAA0BuyB,GAEpDC,EAAQL,EAAO7xB,OACfmyB,EAAQL,EAAO9xB,OAEfoyB,EAAWxyB,OAAKiB,eAAegxB,GAC/BQ,EAAWzyB,OAAKiB,eAAeixB,GAE/B1F,EAAiBxkB,eAAaykB,iBAAiBwF,EAAQpxB,GACvD6rB,EAAiB1kB,eAAaykB,iBAAiByF,EAAQrxB,GAE7D,GAAI2rB,EAAepsB,OAASssB,EAAetsB,SAAW,EACpD,IAAK,IAAID,EAAI,EAAGA,EAAIgB,EAAOf,SAAUD,EACnCgB,EAAOhB,GAAKksB,EAAG1sB,EAAMQ,EAAIR,EAAMS,QAASmsB,EAAMpsB,EAAIosB,EAAMnsB,6BAGjDD,GACP,IAAMiB,EAAMpB,OAAKqB,WAAWlB,EAAGgyB,EAAYC,GAErCvF,EAAOzrB,EAAIgK,OAAOknB,GACxB9F,EAAe1qB,SAAQ,SAAAkC,GAAK,OAAA6oB,EAAK7oB,GAAK,KACtC,IAAM8oB,EAAS9sB,OAAKyB,WAAWorB,EAAMyF,EAAOE,GAEtCzF,EAAO3rB,EAAIgK,OAAOmnB,GACxB7F,EAAe5qB,SAAQ,SAAAkC,GAAK,OAAA+oB,EAAK/oB,GAAK,KACtC,IAAMgpB,EAAShtB,OAAKyB,WAAWsrB,EAAMwF,EAAOE,GAE5CtxB,EAAOhB,GAAKksB,EAAG1sB,EAAMmtB,GAASP,EAAMS,KAXtC,IAAS7sB,EAAI,EAAGA,EAAIgB,EAAOf,SAAUD,IAA5BA,GAeX,MAAO,CAACgB,EAAQN,ICzEb,IAAM6xB,EAAUV,GAAuB,SAACllB,EAAWlJ,GAAc,OAAAkJ,EAAIlJ,KCE/D+uB,EAAYnB,EAAyBoB,MAAKF,GCM1CG,EAA0B,CACrCnB,WAAYoB,MACZnB,YAAa,MACbC,WAAY,SAACvpB,OAACwpB,WAAQkB,UAAOpsB,YACpBC,MACAosB,qBACDlB,EAAanrB,EACfhG,EAASiG,EAAEgB,MACT9G,EAAQH,EAAOP,OAGjByN,EADa7N,OAAK8N,eAAeklB,EAAkBryB,GAEjDsyB,EAAejrB,eAAakrB,mBAAmBrlB,EAAM/M,GACvDJ,EAAQoxB,EAAWvqB,KAAKrB,IAAIU,EAAEsB,QAAQ1E,OAC1C,GAAoB,MAAhByvB,EAAsB,CAExB,IADA,IAAMpyB,EAAqB,IAAIU,MAAMT,GAC5BX,EAAI,EAAGA,EAAIU,EAAST,OAAQD,IACnCU,EAASV,GAAKQ,EAAOsyB,EAAa9yB,IAGpCO,EAAQD,EAAcC,EAAOC,EAAQiG,EAAE9G,MAAOmzB,EAAcpyB,GAC5DgN,EAAO7F,eAAamrB,iBAAiBtlB,EAAKzN,OAAQU,GAElDH,EAASE,EAGXa,EAAiBkF,EAAG,OACpBoB,eAAaqI,2BAA2B,MAAOxC,EAAM/M,GAC/C,IAAAqO,gDAACikB,OAAa9iB,OAKdnP,EAASzB,EAAQgB,EAFJV,OAAKE,cAAcoQ,GAEI8iB,EAAaxsB,EAAE9G,OAEzD,MAAO,CAACoI,OADO4pB,EAAW9oB,MAAM7H,EAAQiyB,EAAaxsB,EAAE9G,OACvC8H,MAAOwrB,EAAatzB,MAAO8G,EAAE9G,SC3BjD,ICXO,IAAMuzB,EAAwC,CACnD3B,WAAY4B,oBACZ3B,YAAa,MACbC,WAAY,SAACvpB,OAACwpB,WAAQkB,UAAOpsB,YACpBC,MACDuI,IAACokB,eAAYpxB,YAASkb,QAAK1X,wBAE3BmsB,EAAanrB,EACnBjF,EAAiBkF,EAAG,qBAEpB,IAAMpD,EAASsuB,EAAWvqB,KAAKrB,IAAIU,EAAEsB,QAAQ1E,OACvCpB,EAAW4F,eAAawrB,kBAC1B5sB,EAAEgB,MAA2C2rB,EAAYpxB,EACzD,CAAC,EAAG,GAAIkb,GACNrD,WClBN9X,EAAqBvB,EAAkBb,EACvC6F,EAA8BvD,GAChC,IACMqxB,EAAWxxB,EAAKC,EAASvB,EAAQb,EADvBE,OAAKiB,eAAeN,GACmByB,EAAU,OAC3DwD,EAAeH,EACjBvD,EAASvB,EAAQb,EAAOsC,GAAU,EAAMuD,GAE5C,MAAO,CAAC8tB,EAASjwB,OAAQoC,EAAapC,gCDW7BkwB,OAAQC,OAGTC,EACF9B,EAAW9oB,MAAM0qB,EAAwBtxB,EAASvC,SAAU+G,EAAE9G,OAC5D+zB,EACF/B,EAAW9oB,MAAM2qB,EAAuBvxB,EAASvC,SAAU+G,EAAE9G,OACjE,MAAO,CACL,CAACoI,OAAQ0rB,EAAchsB,MAAOxF,EAASvC,SAAUC,MAAO8G,EAAE9G,OAC1D,CAACoI,OAAQ2rB,EAAejsB,MAAOxF,EAASvC,SAAUC,MAAO,YE3BzDg0B,EAAsBztB,eAAaytB,oBAI5BC,EAA0C,CACrDrC,WAAYsC,sBACZrC,YAAa,MACbC,WAAY,SAACvpB,OAACwpB,WAAQlrB,YAASosB,UACvB5jB,IAAC4Z,UAAOC,WACRhP,IAACiP,kBAAeC,iBAAcC,mBAAgB8K,iBAG9CnC,EAAanrB,EAEnBjF,EAAiBqnB,EAAO,8BAExB,IAAMK,EAAY0I,EAAWvqB,KAAKrB,IAAI6iB,EAAM7gB,QAAQ1E,OAC9C6lB,EAAayI,EAAWvqB,KAAKrB,IAAI8iB,EAAO9gB,QAAQ1E,OAOhD0wB,QALmBjL,EACDC,EACEC,EACF8K,GAMxB,MAAO,uCC1BEE,EAA6B,CACxCzC,WAAY0C,SACZzC,YAAa,MACbC,WAAY,SAACvpB,OAACwpB,WAAQlrB,YACbC,MACDkrB,EAAanrB,EACnBjF,EAAiBkF,EAAG,UAIpB,IAFA,IAAMpD,EAASsuB,EAAWvqB,KAAKrB,IAAIU,EAAEsB,QAAQ1E,OACvCsO,EAAY,IAAIU,aAAahP,EAAOpD,QACjCD,EAAI,EAAGA,EAAIqD,EAAOpD,SAAUD,EAAG,CACtC,IAAMK,EAAQgD,EAAOrD,GACrB2R,EAAU3R,GAAKK,EAAQA,EAGzB,MAAO,CAAC0H,OADO4pB,EAAW9oB,MAAM8I,EAAWlL,EAAEgB,MAAOhB,EAAE9G,OACtC8H,MAAOhB,EAAEgB,MAAO9H,MAAO8G,EAAE9G,SChBvCu0B,EAAwBrC,GAAuB,SAACpgB,EAAMC,GAC1D,IAAMU,EAAOX,EAAOC,EACpB,OAAOU,EAAOA,SLYW+hB,EALW,CACpCP,EAA2BI,EKJzB3C,EAAyB+C,oBAAmBF,GLIoB1B,EMNvB,CAC3CjB,WAAY8C,YACZ7C,YAAa,MACbC,WAAY,SAACvpB,OAACwpB,WAAQkB,UAAOpsB,YACpBC,MACAhG,SACDkxB,EAAanrB,EAEnBjF,EAAiBkF,EAAG,aAKpB,IAHA,IAAM9F,EAAQ8F,EAAEgB,MAAMxH,OAEhBS,EAAqB,IAAIU,MAAMT,GAC5BX,EAAI,EAAGA,EAAIU,EAAST,OAAQD,IACnCU,EAASV,GAAKyG,EAAEgB,MAAMhH,EAAKT,IAG7B,IACMgB,EAASV,EADAqxB,EAAWvqB,KAAKrB,IAAIU,EAAEsB,QAAQ1E,OACRoD,EAAEgB,MAAOhB,EAAE9G,MAAOc,EAAMC,GAG7D,MAAO,CAACqH,OADO4pB,EAAW9oB,MAAM7H,EAAQN,EAAU+F,EAAE9G,OACpC8H,MAAO/G,EAAUf,MAAO8G,EAAE9G,SNd3BuzB,EAAyBR,GAGjB4B,WAAAA,IAAe,CAArC,IAAMC,OACTC,iBAAeD,qBOfD,OAAO,WAAM,OAAA,IAAI/sB,IAAkB,+CClBnC"}